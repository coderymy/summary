# ArrayList

### ArrayList结构图 

ArrayList 是 java 集合框架中比较常用的数据结构了。继承自 AbstractList，实现了 List 接口。底层基于数组实现容量大小动态变化。允许 null 的存在。同时还实现了 RandomAccess、Cloneable、Serializable 接口，所以ArrayList 是支持快速访问、复制、序列化的。

![图片](https://mmbiz.qpic.cn/mmbiz_png/H9PJZVVHIW8ibhAzD6zTmI8WthicX51Wiboambs1W7gCj0M3Vmiao91zPK6EvnNqicCNjO2gibHGHfYXQibLORIcE453A/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

### ArrayList类简介

- 1、ArrayList是内部是以动态数组的形式来存储数据的、知道数组的可能会疑惑：数组不是定长的吗？这里的动态数组不是意味着去改变原有内部生成的数组的长度、而是保留原有数组的引用、将其指向新生成的数组对象、这样会造成数组的长度可变的假象。
- 2、ArrayList具有数组所具有的特性、通过索引支持随机访问、所以通过随机访问ArrayList中的元素效率非常高、但是执行插入、删除时效率比较地下、具体原因后面有分析。
- 3、ArrayList实现了AbstractList抽象类、List接口、所以其更具有了AbstractList和List的功能、前面我们知道AbstractList内部已经实现了获取Iterator和ListIterator的方法、所以ArrayList只需关心对数组操作的方法的实现、
- 4、ArrayList实现了RandomAccess接口、此接口只有声明、没有方法体、表示ArrayList支持随机访问。
- 5、ArrayList实现了Cloneable接口、此接口只有声明、没有方法体、表示ArrayList支持克隆。
- 6、ArrayList实现了Serializable接口、此接口只有声明、没有方法体、表示ArrayList支持序列化、即可以将ArrayList以流的形式通过ObjectInputStream/ObjectOutputStream来写/读。

##### 基础属性

ArrayList部分源码如下：

```
public class ArrayList<E> extends AbstractList<E>        implements List<E>, RandomAccess, Cloneable, java.io.Serializable{    private static final int DEFAULT_CAPACITY = 10;
    private static final Object[] EMPTY_ELEMENTDATA = {};
    private transient Object[] elementData;
    private int size;
    //...省略部分代码}
```

如上代码中为ArrayList的主要属性:

- DEFAULT_CAPACITY：默认容量，即为初始值大小
- EMPTY_ELEMENTDATA：共享的空数组，用于初始化空实例
- elementData：ArrayList内部结构，是一个Object[]类型的数组
- size：数组长度大小

##### 构造方法

如下为ArrayList的构造方法:

```
1.public ArrayList(int initialCapacity)
2.public ArrayList()
3.public ArrayList(Collection<? extends E> c){    elementData = c.toArray();    size = elementData.length;    // c.toArray might (incorrectly) not return Object[] (see 6260652)    if (elementData.getClass() != Object[].class)        elementData = Arrays.copyOf(elementData, size, Object[].class);}
```

- 1.构造方法1，表示接受指定地容量值，初始化创建数组，建议在可估算数组大小时,创建ArrayList可指定
- 2.构造方法2，是默认的构造方法，它将创建一个空数组
- 3.构造方法3，接收一个Collection的实体，将该Collection实体转换为ArrayList对象

#### 主干流程

1.添加指定元素代码如下

```
public boolean add(E e) {    ensureCapacityInternal(size + 1);  // Increments modCount!!    elementData[size++] = e;    return true;}
```

可以看到实际上只有3行代码，其流程主要如下：

##### 1.扩容 (这里便解释了，在介绍时提出的问题)：

主要源码如下

```
private void ensureCapacityInternal(int minCapacity) {    if (elementData == EMPTY_ELEMENTDATA) {        minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity);    }
    ensureExplicitCapacity(minCapacity);}
private void ensureExplicitCapacity(int minCapacity) {    modCount++;
    // overflow-conscious code    if (minCapacity - elementData.length > 0)        grow(minCapacity);}
//最大数组容量private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;
private void grow(int minCapacity) {    // overflow-conscious code    int oldCapacity = elementData.length;    int newCapacity = oldCapacity + (oldCapacity >> 1);    if (newCapacity - minCapacity < 0)        newCapacity = minCapacity;    if (newCapacity - MAX_ARRAY_SIZE > 0)        newCapacity = hugeCapacity(minCapacity);    // minCapacity is usually close to size, so this is a win:    elementData = Arrays.copyOf(elementData, newCapacity);}
```

- 第一个方法的逻辑为：判断是不是第一次添加元素，若为第一次，则设置初始化大小为默认的值10,否则使用传入的参数
- 第二个方法的逻辑为：若长度大于数组长度，则扩容
- 第三个方法的逻辑为:

> 1·扩容的大小为3/2倍原数组长度
>
> 2.若值newCapacity比传入值minCapacity还要小，则使用传入minCapacity，若newCapacity比设定的最大数组容量大，则使用最大整数值
>
> 3.实际扩容，使用了Arrays.copyof(elementData, newCapacity) (此处有两个问题 1.为啥扩容是原来的3/2倍原数组的长度? 2.调用Arrays.copyOf(elementData, newCapacity)方法具体做了什么操作? )

##### 2.赋值：将添加的值放置到size++的位置上

##### 3.返回：返回true

2.添加指定元素到指定的位置上代码如下:

```
 public void add(int index, E element) {    rangeCheckForAdd(index);
    ensureCapacityInternal(size + 1);  // Increments modCount!!    System.arraycopy(elementData, index, elementData, index + 1,                     size - index);    elementData[index] = element;    size++;}
```

其流程为:

- 1.校验下标：调用rangeCheckForAdd方法进行下标校验，不正确则会抛出IndexOutOfBoundsException异常
- 2.扩容：详见上部分中做的介绍
- 3.移动数据：将数据index后面的数据，都向后移动
- 4.赋值：将加入的值放置到index位置中
- 5.长度增加：长度增加

### 常见问题

#### 1.问题描述

在使用ArrayList比较常见的一个问题就是在遍历ArrayList的时候调用remove()方法进行元素的删除操作,从而得到意想不到的结果，本人在开发过程中也遇到过这样的问题，所以在这里提出了，希望能够帮助到大家。

#### 2.实例及分析

如下代码中，在遍历List时，调用了remove方法，删除元素a

```
//arrayList中的值为 [a,a,c,a,a]for (int i = 0; i < arrayList.size(); i++) {    if (arrayList.get(i) == "a") {        arrayList.remove(i);    }}System.out.println(arrayList);
```

- 这段代码看似解决了删除列表中所有的a元素，但是删除后得出List的结果为[a, c, a]，为什么这种方式没有达到想要的效果，其实仔细分析后会发现，在调用remove()方法时List的长度会发生变化而且元素的位置会发生移动，从而在遍历时list实际上是变化的，例如
- 当i=0时，此时list中的元素为[a,a,c,a,a],
- 但当i=1时，此时List中的元素为[a,c,a,a],元素的位置发生了移动，从而导致在遍历的过程中不能达到删除的效果

#### 3.解决方案

通过上述的分析可以看出，出现问题的原因是元素的位置发生了移动，从而导致异常的结果 方案一、逆向遍历List删除,代码如下，这种做法可行主要是因为remove()方法删除index处的元素时，是将index+1到size-1索引处的元素前移，而逆向遍历可以避免元素位置的移动

```
for (int i = arrayList.size()-1; i >=0 ; i--) {    if (arrayList.get(i) == "a") {        arrayList.remove(i);    }}System.out.println(arrayList);
```

方案二、使用迭代器中的remove方法，迭代器具体参考Iterator详解，主要代码如下(这种方式比较推荐)

```
Iterator<String> ite = arrayList.listIterator();while (ite.hasNext()){    if(ite.next() == "a")        ite.remove();}System.out.println(arrayList);
```

### 手写一个ArrayList

自己手写一个ArrayList,代码如下：

```
public class MyArrayList<T> implements Iterable<T>  {    private T[] theItems;    private int theSize;    private static final int DEAULT_CAPACITY=10;
    public MyArrayList(){        theSize=0;        ensureCapacity(DEAULT_CAPACITY);
    }
    public void add(T data){        if(size()==theItems.length){            ensureCapacity(size()*2+1);        }        theItems[size()]=data;        theSize++;    }
    public void add(int index,T data){        if(size()==theItems.length){            ensureCapacity(size()*2+1);        }        for(int i=theSize;i>index;i--){            theItems[i]=theItems[i-1];        }        theItems[index]=data;        theSize++;    }
    public T get(int index){        if(index<0|index>=size()){            throw new IndexOutOfBoundsException("index error");        }        return theItems[index];    }
    public T remove(int index){        T removeData=get(index);        for(int i=index;i<size()-1;i++){            theItems[i]=theItems[i+1];        }        theSize--;        return removeData;    }
    public int size(){        return theSize;    }
    private void ensureCapacity(int newCapacity){        if(theSize>newCapacity){            return;        }
        T[] old=theItems;        theItems= (T[]) new Object[newCapacity];        for(int i=0;i<size();i++){            theItems[i]=old[i];        }    }


    @Override    public Iterator<T> iterator() {        return null;    }
    @Override    public void forEach(Consumer<? super T> action) {
    }
    @Override    public Spliterator<T> spliterator() {        return null;    }}
```

### 总结

- 1.ArrayList是基于数组实现的，它的内存储元素的数组为 elementData;elementData的声明为：transient Object[] elementData;
- 2.ArrayList中EMPTYELEMENTDATA和DEFAULTCAPACITYEMPTY_ELEMENTDATA的使用；这两个常量，使用场景不同。前者是用在用户通过ArrayList(int initialCapacity)该构造方法直接指定初始容量为0时，后者是用户直接使用无参构造创建ArrayList时。
- 3.ArrayList默认容量为10。调用无参构造新建一个ArrayList时，它的elementData = DEFAULTCAPACITYEMPTYELEMENTDATA, 当第一次使用 add() 添加元素时，ArrayList的容量会为 10。
- 4.ArrayList的扩容计算为 newCapacity = oldCapacity + (oldCapacity >> 1);且扩容并非是无限制的，有内存限制，虚拟机限制。
- 5.ArrayList的toArray()方法和subList()方法，在源数据和子数据之间的区别；
- 6.注意扩容方法ensureCapacityInternal()。ArrayList在每次增加元素（可能是1个，也可能是一组）时，都要调用该方法来确保足够的容量。当容量不足以容纳当前的元素个数时，就设置新的容量为旧的容量的1.5倍加1，如果设置后的新容量还不够，则直接新容量设置为传入的参数（也就是所需的容量），而后用Arrays.copyof()方法将元素拷贝到新的数组。从中可以看出，当容量不够时，每次增加元素，都要将原来的元素拷贝到一个新的数组中，非常之耗时，也因此建议在事先能确定元素数量的情况下，才使用ArrayList，否则不建议使用。

# LinkedList

## 定义

实现List接口与Deque接口双向链表，实现了列表的所有操作，并且允许包括null值的所有元素，对于LinkedList定义我产生了如下疑问：

- 1.Deque接口是什么，定义了一个怎样的规范?
- 2.LinkedList是双向链表，其底层实现是怎样的,具体包含哪些操作?

下文将围绕这两个问题进行，去探寻LinkedList内部的奥秘,以下源码是基于JDK1.7.0_79。

## 结构

### 类结构

LinkedList的类的结构如下图所示:

![图片](https://mmbiz.qpic.cn/mmbiz/H9PJZVVHIW8hvf9gykJpSqODGib2JJ6dZhXxFNy2kJwUNoBnklVtnJVmbxWvG807Biaibt325NHVQPZ6PHlWLX5mA/640?wx_fmt=other&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

通过上图可以看出，LinkedList继承的类与实现的接口如下：

- `1.Collection接口`： Collection接口是所有集合类的根节点，Collection表示一种规则，所有实现了Collection接口的类遵循这种规则
- `2.List接口`： List是Collection的子接口，它是一个元素有序(按照插入的顺序维护元素顺序)、可重复、可以为null的集合
- `3.AbstractCollection类`： Collection接口的骨架实现类，最小化实现了Collection接口所需要实现的工作量
- `4.AbstractList类`： List接口的骨架实现类，最小化实现了List接口所需要实现的工作量
- `5.Cloneable接口`： 实现了该接口的类可以显示的调用Object.clone()方法，合法的对该类实例进行字段复制，如果没有实现Cloneable接口的实例上调用Obejct.clone()方法，会抛出CloneNotSupportException异常。正常情况下，实现了Cloneable接口的类会以公共方法重写Object.clone()
- `6.Serializable接口`： 实现了该接口标示了类可以被序列化和反序列化，具体的 查询序列化详解
- `7.Deque接口`： Deque定义了一个线性Collection，支持在两端插入和删除元素，Deque实际是“double ended queue(双端队列)”的简称，大多数Deque接口的实现都不会限制元素的数量，但是这个队列既支持有容量限制的实现，也支持没有容量限制的实现，比如LinkedList就是有容量限制的实现,其最大的容量为Integer.MAX_VALUE
- `8.AbstractSequentialList类`： 提供了List接口的骨干实现，最大限度地减少了实现受“连续访问”数据存储(如链表)支持的此接口所需的工作，对于随机访问数据(如数组)，应该优先使用 AbstractList，而不是使用AbstractSequentailList类

## 基础属性及构造方法

### 基础属性

```
public class LinkedList<E>    extends AbstractSequentialList<E>    implements List<E>, Deque<E>, Cloneable, java.io.Serializable{    //长度    transient int size = 0;    //指向头结点    transient Node<E> first;    //指向尾结点    transient Node<E> last;}
```

如上源码中为LinkedList中的基本属性，其中size为LinkedList的长度，first为指向头结点，last指向尾结点，Node为LinkedList的一个私有内部类，其定义如下，即定义了item(元素)，next(指向后一个元素的指针)，prev(指向前一个元素的指针)

```
private static class Node<E> {    //元素    E item;    //指向后一个元素的指针    Node<E> next;    //指向前一个元素的指针    Node<E> prev;
    Node(Node<E> prev, E element, Node<E> next) {        this.item = element;        this.next = next;        this.prev = prev;    }}
```

那么假如LinkedList中的元素为["A","B","C"],其内部的结构如下图所示

![图片](https://mmbiz.qpic.cn/mmbiz/H9PJZVVHIW8hvf9gykJpSqODGib2JJ6dZdicy5QfZk212zDpiaVbibq87F2xc6Sb2kiaClicVBOj6SHvLKb31r9yJ0ibg/640?wx_fmt=other&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

可以看出一个节点中包含三个属性，也就是上面源码中定义的属性，可以清晰的看出LinkedList底层是双向链表的实现

### 构造方法

在源码中，LinkedList主要提供了两个构造方法，

- 1.public LinkedList() ：空的构造方法，啥事情都没有做
- 2.public LinkedList(Collection c) : 将一个元素集合添加到LinkedList中

## 底层实现

在2.2.1中的LinkedList内部结构图，可以清晰的看出LinkedList双向链表的实现，下面将通过源码分析如何在双向链表中添加和删除节点的。

### 添加节点

通常我们会使用add(E e)方法添加元素，通过源码我们发现add(E e)内部主要调用了以下方法 //在链表的最后添加元素

```
void linkLast(E e) {    final Node<E> l = last;    final Node<E> newNode = new Node<>(l, e, null);    last = newNode;    if (l == null)        first = newNode;    else        l.next = newNode;    size++;    modCount++;}
```

其实通过源码可以看出添加的过程如下

- 1.记录当前末尾节点，通过构造另外一个指向末尾节点的指针l
- 2.产生新的节点：注意的是由于是添加在链表的末尾，next是为null的
- 3.last指向新的节点
- 4.这里有个判断，我的理解是判断是否为第一个元素(当l==null时，表示链表中是没有节点的)， 那么就很好理解这个判断了，如果是第一节点，则使用first指向这个节点，若不是则当前节点的next指向新增的节点
- 5.size增加 例如，在上面提到的LinkedList["A","B","C"]中添加元素“D”，过程大致如图所示

![图片](https://mmbiz.qpic.cn/mmbiz/H9PJZVVHIW8hvf9gykJpSqODGib2JJ6dZDicvSt43WcHXGZbH7CvMKTYOpcMr6xyJX6Nu2b4a84GoLrSvPztibI7g/640?wx_fmt=other&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

LinkedList中还提供如下的方法，进行添加元素，具体逻辑与linkLast方法大同小异，就不在这里一一介绍了。

### 删除节点

LinkedList中提供了两个方法删除节点，如下源码所示

```
//方法1.删除指定索引上的节点public E remove(int index) {    //检查索引是否正确    checkElementIndex(index);    //这里分为两步，第一通过索引定位到节点，第二删除节点    return unlink(node(index));}
//方法2.删除指定值的节点public boolean remove(Object o) {    //判断删除的元素是否为null    if (o == null) {        //若是null遍历删除        for (Node<E> x = first; x != null; x = x.next) {            if (x.item == null) {                unlink(x);                return true;            }        }    } else {        //若不是遍历删除         for (Node<E> x = first; x != null; x = x.next) {            if (o.equals(x.item)) {                unlink(x);                return true;            }        }    }    return false;}
```

通过源码可以看出两个方法都是通过unlink()删除，在方法一种有个方法要介绍下，就是node(index)该方法的作用就是根据下标找到对应的节点，要是本人去写这个方法肯定是遍历到index找到对应的节点，而JDK提供的方法如下所示

- 1.首先确定index的位置，是靠近first还是靠近last
- 2.若靠近first则从头开始查询，否则从尾部开始查询，可以看出这样避免极端情况的发生，也更好的利用了LinkedList双向链表的特征

```
Node<E> node(int index) {    // assert isElementIndex(index);    if (index < (size >> 1)) {        Node<E> x = first;        for (int i = 0; i < index; i++)            x = x.next;        return x;    } else {        Node<E> x = last;        for (int i = size - 1; i > index; i--)            x = x.prev;        return x;    }}
```

下面会详细介绍unlink()方法的源码,这是删除节点最核心的方法

```
E unlink(Node<E> x) {    // assert x != null;    final E element = x.item;    final Node<E> next = x.next;    final Node<E> prev = x.prev;
    //删除的是第一个节点，first向后移动    if (prev == null) {        first = next;    } else {        prev.next = next;        x.prev = null;    }
    //删除的是最后一个节点，last向前移    if (next == null) {        last = prev;    } else {        next.prev = prev;        x.next = null;    }
    x.item = null;    size--;    modCount++;    return element;}
```

- 1.获取到需要删除元素当前的值，指向它前一个节点的引用，以及指向它后一个节点的引用。
- 2.判断删除的是否为第一个节点，若是则first向后移动，若不是则将当前节点的前一个节点next指向当前节点的后一个节点
- 3.判断删除的是否为最后一个节点，若是则last向前移动，若不是则将当前节点的后一个节点的prev指向当前节点的前一个节点
- 4.将当前节点的值置为null
- 5.size减少并返回删除节点的值

至此介绍了LinkedList添加、删除元素的内部实现。

## 4.对比

在ArrList详解中讲解了ArrayList的相关的内容，下面将对ArrayList与LinkedList进行对比，主要从以下方面进行

### 4.1 相同点

- 1.接口实现：都实现了List接口，都是线性列表的实现
- 2.线程安全：都是线程不安全的

### 4.2 区别

- 1.底层实现:ArrayList内部是数组实现，而LinkedList内部实现是双向链表结构
- 2.接口实现：ArrayList实现了RandomAccess可以支持随机元素访问，而LinkedList实现了Deque可以当做队列使用
- 3.性能：新增、删除元素时ArrayList需要使用到拷贝原数组，而LinkedList只需移动指针，查找元素 ArrayList支持随机元素访问,而LinkedList只能一个节点的去遍历

### 4.3 性能比较

下面通过代码去比较下ArrayList与LinkedList在性能方面的差别，代码如下

```
public class ListPerformance {
    private static ArrayList<String> arrayList= new ArrayList<String>();
    private static LinkedList<String> linkedList = new LinkedList<String>();
    /**     * 插入数据     * @param list     * @param count     */    public static void insertElements(List<String> list, int count){        Long startTime = System.currentTimeMillis();        for (int i = 0; i < count; i++) {            list.add(String.valueOf(i));        }        Long endTime =  System.currentTimeMillis();        System.out.println("insert elements use time: " +(endTime-startTime) + " ms");    }
    /**     * 删除元素     * @param list     * @param count     */    public static void removeElements(List<String> list, int count){        Long startTime = System.currentTimeMillis();        for (int i = 0; i < count; i++) {            list.remove(0);        }        Long endTime =  System.currentTimeMillis();        System.out.println("remove elements use time: " +(endTime-startTime) + " ms");    }
    /**     * 获取元素     * @param list     * @param count     */    public static void getElements(List<String> list, int count){        Long startTime = System.currentTimeMillis();        for (int i = 0; i < count; i++) {            list.get(i);        }        Long endTime =  System.currentTimeMillis();        System.out.println("get elements use time: " +(endTime-startTime) + " ms");    }    /**     * 删除元素第二种实现     * @param list     * @param count     */    public static void removeElements2(List<String> list, int count){        Long startTime = System.currentTimeMillis();        for (int i = count-1; i > 0; i--) {            list.remove(i);        }        Long endTime =  System.currentTimeMillis();        System.out.println("remove elements use time: " +(endTime-startTime) + " ms");    }    public static void main(String[] args){        System.out.println("arrayList test");        insertElements(arrayList,100000);        getElements(arrayList,100000);        removeElements(arrayList,100000);
        System.out.println("linkedList test");        insertElements(linkedList,100000);        getElements(linkedList,100000);        removeElements(linkedList,100000);

        System.out.println("arrayList test2");        insertElements(arrayList,100000);        getElements(arrayList,100000);        removeElements2(arrayList,100000);
        System.out.println("linkedList test2");        insertElements(linkedList,100000);        getElements(linkedList,100000);        removeElements2(linkedList,100000);    }
```

结果如下图所示，可以看出

~

- 1.LinkedList下插入、删除是性能优于ArrayList，这是由于插入、删除元素时ArrayList中需要额外的开销去移动、拷贝元素(但是使用removeElements2方法所示去遍历删除是速度异常的快，这种方式的做法是从末尾开始删除，不存在移动、拷贝元素，从而速度非常快)
- 2.ArrayList在查询元素的性能上要由于LinkedList

### 自己动手写个LinkedList

自己动手实现一个这样的LinkedList：

```
 public class MyLinkList<T> implements Iterable<T> {
    private int size;    private int modeCount = 0;    private Node<T> beginMarker;    private Node<T> endMarker;
    public MyLinkList() {        doClear();    }
    private void doClear() {        size = 0;        modeCount++;        beginMarker = new Node<T>(null, null, null);        endMarker = new Node<T>(null, beginMarker, null);        beginMarker.next = endMarker;    }
    public boolean add(T data) {        Node<T> node = new Node<>(data, endMarker.prev, endMarker);        endMarker.prev.next = node;        endMarker.prev = node;        modeCount++;        size++;        return true;    }
    public T remove(int index) {        Node<T> node = getNode(index);        node.prev.next = node.next;        node.next.prev = node.prev;        size--;        modeCount--;        return node.data;    }
    public Node<T> getNode(int index) {        Node<T> p;        if (index < 0 | index >= size) {            throw new IndexOutOfBoundsException("out of index");        }        if (index < size / 2) {//从左边开始找            p = beginMarker.next;            for (int i = 0; i < index; i++) {                p = p.next;            }
        } else {//从右边开始找            p = endMarker;            for (int i = size; i > index; i--) {                p = p.prev;            }
        }        return p;    }
    public T get(int index) {
        return getNode(index).data;
    }

    @Override    public Iterator<T> iterator() {        return null;    }
    @Override    public void forEach(Consumer<? super T> action) {
    }
    @Override    public Spliterator<T> spliterator() {        return null;    }
    static class Node<T> {        private T data;        private Node<T> prev;        private Node<T> next;
        public Node(T data, Node<T> prev, Node<T> next) {            this.data = data;            this.prev = prev;            this.next = next;        }

    }}
```

# hashMap

##  HashMap 概述

Map 是 Key-Value 对映射的抽象接口，该映射不包括重复的键，即一个键对应一个值。HashMap 是 Java Collection Framework 的重要成员，也是Map族(如下图所示)中我们最为常用的一种。简单地说，HashMap 是基于哈希表的 Map 接口的实现，以 Key-Value 的形式存在，即存储的对象是 Entry (同时包含了 Key 和 Value) 。在HashMap中，其会根据hash算法来计算key-value的存储位置并进行快速存取。特别地，HashMap最多只允许一条Entry的键为Null(多条会覆盖)，但允许多条Entry的值为Null。此外，HashMap 是 Map 的一个非同步的实现。

![图片](https://mmbiz.qpic.cn/mmbiz_png/H9PJZVVHIW9h6OHVQ3VbEhxDicYQAcotEvxibuRmej2gkFZr1ygdAyHBYyHLRY6odUxLj6VdPnmSRDaMEJqWQeNA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

同样地，HashSet 也是 Java Collection Framework 的重要成员，是 Set 接口的常用实现类，但其与 HashMap 有很多相似之处。对于 HashSet 而言，其采用 Hash 算法决定元素在Set中的存储位置，这样可以保证元素的快速存取；对于 HashMap 而言，其将 key-value 当成一个整体(Entry 对象)来处理，其也采用同样的 Hash 算法去决定 key-value 的存储位置从而保证键值对的快速存取。虽然 HashMap 和 HashSet 实现的接口规范不同，但是它们底层的 Hash 存储机制完全相同。实际上，HashSet 本身就是在 HashMap 的基础上实现的。因此，通过对 HashMap 的数据结构、实现原理、源码实现三个方面了解，我们不但可以进一步掌握其底层的 Hash 存储机制，也有助于对 HashSet 的了解。

必须指出的是，虽然容器号称存储的是 Java 对象，但实际上并不会真正将 Java 对象放入容器中，只是在容器中保留这些对象的引用。也就是说，Java 容器实际上包含的是引用变量，而这些引用变量指向了我们要实际保存的 Java 对象。

当我们执行下面的操作时：

```
HashMap<String, Integer> map = new HashMap<String, Integer>();map.put("语文", 1);map.put("数学", 2);map.put("英语", 3);map.put("历史", 4);map.put("政治", 5);map.put("地理", 6);map.put("生物", 7);map.put("化学", 8);for(Entry<String, Integer> entry : map.entrySet()) {    System.out.println(entry.getKey() + ": " + entry.getValue());}
```

运行结果是

> 政治: 5
>
> 生物: 7
>
> 历史: 4
>
> 数学: 2
>
> 化学: 8
>
> 语文: 1
>
> 英语: 3
>
> 地理: 6

发生了什么呢？下面是一个大致的结构，希望我们对HashMap的结构有一个感性的认识：

![图片](https://mmbiz.qpic.cn/mmbiz_png/H9PJZVVHIW9h6OHVQ3VbEhxDicYQAcotE3icOqhNzHZO1dnYqaOJGNKB2Z4Vnv3ELiaYvHz2QA64wwHQIgTsCBvKQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

在官方文档中是这样描述HashMap的：

> Hash table based implementation of the Map interface. This implementation provides all of the optional map operations, and permits null values and the null key. (The HashMap class is roughly equivalent to Hashtable, except that it is unsynchronized and permits nulls.) This class makes no guarantees as to the order of the map; in particular, it does not guarantee that the order will remain constant over time.

几个关键的信息：基于Map接口实现、允许null键/值、非同步、不保证有序(比如插入的顺序)、也不保证序不随时间变化。

## 两个重要的参数

在HashMap中有两个很重要的参数，容量(Capacity)和负载因子(Load factor)

> - 
>
>   Initial capacity The capacity is the number of buckets in the hash table, The initial capacity is simply the capacity at the time the hash table is created.
>
>   
>
> - 
>
>   Load factor The load factor is a measure of how full the hash table is allowed to get before its capacity is automatically increased.
>
>   

简单的说，Capacity就是buckets的数目，Load factor就是buckets填满程度的最大比例。如果对迭代性能要求很高的话不要把capacity设置过大，也不要把load factor设置过小。当bucket填充的数目（即hashmap中元素的个数）大于capacity*load factor时就需要调整buckets的数目为当前的2倍。

## put函数的实现

put函数大致的思路为：

- 对key的hashCode()做hash，然后再计算index;
- 如果没碰撞直接放到bucket里；
- 如果碰撞了，以链表的形式存在buckets后；
- 如果碰撞导致链表过长(大于等于TREEIFY_THRESHOLD)，就把链表转换成红黑树；
- 如果节点已经存在就替换old value(保证key的唯一性)
- 如果bucket满了(超过load factor*current capacity)，就要resize。 具体代码的实现如下：

```
public V put(K key, V value) {    // 对key的hashCode()做hash    return putVal(hash(key), key, value, false, true);}final V putVal(int hash, K key, V value, boolean onlyIfAbsent,               boolean evict) {    Node<K,V>[] tab; Node<K,V> p; int n, i;    // tab为空则创建    if ((tab = table) == null || (n = tab.length) == 0)        n = (tab = resize()).length;    // 计算index，并对null做处理    if ((p = tab[i = (n - 1) & hash]) == null)        tab[i] = newNode(hash, key, value, null);    else {        Node<K,V> e; K k;        // 节点存在        if (p.hash == hash &&            ((k = p.key) == key || (key != null && key.equals(k))))            e = p;        // 该链为树        else if (p instanceof TreeNode)            e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);        // 该链为链表        else {            for (int binCount = 0; ; ++binCount) {                if ((e = p.next) == null) {                    p.next = newNode(hash, key, value, null);                    if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st                        treeifyBin(tab, hash);                    break;                }                if (e.hash == hash &&                    ((k = e.key) == key || (key != null && key.equals(k))))                    break;                p = e;            }        }        // 写入        if (e != null) { // existing mapping for key            V oldValue = e.value;            if (!onlyIfAbsent || oldValue == null)                e.value = value;            afterNodeAccess(e);            return oldValue;        }    }    ++modCount;    // 超过load factor*current capacity，resize    if (++size > threshold)        resize();    afterNodeInsertion(evict);    return null;}
```

## get函数的实现

在理解了put之后，get就很简单了。大致思路如下：

- bucket里的第一个节点，直接命中；
- 如果有冲突，则通过key.equals(k)去查找对应的entry
- 若为树，则在树中通过key.equals(k)查找，O(logn)；
- 若为链表，则在链表中通过key.equals(k)查找，O(n)。 具体代码的实现如下：

```
public V get(Object key) {    Node<K,V> e;    return (e = getNode(hash(key), key)) == null ? null : e.value;}final Node<K,V> getNode(int hash, Object key) {    Node<K,V>[] tab; Node<K,V> first, e; int n; K k;    if ((tab = table) != null && (n = tab.length) > 0 &&        (first = tab[(n - 1) & hash]) != null) {        // 直接命中        if (first.hash == hash && // always check first node            ((k = first.key) == key || (key != null && key.equals(k))))            return first;        // 未命中        if ((e = first.next) != null) {            // 在树中get            if (first instanceof TreeNode)                return ((TreeNode<K,V>)first).getTreeNode(hash, key);            // 在链表中get            do {                if (e.hash == hash &&                    ((k = e.key) == key || (key != null && key.equals(k))))                    return e;            } while ((e = e.next) != null);        }    }    return null;}
```

## hash函数的实现

在get和put的过程中，计算下标时，先对hashCode进行hash操作，然后再通过hash值进一步计算下标，如下图所示：

![图片](https://mmbiz.qpic.cn/mmbiz_png/H9PJZVVHIW9h6OHVQ3VbEhxDicYQAcotEHicjDsUrvJibvTCxl1q1VNqm8fvJSmY0boPZAMk7MAbhbFGq0mZs8kag/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

在对hashCode()计算hash时具体实现是这样的：

```
static final int hash(Object key) {    int h;    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);}
```

在设计hash函数时，因为目前的table长度n为2的幂，而计算下标的时候，是这样实现的(使用&位操作，而非%求余)：

```
(n - 1) & hash
```

设计者认为这方法很容易发生碰撞。为什么这么说呢？不妨思考一下，在n - 1为15(0x1111)时，其实散列真正生效的只是低4bit的有效位，当然容易碰撞了。

因此，设计者想了一个顾全大局的方法(综合考虑了速度、作用、质量)，就是把高16bit和低16bit异或了一下。设计者还解释到因为现在大多数的hashCode的分布已经很不错了，就算是发生了碰撞也用O(logn)的tree去做了。仅仅异或一下，既减少了系统的开销，也不会造成的因为高位没有参与下标的计算(table长度比较小时)，从而引起的碰撞。

如果还是产生了频繁的碰撞，会发生什么问题呢？作者注释说，他们使用树来处理频繁的碰撞(we use trees to handle large sets of collisions in bins)，在JEP-180中，描述了这个问题：

\>

> Improve the performance of java.util.HashMap under high hash-collision conditions by using balanced trees rather than linked lists to store map entries. Implement the same improvement in the LinkedHashMap class.

之前已经提过，在获取HashMap的元素时，基本分两步：

- 首先根据hashCode()做hash，然后确定bucket的index；
- 如果bucket的节点的key不是我们需要的，则通过keys.equals()在链中找。

在Java 8之前的实现中是用链表解决冲突的，在产生碰撞的情况下，进行get时，两步的时间复杂度是O(1)+O(n)。因此，当碰撞很厉害的时候n很大，O(n)的速度显然是影响速度的。

因此在Java 8中，利用红黑树替换链表，这样复杂度就变成了O(1)+O(logn)了，这样在n很大的时候，能够比较理想的解决这个问题，在Java 8：HashMap的性能提升一文中有性能测试的结果。

## RESIZE的实现

当put时，如果发现目前的bucket占用程度已经超过了Load Factor所希望的比例，那么就会发生resize。在resize的过程，简单的说就是把bucket扩充为2倍，之后重新计算index，把节点再放到新的bucket中。resize的注释是这样描述的：

\>

> Initializes or doubles table size. If null, allocates in accord with initial capacity target held in field threshold. Otherwise, because we are using power-of-two expansion, the elements from each bin must either stay at same index, or move with a power of two offset in the new table.

大致意思就是说，当超过限制的时候会resize，然而又因为我们使用的是2次幂的扩展(指长度扩为原来2倍)，所以，元素的位置要么是在原位置，要么是在原位置再移动2次幂的位置。

怎么理解呢？例如我们从16扩展为32时，具体的变化如下所示：

![图片](https://mmbiz.qpic.cn/mmbiz_png/H9PJZVVHIW9h6OHVQ3VbEhxDicYQAcotEeZQad4qIw1YrGlGkun5lYl7On5xsGb0aNyniaZa9W3TXiaN79HIxxfKg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

因此元素在重新计算hash之后，因为n变为2倍，那么n-1的mask范围在高位多1bit(红色)，因此新的index就会发生这样的变化：

![图片](https://mmbiz.qpic.cn/mmbiz_png/H9PJZVVHIW9h6OHVQ3VbEhxDicYQAcotEgJ5QBooeC4riadpldsktVxdKib8L3vNiavJTDFtcdWEAUc52AfvGgu2bw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

因此，我们在扩充HashMap的时候，不需要重新计算hash，只需要看看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成“原索引+oldCap”。可以看看下图为16扩充为32的resize示意图：

![图片](https://mmbiz.qpic.cn/mmbiz_png/H9PJZVVHIW9h6OHVQ3VbEhxDicYQAcotEddxy2kN5erqYQw1jAFML0996ksxcPdt1GicxHthh1ia8kYltOOicwWLDg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

这个设计确实非常的巧妙，既省去了重新计算hash值的时间，而且同时，由于新增的1bit是0还是1可以认为是随机的，因此resize的过程，均匀的把之前的冲突的节点分散到新的bucket了。

下面是代码的具体实现：

```
final Node<K,V>[] resize() {    Node<K,V>[] oldTab = table;    int oldCap = (oldTab == null) ? 0 : oldTab.length;    int oldThr = threshold;    int newCap, newThr = 0;    if (oldCap > 0) {        // 超过最大值就不再扩充了，就只好随你碰撞去吧        if (oldCap >= MAXIMUM_CAPACITY) {            threshold = Integer.MAX_VALUE;            return oldTab;        }        // 没超过最大值，就扩充为原来的2倍        else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&                 oldCap >= DEFAULT_INITIAL_CAPACITY)            newThr = oldThr << 1; // double threshold    }    else if (oldThr > 0) // initial capacity was placed in threshold        newCap = oldThr;    else {               // zero initial threshold signifies using defaults        newCap = DEFAULT_INITIAL_CAPACITY;        newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);    }    // 计算新的resize上限    if (newThr == 0) {        float ft = (float)newCap * loadFactor;        newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ?                  (int)ft : Integer.MAX_VALUE);    }    threshold = newThr;    @SuppressWarnings({"rawtypes","unchecked"})        Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];    table = newTab;    if (oldTab != null) {        // 把每个bucket都移动到新的buckets中        for (int j = 0; j < oldCap; ++j) {            Node<K,V> e;            if ((e = oldTab[j]) != null) {                oldTab[j] = null;                if (e.next == null)                    newTab[e.hash & (newCap - 1)] = e;                else if (e instanceof TreeNode)                    ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);                else { // preserve order                    Node<K,V> loHead = null, loTail = null;                    Node<K,V> hiHead = null, hiTail = null;                    Node<K,V> next;                    do {                        next = e.next;                        // 原索引                        if ((e.hash & oldCap) == 0) {                            if (loTail == null)                                loHead = e;                            else                                loTail.next = e;                            loTail = e;                        }                        // 原索引+oldCap                        else {                            if (hiTail == null)                                hiHead = e;                            else                                hiTail.next = e;                            hiTail = e;                        }                    } while ((e = next) != null);                    // 原索引放到bucket里                    if (loTail != null) {                        loTail.next = null;                        newTab[j] = loHead;                    }                    // 原索引+oldCap放到bucket里                    if (hiTail != null) {                        hiTail.next = null;                        newTab[j + oldCap] = hiHead;                    }                }            }        }    }    return newTab;}
```

　

## 总结

我们现在可以回答开始的几个问题，加深对HashMap的理解：

### 1. 什么时候会使用HashMap？他有什么特点？

是基于Map接口的实现，存储键值对时，它可以接收null的键值，是非同步的，HashMap存储着Entry(hash, key, value, next)对象。

### 2. 你知道HashMap的工作原理吗？

通过hash的方法，通过put和get存储和获取对象。存储对象时，我们将K/V传给put方法时，它调用hashCode计算hash从而得到bucket位置，进一步存储，HashMap会根据当前bucket的占用情况自动调整容量(超过Load Facotr则resize为原来的2倍)。获取对象时，我们将K传给get，它调用hashCode计算hash从而得到bucket位置，并进一步调用equals()方法确定键值对。如果发生碰撞的时候，Hashmap通过链表将产生碰撞冲突的元素组织起来，在Java 8中，如果一个bucket中碰撞冲突的元素超过某个限制(默认是8)，则使用红黑树来替换链表，从而提高速度。

### 3. 你知道get和put的原理吗？equals()和hashCode()的都有什么作用？

通过对key的hashCode()进行hashing，并计算下标( n-1 & hash)，从而获得buckets的位置。如果产生碰撞，则利用key.equals()方法去链表或树中去查找对应的节点

### 4. 你知道hash的实现吗？为什么要这样实现？

在Java 1.8的实现中，是通过hashCode()的高16位异或低16位实现的：(h = k.hashCode()) ^ (h >>> 16)，主要是从速度、功效、质量来考虑的，这么做可以在bucket的n比较小的时候，也能保证考虑到高低bit都参与到hash的计算中，同时不会有太大的开销。

### 5. 如果HashMap的大小超过了负载因子(load factor)定义的容量，怎么办？

如果超过了负载因子(默认0.75)，则会重新resize一个原来长度两倍的HashMap，并且重新调用hash方法。

## 自己动手写一个HashMap

实现的过程如下：

```
 package com.forezp.datastruct.lqbz;
/** * Created by forezp on 2018/3/20. */public class MyHashMap<K, V> {

    private Node[] theNodes;    private int size;    private int THE_NODES_SIZE = 16;
    public MyHashMap() {        theNodes = new Node[THE_NODES_SIZE];        size = 0;    }
    public void put(K key, V value) {        Node node = findNode(key);        if (node == null) {            node = new Node(key.hashCode(), key, value, null);            theNodes[findItemIndex(key)] = node;        } else {            while (node.next != null) {                node = node.next;            }            node.next = new Node(key.hashCode(), key, value, null);        }        size++;    }
    public V get(K key) {        Node<K, V> node = theNodes[findItemIndex(key)];        if (node == null) {            return null;        }        while (node.next != null) {            if (node != null && node.hash != key.hashCode()) {                node = node.next;            } else {                if (node != null) {                    return node.value;                }            }        }        return null;
    }
    private Node findNode(K key) {        return theNodes[findItemIndex(key)];    }
    private int findItemIndex(K key) {        int hashCode = key.hashCode();        int nodeIndex = hashCode % THE_NODES_SIZE;        return nodeIndex;    }
    class Node<K, V> {        public int hash;        public K key;        public V value;        public Node next;
        public Node(int hash, K key, V value, Node next) {            this.hash = hash;            this.key = key;            this.value = value;            this.next = next;        }    }

}
```

# hashSet

## HashSet 的实现

对于 HashSet 而言，它是基于 HashMap 实现的，HashSet 底层采用 HashMap 来保存所有元素，因此 HashSet 的实现比较简单，查看 HashSet 的源代码，可以看到如下代码：

```
public class HashSet<E>    extends AbstractSet<E>    implements Set<E>, Cloneable, java.io.Serializable   {    // 使用 HashMap 的 key 保存 HashSet 中所有元素   private transient HashMap<E,Object> map;    // 定义一个虚拟的 Object 对象作为 HashMap 的 value    private static final Object PRESENT = new Object();    ...    // 初始化 HashSet，底层会初始化一个 HashMap    public HashSet()    {        map = new HashMap<E,Object>();    }    // 以指定的 initialCapacity、loadFactor 创建 HashSet    // 其实就是以相应的参数创建 HashMap    public HashSet(int initialCapacity, float loadFactor)    {        map = new HashMap<E,Object>(initialCapacity, loadFactor);    }    public HashSet(int initialCapacity)    {        map = new HashMap<E,Object>(initialCapacity);    }    HashSet(int initialCapacity, float loadFactor, boolean dummy)    {        map = new LinkedHashMap<E,Object>(initialCapacity            , loadFactor);    }    // 调用 map 的 keySet 来返回所有的 key    public Iterator<E> iterator()    {        return map.keySet().iterator();    }    // 调用 HashMap 的 size() 方法返回 Entry 的数量，就得到该 Set 里元素的个数   public int size()    {        return map.size();    }    // 调用 HashMap 的 isEmpty() 判断该 HashSet 是否为空，   // 当 HashMap 为空时，对应的 HashSet 也为空   public boolean isEmpty()    {        return map.isEmpty();    }    // 调用 HashMap 的 containsKey 判断是否包含指定 key    //HashSet 的所有元素就是通过 HashMap 的 key 来保存的   public boolean contains(Object o)    {        return map.containsKey(o);    }    // 将指定元素放入 HashSet 中，也就是将该元素作为 key 放入 HashMap    public boolean add(E e)    {        return map.put(e, PRESENT) == null;    }    // 调用 HashMap 的 remove 方法删除指定 Entry，也就删除了 HashSet 中对应的元素   public boolean remove(Object o)    {        return map.remove(o)==PRESENT;    }    // 调用 Map 的 clear 方法清空所有 Entry，也就清空了 HashSet 中所有元素   public void clear()    {        map.clear();    }    ...   
```

由上面源程序可以看出，HashSet 的实现其实非常简单，它只是封装了一个 HashMap 对象来存储所有的集合元素，所有放入 HashSet 中的集合元素实际上由 HashMap 的 key 来保存，而 HashMap 的 value 则存储了一个 PRESENT，它是一个静态的 Object 对象。

HashSet 的绝大部分方法都是通过调用 HashMap 的方法来实现的，因此 HashSet 和 HashMap 两个集合在实现本质上是相同的。 掌握上面理论知识之后，接下来看一个示例程序，测试一下自己是否真正掌握了 HashMap 和 HashSet 集合的功能。

```
 class Name  {      private String first;       private String last;   
    public Name(String first, String last)       {           this.first = first;           this.last = last;       }   
    public boolean equals(Object o)       {           if (this == o)           {               return true;           }   
    if (o.getClass() == Name.class)           {               Name n = (Name)o;               return n.first.equals(first)                   && n.last.equals(last);           }           return false;       }   }  
public class HashSetTest  {      public static void main(String[] args)      {           Set<Name> s = new HashSet<Name>();          s.add(new Name("abc", "123"));          System.out.println(              s.contains(new Name("abc", "123")));      }  }   
```

上面程序中向 HashSet 里添加了一个 new Name("abc", "123") 对象之后，立即通过程序判断该 HashSet 是否包含一个 new Name("abc", "123") 对象。粗看上去，很容易以为该程序会输出 true。

实际运行上面程序将看到程序输出 false，这是因为 HashSet 判断两个对象相等的标准除了要求通过 equals() 方法比较返回 true 之外，还要求两个对象的 hashCode() 返回值相等。因为在判断key是否存在Hashmap中，首先判断的是hashCode ,而上面程序没有重写 Name 类的 hashCode() 方法，两个 Name 对象的 hashCode() 返回值并不相同，因此 HashSet 会把它们当成 2 个对象处理，因此程序返回 false。

由此可见，当我们试图把某个类的对象当成 HashMap 的 key，或试图将这个类的对象放入 HashSet 中保存时，重写该类的 equals(Object obj) 方法和 hashCode() 方法很重要，而且这两个方法的返回值必须保持一致：当该类的两个的 hashCode() 返回值相同时，它们通过 equals() 方法比较也应该返回 true。通常来说，所有参与计算 hashCode() 返回值的关键属性，都应该用于作为 equals() 比较的标准。 如下程序就正确重写了 Name 类的 hashCode() 和 equals() 方法，程序如下：

```
class Name   {       private String first;      private String last;      public Name(String first, String last)      {           this.first = first;           this.last = last;       }       // 根据 first 判断两个 Name 是否相等      public boolean equals(Object o)       {           if (this == o)           {               return true;           }           if (o.getClass() == Name.class)           {               Name n = (Name)o;               return n.first.equals(first);           }           return false;       }   
    // 根据 first 计算 Name 对象的 hashCode() 返回值      public int hashCode()       {           return first.hashCode();       }  
    public String toString()       {           return "Name[first=" + first + ", last=" + last + "]";       }    }   
 public class HashSetTest2    {       public static void main(String[] args)       {           HashSet<Name> set = new HashSet<Name>();           set.add(new Name("abc" , "123"));           set.add(new Name("abc" , "456"));           System.out.println(set);       }   }  
```

上面程序中提供了一个 Name 类，该 Name 类重写了 equals() 和 toString() 两个方法，这两个方法都是根据 Name 类的 first 实例变量来判断的，当两个 Name 对象的 first 实例变量相等时，这两个 Name 对象的 hashCode() 返回值也相同，通过 equals() 比较也会返回 true。

程序主方法先将第一个 Name 对象添加到 HashSet 中，该 Name 对象的 first 实例变量值为"abc"，接着程序再次试图将一个 first 为"abc"的 Name 对象添加到 HashSet 中，很明显，此时没法将新的 Name 对象添加到该 HashSet 中，因为此处试图添加的 Name 对象的 first 也是" abc"，HashSet 会判断此处新增的 Name 对象与原有的 Name 对象相同，因此无法添加进入，程序在①号代码处输出 set 集合时将看到该集合里只包含一个 Name 对象，就是第一个、last 为"123"的 Name 对象。



# bitSet

## 适用场景：整数，无重复；

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/H9PJZVVHIW9qCqlHPBDEso3BA5LbaIiblBibl78BqVeBBEyYvQN7SJiaBQ8qGYgic2dvJtFreFOhKd5iaD2PwOunbNw/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

## Bitset 基础

Bitset，也就是位图，由于可以用非常紧凑的格式来表示给定范围的连续数据而经常出现在各种算法设计中。上面的图来自c++库中bitset的一张图。

基本原理是，用1位来表示一个数据是否出现过，0为没有出现过，1表示出现过。使用用的时候既可根据某一个是否为0表示此数是否出现过。

一个1G的空间，有 8102410241024=8.5810^9bit，也就是可以表示85亿个不同的数。

常见的应用是那些需要对海量数据进行一些统计工作的时候，比如日志分析等。

面试题中也常出现，比如：统计40亿个数据中没有出现的数据，将40亿个不同数据进行排序等。

又如：现在有1千万个随机数，随机数的范围在1到1亿之间。现在要求写出一种算法，将1到1亿之间没有在随机数中的数求出来(百度)。

programming pearls上也有一个关于使用bitset来查找电话号码的题目。

Bitmap的常见扩展，是用2位或者更多为来表示此数字的更多信息，比如出现了多少次等。

## Java中Bitset的实现

Bitset这种结构虽然简单，实现的时候也有一些细节需要主要。其中的关键是一些位操作，比如如何将指定位进行反转、设置、查询指定位的状态（0或者1）等。 本文，分析一下java中bitset的实现，抛砖引玉，希望给那些需要自己设计位图结构的需要的程序员有所启发。

Bitmap的基本操作有：

- 初始化一个bitset，指定大小。
- 清空bitset。
- 反转某一指定位。
- 设置某一指定位。
- 获取某一位的状态。
- 当前bitset的bit总位数。

## 使用场景

常见的应用是那些需要对海量数据进行一些统计工作的时候，比如日志分析、用户数统计等等

如统计40亿个数据中没有出现的数据，将40亿个不同数据进行排序等。

现在有1千万个随机数，随机数的范围在1到1亿之间。现在要求写出一种算法，将1到1亿之间没有在随机数中的数求出来

## 代码示例

```
package util;

import java.util.Arrays;
import java.util.BitSet;

public class BitSetDemo {
    /**
     * 求一个字符串包含的char     *
     */
    public static void containChars(String str) {
        BitSet used = new BitSet();
        for (int i = 0; i < str.length(); i++) used.set(str.charAt(i)); // set bit for char
        StringBuilder sb = new StringBuilder();
        sb.append("[");
        int size = used.size();
        System.out.println(size);
        for (int i = 0; i < size; i++) {
            if (used.get(i)) {
                sb.append((char) i);
            }
        }
        sb.append("]");
        System.out.println(sb.toString());
    }

    /**
     * 求素数 有无限个。一个大于1的自然数，如果除了1和它本身外，不能被其他自然数整除(除0以外）的数称之为素数(质数） 否则称为合数
     */
    public static void computePrime() {
        BitSet sieve = new BitSet(1024);
        int size = sieve.size();
        for (int i = 2; i < size; i++) sieve.set(i);
        int finalBit = (int) Math.sqrt(sieve.size());
        for (int i = 2; i < finalBit; i++) if (sieve.get(i)) for (int j = 2 * i; j < size; j += i) sieve.clear(j);
        int counter = 0;
        for (int i = 1; i < size; i++) {
            if (sieve.get(i)) {
                System.out.printf("%5d", i);
                if (++counter % 15 == 0) System.out.println();
            }
        }
        System.out.println();
    }

    /**
     * 进行数字排序
     */
    public static void sortArray() {
        int[] array = new int[]{423, 700, 9999, 2323, 356, 6400, 1, 2, 3, 2, 2, 2, 2};
        BitSet bitSet = new BitSet(2 << 13);        // 虽然可以自动扩容，但尽量在构造时指定估算大小,默认为64        System.out.println("BitSet size: " + bitSet.size());
        for (int i = 0; i < array.length; i++) {
            bitSet.set(array[i]);
        }        //剔除重复数字后的元素个数        int bitLen=bitSet.cardinality();
        //进行排序，即把bit为true的元素复制到另一个数组        int[] orderedArray = new int[bitLen];        int k = 0;        for (int i = bitSet.nextSetBit(0); i >= 0; i = bitSet.nextSetBit(i + 1)) {            orderedArray[k++] = i;        }
        System.out.println("After ordering: ");
        for (int i = 0; i < bitLen; i++) {
            System.out.print(orderedArray[i] + "\t");
        }
        System.out.println("iterate over the true bits in a BitSet");        //或直接迭代BitSet中bit为true的元素iterate over the true bits in a BitSet        for (int i = bitSet.nextSetBit(0); i >= 0; i = bitSet.nextSetBit(i + 1)) {            System.out.print(i+"\t");        }        System.out.println("---------------------------");    }
        /**     * 将BitSet对象转化为ByteArray     * @param bitSet     * @return     */public static byte[] bitSet2ByteArray
        (BitSet bitSet){
            byte[] bytes = new byte[bitSet.size() / 8];
            for (int i = 0; i < bitSet.size(); i++) {
                int index = i / 8;
                int offset = 7 - i % 8;
                bytes[index] |= (bitSet.get(i) ? 1 : 0) << offset;
            }
            return bytes;
        }
        /**     * 将ByteArray对象转化为BitSet     * @param bytes     * @return     */public static BitSet byteArray2BitSet (
        byte[] bytes){
            BitSet bitSet = new BitSet(bytes.length * 8);
            int index = 0;
            for (int i = 0; i < bytes.length; i++) {
                for (int j = 7; j >= 0; j--) {
                    bitSet.set(index++, (bytes[i] & (1 << j)) >> j == 1 ? true : false);
                }
            }
            return bitSet;
        }
        /**     * 简单使用示例     */public static void simpleExample () {
            String names[] = {"Java", "Source", "and", "Support"};
            BitSet bits = new BitSet();
            for (int i = 0, n = names.length; i < n; i++) {
                if ((names[i].length() % 2) == 0) {
                    bits.set(i);
                }
            }
            System.out.println(bits);
            System.out.println("Size : " + bits.size());
            System.out.println("Length: " + bits.length());
            for (int i = 0, n = names.length; i < n; i++) {
                if (!bits.get(i)) {
                    System.out.println(names[i] + " is odd");
                }
            }
            BitSet bites = new BitSet();
            bites.set(0);
            bites.set(1);
            bites.set(2);
            bites.set(3);
            bites.andNot(bits);
            System.out.println(bites);
        }
        public static void main (String args[])
        {        //BitSet使用示例 
            BitSetDemo.containChars("How do you do? 你好呀");
            BitSetDemo.computePrime();
            BitSetDemo.sortArray();
            BitSetDemo.simpleExample();

            //BitSet与Byte数组互转示例
            BitSet bitSet = new BitSet();
            bitSet.set(3, true);
            bitSet.set(98, true);
            System.out.println(bitSet.size() + "," + bitSet.cardinality());        //将BitSet对象转成byte数组        byte[] bytes = BitSetDemo.bitSet2ByteArray(bitSet);        System.out.println(Arrays.toString(bytes));
            //在将byte数组转回来 
            bitSet = BitSetDemo.byteArray2BitSet(bytes);
            System.out.println(bitSet.size() + "," + bitSet.cardinality());
            System.out.println(bitSet.get(3));
            System.out.println(bitSet.get(98));
            for (int i = bitSet.nextSetBit(0); i >= 0; i = bitSet.nextSetBit(i + 1)) {
                System.out.print(i + "\t");
            }
        }
    }
```





# hashMap的问题
作者：java后端技术全栈
链接：https://zhuanlan.zhihu.com/p/380375038
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

1、说说HashMap 底层数据结构是怎样的？
HashMap 底层是 hash 数组和单向链表实现，jdk8后采用数组+链表+红黑树的数据结构。
2、说说HashMap 的工作原理
如果第一题没问，直接问原理，那就必须把HashMap的数据结构说清楚。HashMap 底层是 hash 数组和单向链表实现，JDK8后采用数组+链表+红黑树的数据结构。我们通过put和get存储和获取对象。当我们给put()方法传递键和值时，先对键做一个hashCode()的计算来得到它在bucket数组中的位置来存储Entry对象。当获取对象时，通过get获取到bucket的位置，再通过键对象的equals()方法找到正确的键值对，然后在返回值对象。
3、使用HashMap时，当两个对象的 hashCode 相同怎么办？
因为HashCode 相同，不一定就是相等的（equals方法比较），所以两个对象所在数组的下标相同，"碰撞"就此发生。又因为 HashMap 使用链表存储对象，这个 Node 会存储到链表中。
4、HashMap 的哈希函数怎么设计的吗？
hash 函数是先拿到通过 key 的 hashCode ，是 32 位的 int 值，然后让 hashCode 的高 16 位和低 16 位进行异或操作。两个好处：一定要尽可能降低 hash 碰撞，越分散越好；算法一定要尽可能高效，因为这是高频操作, 因此采用位运算；
5、HashMap遍历方法有几种？
Iterator 迭代器最常见的使用方式，可同时得到 key、value 值使用 foreach 方式（JDK1.8 才有）通过 key 的 set 集合遍历
6、为什么采用 hashcode 的高 16 位和低 16 位异或能降低 hash 碰撞？
因为 key.hashCode()函数调用的是 key 键值类型自带的哈希函数，返回 int 型散列值。int 值范围为**-2147483648~2147483647**，前后加起来大概 40 亿的映射空间。只要哈希函数映射得比较均匀松散，一般应用是很难出现碰撞的。但问题是一个 40 亿长度的数组，内存是放不下的。设想，如果 HashMap 数组的初始大小才 16，用之前需要对数组的长度取模运算，得到的余数才能用来访问数组下标。
7、解决hash冲突的有几种方法？
1、再哈希法：如果hash出的index已经有值，就再hash，不行继续hash，直至找到空的index位置，要相信瞎猫总能碰上死耗子。这个办法最容易想到。但有2个缺点：比较浪费空间，消耗效率。根本原因还是数组的长度是固定不变的，不断hash找出空的index，可能越界，这时就要创建新数组，而老数组的数据也需要迁移。随着数组越来越大，消耗不可小觑。get不到，或者说get算法复杂。进是进去了，想出来就没那么容易了。2、开放地址方法：如果hash出的index已经有值，通过算法在它前面或后面的若干位置寻找空位，这个和再hash算法差别不大。3、建立公共溢出区： 把冲突的hash值放到另外一块溢出区。4、链式地址法： 把产生hash冲突的hash值以链表形式存储在index位置上。HashMap用的就是该方法。优点是不需要另外开辟新空间，也不会丢失数据，寻址也比较简单。但是随着hash链越来越长，寻址也是更加耗时。好的hash算法就是要让链尽量短，最好一个index上只有一个值。也就是尽可能地保证散列地址分布均匀，同时要计算简单。
8、为什么要用异或运算符？
保证了对象的 hashCode 的 32 位值只要有一位发生改变，整个 hash() 返回值就会改变。尽可能的减少碰撞。
9、HashMap 的 table 的容量如何确定？
①、table 数组大小是由 capacity 这个参数确定的，默认是16，也可以构造时传入，最大限制是1<<30；②、loadFactor 是装载因子，主要目的是用来确认table 数组是否需要动态扩展，默认值是0.75，比如table 数组大小为 16，装载因子为 0.75 时，threshold 就是12，当 table 的实际大小超过 12 时，table就需要动态扩容；③、扩容时，调用 resize() 方法，将 table 长度变为原来的两倍（注意是 table 长度，而不是 threshold）；④、如果数据很大的情况下，扩展时将会带来性能的损失，在性能要求很高的地方，这种损失很可能很致命。
10、请解释一下HashMap的参数loadFactor，它的作用是什么
loadFactor表示HashMap的拥挤程度，影响hash操作到同一个数组位置的概率。默认loadFactor等于0.75，当HashMap里面容纳的元素已经达到HashMap数组长度的75%时，表示HashMap太挤了，需要扩容，在HashMap的构造器中可以定制loadFactor。
11、说说HashMap中put方法的过程由于JDK版本中HashMap设计上存在差异，这里说说JDK7和JDK8中的区别：具体put流程，请参照下图进行回答：
12、当链表长度 >= 8时，为什么要将链表转换成红黑树？
因为红黑树的平均查找长度是log(n)，长度为8的时候，平均查找长度为3，如果继续使用链表，平均查找长度为8/2=4，所以，当链表长度 >= 8时 ，有必要将链表转换成红黑树。
13、new HashMap(18);此时HashMap初始容量为多少？
容量为32。在HashMap中有个静态方法tableSizeFor ，tableSizeFor方法保证函数返回值是大于等于给定参数initialCapacity最小的2的幂次方的数值 。static final int tableSizeFor(int cap) {
  int n = cap - 1;
  n |= n >>> 1;
  n |= n >>> 2;
  n |= n >>> 4;
  n |= n >>> 8;
  n |= n >>> 16;
  return (n = MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;
  }
14、说说resize扩容的过程
创建一个新的数组，其容量为旧数组的两倍，并重新计算旧数组中结点的存储位置。结点在新数组中的位置只有两种，原下标位置或原下标+旧数组的大小。
15、说说hashMap中get是如何实现的？
对key的hashCode进行hash值计算，与运算计算下标获取bucket位置，如果在桶的首位上就可以找到就直接返回，否则在树中找或者链表中遍历找，如果有hash冲突，则利用equals方法去遍历链表查找节点。
16、拉链法导致的链表过深问题为什么不用二叉查找树代替，而选择红黑树？
为什么不一直使用红黑树？之所以选择红黑树是为了解决二叉查找树的缺陷，二叉查找树在特殊情况下会变成一条线性结构（这就跟原来使用链表结构一样了，造成很深的问题），遍历查找会非常慢。而红黑树在插入新数据后可能需要通过左旋，右旋、变色这些操作来保持平衡，引入红黑树就是为了查找数据快，解决链表查询深度的问题，我们知道红黑树属于平衡二叉树，但是为了保持“平衡”是需要付出代价的，但是该代价所损耗的资源要比遍历线性链表要少，所以当长度大于8的时候，会使用红黑树，如果链表长度很短的话，根本不需要引入红黑树，引入反而会慢。
17、说说你对红黑树的了解
红黑树是一种自平衡的二叉查找树，是一种高效的查找树。红黑树通过如下的性质定义实现自平衡：节点是红色或黑色。根是黑色。所有叶子都是黑色（叶子是NIL节点）。每个红色节点必须有两个黑色的子节点。（从每个叶子到根的所有路径上不能有两个连续的红色节点。）从任一节点到其每个叶子的所有简单路径都包含相同数目的黑色节点（简称黑高）。
18、JDK8中对HashMap做了哪些改变？
1.在java 1.8中，如果链表的长度超过了8，那么链表将转换为红黑树。（桶的数量必须大于64，小于64的时候只会扩容）
2.发生hash碰撞时，java 1.7 会在链表的头部插入，而java 1.8会在链表的尾部插入
3.在java 1.8中，Entry被Node替代(换了一个马甲)。
19、HashMap 中的 key 我们可以使用任何类作为 key 吗？
平时可能大家使用的最多的就是使用 String 作为 HashMap 的 key，但是现在我们想使用某个自定 义类作为 HashMap 的 key，那就需要注意以下几点：如果类重写了 equals 方法，它也应该重写 hashCode 方法。类的所有实例需要遵循与 equals 和 hashCode 相关的规则。如果一个类没有使用 equals，你不应该在 hashCode 中使用它。咱们自定义 key 类的最佳实践是使之为不可变的，这样，hashCode 值可以被缓存起来，拥有更好的性能。不可变的类也可以确保 hashCode 和 equals 在未来不会改变，这样就会解决与可变相关的问题了。
20、HashMap 的长度为什么是 2 的 N 次方呢？
为了能让 HashMap 存数据和取数据的效率高，尽可能地减少 hash 值的碰撞，也就是说尽量把数 据能均匀的分配，每个链表或者红黑树长度尽量相等。我们首先可能会想到 % 取模的操作来实现。下面是回答的重点哟：取余（%）操作中如果除数是 2 的幂次，则等价于与其除数减一的与（&）操作（也就是说 hash % length == hash &(length - 1) 的前提是 length 是 2 的 n 次方）。并且，采用二进 制位操作 & ，相对于 % 能够提高运算效率。这就是为什么 HashMap 的长度需要 2 的 N 次方了。
21、HashMap，LinkedHashMap，TreeMap 有什么区别？
LinkedHashMap是继承于HashMap，是基于HashMap和双向链表来实现的。HashMap无序；LinkedHashMap有序，可分为插入顺序和访问顺序两种。如果是访问顺序，那put和get操作已存在的Entry时，都会把Entry移动到双向链表的表尾(其实是先删除再插入)。LinkedHashMap存取数据，还是跟HashMap一样使用的Entry[]的方式，双向链表只是为了保证顺序。LinkedHashMap是线程不安全的。
22、说说什么是 fail-fast？
fail-fast 机制是 Java 集合（Collection）中的一种错误机制。当多个线程对同一个集合的内容进行 操作时，就可能会产生 fail-fast 事件。例如：当某一个线程 A 通过 iterator 去遍历某集合的过程中，若该集合的内容被其他线程所改变 了，那么线程 A 访问集合时，就会抛出 ConcurrentModificationException 异常，产生 fail-fast 事 件。这里的操作主要是指 add、remove 和 clear，对集合元素个数进行修改。解决办法建议使用“java.util.concurrent 包下的类”去取代“java.util 包下的类”。可以这么理解：在遍历之前，把 modCount 记下来 expectModCount，后面 expectModCount 去 和 modCount 进行比较，如果不相等了，证明已并发了，被修改了，于是抛出 ConcurrentModificationException 异常。
23、HashMap 和 HashTable 有什么区别？
①、HashMap 是线程不安全的，HashTable 是线程安全的；②、由于线程安全，所以 HashTable 的效率比不上 HashMap；③、HashMap最多只允许一条记录的键为null，允许多条记录的值为null，而 HashTable不允许；④、HashMap 默认初始化数组的大小为16，HashTable 为 11，前者扩容时，扩大两倍，后者扩大两倍+1；⑤、HashMap 需要重新计算 hash 值，而 HashTable 直接使用对象的 hashCode；
24、HashMap 是线程安全的吗？
不是，在多线程环境下，1.7 会产生死循环、数据丢失、数据覆盖的问题，1.8 中会有数据覆盖的问题，以 1.8 为例，当 A 线程判断 index 位置为空后正好挂起，B 线程开始往 index 位置的写入节点数据，这时 A 线程恢复现场，执行赋值操作，就把 A 线程的数据给覆盖了；还有++size 这个地方也会造成多线程同时扩容等问题。
25、如何规避 HashMap 的线程不安全？
单线程条件下，为避免出现ConcurrentModificationException，需要保证只通过HashMap本身或者只通过Iterator去修改数据，不能在Iterator使用结束之前使用HashMap本身的方法修改数据。因为通过Iterator删除数据时，HashMap的modCount和Iterator的expectedModCount都会自增，不影响二者的相等性。如果是增加数据，只能通过HashMap本身的方法完成，此时如果要继续遍历数据，需要重新调用iterator()方法从而重新构造出一个新的Iterator，使得新Iterator的expectedModCount与更新后的HashMap的modCount相等。多线程条件下，可使用两种方式：Collections.synchronizedMap方法构造出一个同步Map直接使用线程安全的ConcurrentHashMap。
26、HashMap 和 ConcurrentHashMap 的区别？
都是 key-value 形式的存储数据；HashMap 是线程不安全的，ConcurrentHashMap 是 JUC 下的线程安全的；HashMap 底层数据结构是数组 + 链表（JDK 1.8 之前）。JDK 1.8 之后是数组 + 链表 + 红黑 树。当链表中元素个数达到 8 的时候，链表的查询速度不如红黑树快，链表会转为红黑树，红 黑树查询速度快；HashMap 初始数组大小为 16（默认），当出现扩容的时候，以 0.75 * 数组大小的方式进行扩 容；ConcurrentHashMap 在 JDK 1.8 之前是采用分段锁来现实的 Segment + HashEntry， Segment 数组大小默认是 16，2 的 n 次方；JDK 1.8 之后，采用 Node + CAS + Synchronized 来保证并发安全进行实现。
27、为什么 ConcurrentHashMap 比 HashTable 效率要高？
HashTable：使用一把锁（锁住整个链表结构）处理并发问题，多个线程竞争一把锁，容易阻塞；ConcurrentHashMap：JDK 1.7 中使用分段锁（ReentrantLock + Segment + HashEntry），相当于把一个 HashMap 分成多个段，每段分配一把锁，这样支持多线程访问。锁粒度：基于 Segment，包含多个 HashEntry。JDK 1.8 中使用CAS + synchronized + Node + 红黑树。锁粒度：Node（首结点）（实现 Map.Entry<K,V>）。锁粒度降低了。
28、说说 ConcurrentHashMap中 锁机制
JDK 1.7 中，采用分段锁的机制，实现并发的更新操作，底层采用数组+链表的存储结构，包括两个核心静态内部类 Segment 和 HashEntry。①、Segment 继承 ReentrantLock（重入锁） 用来充当锁的角色，每个 Segment 对象守护每个散列映射表的若干个桶；②、HashEntry 用来封装映射表的键-值对；③、每个桶是由若干个 HashEntry 对象链接起来的链表JDK 1.8 中，采用Node + CAS + Synchronized来保证并发安全。取消类 Segment，直接用 table 数组存储键值对；当 HashEntry 对象组成的链表长度超过 TREEIFY_THRESHOLD 时，链表转换为红黑树，提升性能。底层变更为数组 + 链表 + 红黑树。
29、在 JDK 1.8 中，ConcurrentHashMap 为什么要使用内置锁 
synchronized 来代替重入锁 ReentrantLock？①、粒度降低了；②、JVM 开发团队没有放弃 synchronized，而且基于 JVM 的 synchronized 优化空间更大，更加自然。③、在大量的数据操作下，对于 JVM 的内存压力，基于 API 的 ReentrantLock 会开销更多的内存。
30、能对ConcurrentHashMap 做个简单介绍吗？
①、重要的常量：　　private transient volatile int sizeCtl; 　　当为负数时，-1 表示正在初始化，-N 表示 N - 1 个线程正在进行扩容；　　当为 0 时，表示 table 还没有初始化；　　当为其他正数时，表示初始化或者下一次进行扩容的大小。②、数据结构：　　Node 是存储结构的基本单元，继承 HashMap 中的 Entry，用于存储数据； TreeNode 继承 Node，但是数据结构换成了二叉树结构，是红黑树的存储结构，用于红黑树中存储数据；　　TreeBin 是封装 TreeNode 的容器，提供转换红黑树的一些条件和锁的控制。③、存储对象时（put() 方法）：　　如果没有初始化，就调用 initTable() 方法来进行初始化；　　如果没有 hash 冲突就直接 CAS 无锁插入；　　如果需要扩容，就先进行扩容；　　如果存在 hash 冲突，就加锁来保证线程安全，两种情况：一种是链表形式就直接遍历到尾端插入，一种是红黑树就按照红黑树结构插入；　　如果该链表的数量大于阀值 8，就要先转换成红黑树的结构，break 再一次进入循环 　　如果添加成功就调用 addCount() 方法统计 size，并且检查是否需要扩容。④、扩容方法 transfer()：默认容量为 16，扩容时，容量变为原来的两倍。　　helpTransfer()：调用多个工作线程一起帮助进行扩容，这样的效率就会更高。⑤、获取对象时（get()方法）：　　计算 hash 值，定位到该 table 索引位置，如果是首结点符合就返回；　　如果遇到扩容时，会调用标记正在扩容结点 ForwardingNode.find()方法，查找该结点，匹配就返回；　　以上都不符合的话，就往下遍历结点，匹配就返回，否则最后就返回 null。
31、熟悉ConcurrentHashMap 的并发度吗？
程序运行时能够同时更新 ConccurentHashMap 且不产生锁竞争的最大线程数。默认为 16，且可以在构造函数中设置。当用户设置并发度时，ConcurrentHashMap 会使用大于等于该值的最小2幂指数作为实际并发度（假如用户设置并发度为17，实际并发度则为32）。