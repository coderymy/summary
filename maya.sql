/*
Navicat MySQL Data Transfer

Source Server         : 49.233.4.233
Source Server Version : 80026
Source Host           : 49.233.4.233:3306
Source Database       : maya

Target Server Type    : MYSQL
Target Server Version : 80026
File Encoding         : 65001

Date: 2023-03-14 10:26:22
*/

SET FOREIGN_KEY_CHECKS=0;

-- ----------------------------
-- Table structure for sql_test
-- ----------------------------
DROP TABLE IF EXISTS `sql_test`;
CREATE TABLE `sql_test` (
  `id` int NOT NULL AUTO_INCREMENT,
  `name` varchar(10) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=4 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;

-- ----------------------------
-- Records of sql_test
-- ----------------------------
INSERT INTO `sql_test` VALUES ('1', 'first');
INSERT INTO `sql_test` VALUES ('2', 'xiaoming');
INSERT INTO `sql_test` VALUES ('3', 'xiaobai');

-- ----------------------------
-- Table structure for tb_card
-- ----------------------------
DROP TABLE IF EXISTS `tb_card`;
CREATE TABLE `tb_card` (
  `id` int unsigned NOT NULL AUTO_INCREMENT,
  `first_class` tinyint NOT NULL DEFAULT '0' COMMENT '一级分类，大类：classify=1',
  `second_class` tinyint NOT NULL DEFAULT '0' COMMENT '二级分类，classify=2 ',
  `question` varchar(1024) NOT NULL DEFAULT '' COMMENT '问题',
  `ctime` datetime DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
  `mtime` datetime DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '修改时间',
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=351 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci COMMENT='卡片问题';

-- ----------------------------
-- Records of tb_card
-- ----------------------------
INSERT INTO `tb_card` VALUES ('7', '1', '3', '什么是懒加载', '2022-07-02 17:40:01', '2022-07-02 17:40:01');
INSERT INTO `tb_card` VALUES ('8', '11', '12', '为什么要用RocketMq？', '2022-07-02 17:40:01', '2022-07-02 17:40:01');
INSERT INTO `tb_card` VALUES ('9', '11', '12', 'RocketMq的部署架构了解吗？', '2022-07-02 17:40:02', '2022-07-02 17:40:02');
INSERT INTO `tb_card` VALUES ('10', '11', '12', 'RocketMq有哪几种部署类型？分别有什么特点？', '2022-07-02 17:40:02', '2022-07-02 17:40:02');
INSERT INTO `tb_card` VALUES ('11', '11', '12', 'rocketmq如何保证高可用性？', '2022-07-02 17:40:03', '2022-07-02 17:40:03');
INSERT INTO `tb_card` VALUES ('24', '1', '4', 'Wait和sleep的区别？', '2022-07-04 18:22:49', '2022-07-04 18:22:49');
INSERT INTO `tb_card` VALUES ('25', '1', '4', '并行和并发的区别？', '2022-07-04 18:22:49', '2022-07-04 18:22:49');
INSERT INTO `tb_card` VALUES ('26', '1', '4', 'Synchronized和Lock区别？', '2022-07-04 18:22:49', '2022-07-04 18:22:49');
INSERT INTO `tb_card` VALUES ('27', '1', '4', '线程间通信（线程交替进行）', '2022-07-04 18:22:50', '2022-07-04 18:22:50');
INSERT INTO `tb_card` VALUES ('28', '1', '4', '什么叫做集合的线程不安全？', '2022-07-04 18:22:50', '2022-07-04 18:22:50');
INSERT INTO `tb_card` VALUES ('29', '1', '4', '如何解决ArrayList的线程不安全问题？', '2022-07-04 18:22:50', '2022-07-04 18:22:50');
INSERT INTO `tb_card` VALUES ('30', '1', '4', 'Runnable接口和Callable接口区别？', '2022-07-04 18:22:50', '2022-07-04 18:22:50');
INSERT INTO `tb_card` VALUES ('31', '1', '4', 'Java并发编程哪些辅助类？', '2022-07-04 18:22:50', '2022-07-04 18:22:50');
INSERT INTO `tb_card` VALUES ('32', '1', '4', '多线程锁的分类', '2022-07-04 18:22:50', '2022-07-04 18:22:50');
INSERT INTO `tb_card` VALUES ('33', '1', '4', '乐观锁和悲观锁', '2022-07-04 18:22:50', '2022-07-04 18:22:50');
INSERT INTO `tb_card` VALUES ('34', '1', '4', '自旋锁和适应性自旋锁', '2022-07-04 18:22:51', '2022-07-04 18:22:51');
INSERT INTO `tb_card` VALUES ('35', '1', '4', '无锁、偏向锁、轻量级锁、重量级锁', '2022-07-04 18:22:51', '2022-07-04 18:22:51');
INSERT INTO `tb_card` VALUES ('36', '1', '4', '公平锁和非公平锁', '2022-07-04 18:22:51', '2022-07-04 18:22:51');
INSERT INTO `tb_card` VALUES ('37', '1', '4', '可重入锁和非可重入锁', '2022-07-04 18:22:51', '2022-07-04 18:22:51');
INSERT INTO `tb_card` VALUES ('38', '1', '4', '简述synchronized', '2022-07-04 18:22:51', '2022-07-04 18:22:51');
INSERT INTO `tb_card` VALUES ('39', '1', '4', '简述CAS', '2022-07-04 18:22:51', '2022-07-04 18:22:51');
INSERT INTO `tb_card` VALUES ('40', '1', '4', '简述AQS', '2022-07-04 18:22:51', '2022-07-04 18:22:51');
INSERT INTO `tb_card` VALUES ('41', '1', '4', '简述volatile', '2022-07-04 18:22:52', '2022-07-04 18:22:52');
INSERT INTO `tb_card` VALUES ('42', '1', '4', '简述线程池', '2022-07-04 18:22:52', '2022-07-04 18:22:52');
INSERT INTO `tb_card` VALUES ('43', '1', '4', '简述ThreadPoolExecutor', '2022-07-04 18:22:52', '2022-07-04 18:22:52');
INSERT INTO `tb_card` VALUES ('44', '1', '4', 'ThreadPoolExecutor的提交优先级和执行优先级', '2022-07-04 18:22:52', '2022-07-04 18:22:52');
INSERT INTO `tb_card` VALUES ('45', '1', '4', 'ThreadPoolExecutor的拒绝策略', '2022-07-04 18:22:52', '2022-07-04 18:22:52');
INSERT INTO `tb_card` VALUES ('46', '1', '4', 'ThreadPoolExecutor的工作队列workQueue', '2022-07-04 18:22:52', '2022-07-04 18:22:52');
INSERT INTO `tb_card` VALUES ('47', '1', '4', 'ThreadPoolExecutor中execute和submit提交（开启线程池）任务的区别', '2022-07-04 18:22:52', '2022-07-04 18:22:52');
INSERT INTO `tb_card` VALUES ('48', '1', '4', 'ThreadPoolExecutor关闭线程池的方法', '2022-07-04 18:22:52', '2022-07-04 18:22:52');
INSERT INTO `tb_card` VALUES ('49', '1', '4', '为什么要有锁的优化，为什么Java6要增加锁的复杂度', '2022-07-04 18:22:52', '2022-07-04 18:22:52');
INSERT INTO `tb_card` VALUES ('50', '1', '1', '测试Markdown', '2022-07-05 14:49:05', '2022-07-05 14:49:07');
INSERT INTO `tb_card` VALUES ('51', '1', '3', '有什么办法主动通知虚拟机进行垃圾回收？', '2022-07-11 17:56:34', '2022-07-11 17:56:34');
INSERT INTO `tb_card` VALUES ('52', '1', '3', 'Jvm内存结构', '2022-07-11 17:56:34', '2022-07-11 17:56:34');
INSERT INTO `tb_card` VALUES ('53', '1', '3', '什么是类加载器', '2022-07-11 17:56:34', '2022-07-11 17:56:34');
INSERT INTO `tb_card` VALUES ('54', '1', '3', '类加载器的分类', '2022-07-11 17:56:34', '2022-07-11 17:56:34');
INSERT INTO `tb_card` VALUES ('55', '1', '3', '什么是双亲委派机制', '2022-07-11 17:56:34', '2022-07-11 17:56:34');
INSERT INTO `tb_card` VALUES ('56', '1', '3', '为什么要有双亲委派机制', '2022-07-11 17:56:34', '2022-07-11 17:56:34');
INSERT INTO `tb_card` VALUES ('57', '1', '3', '双亲委派加载流程', '2022-07-11 17:56:34', '2022-07-11 17:56:34');
INSERT INTO `tb_card` VALUES ('58', '1', '3', 'Java类加载的懒加载模式', '2022-07-11 17:56:34', '2022-07-11 17:56:34');
INSERT INTO `tb_card` VALUES ('59', '1', '3', '类加载过程', '2022-07-11 17:56:34', '2022-07-11 17:56:34');
INSERT INTO `tb_card` VALUES ('60', '1', '3', '如何自定义类加载器', '2022-07-11 17:56:34', '2022-07-11 17:56:34');
INSERT INTO `tb_card` VALUES ('61', '1', '3', '简述运行时数据区的各个部分', '2022-07-11 17:56:34', '2022-07-11 17:56:34');
INSERT INTO `tb_card` VALUES ('62', '1', '3', '程序计数器（PC寄存器）的作用', '2022-07-11 17:56:34', '2022-07-11 17:56:34');
INSERT INTO `tb_card` VALUES ('63', '1', '3', '什么是虚拟机栈', '2022-07-11 17:56:34', '2022-07-11 17:56:34');
INSERT INTO `tb_card` VALUES ('64', '1', '3', '虚拟机栈的原理及组成部分', '2022-07-11 17:56:34', '2022-07-11 17:56:34');
INSERT INTO `tb_card` VALUES ('65', '1', '3', '虚拟机栈可能出现的异常', '2022-07-11 17:56:34', '2022-07-11 17:56:34');
INSERT INTO `tb_card` VALUES ('66', '1', '3', '什么是本地方法栈', '2022-07-11 17:56:34', '2022-07-11 17:56:34');
INSERT INTO `tb_card` VALUES ('67', '1', '3', '简述Jvm中的堆', '2022-07-11 17:56:35', '2022-07-11 17:56:35');
INSERT INTO `tb_card` VALUES ('68', '1', '3', '如何对堆进行逻辑细分', '2022-07-11 17:56:35', '2022-07-11 17:56:35');
INSERT INTO `tb_card` VALUES ('69', '1', '3', '堆空间调优参数有哪些', '2022-07-11 17:56:35', '2022-07-11 17:56:35');
INSERT INTO `tb_card` VALUES ('70', '1', '3', '简述年轻代和老年代', '2022-07-11 17:56:35', '2022-07-11 17:56:35');
INSERT INTO `tb_card` VALUES ('71', '1', '3', '堆空间是分配对象存储的唯一选择嘛（逃逸分析）', '2022-07-11 17:56:35', '2022-07-11 17:56:35');
INSERT INTO `tb_card` VALUES ('72', '1', '3', '方法区、栈和堆的关系', '2022-07-11 17:56:35', '2022-07-11 17:56:35');
INSERT INTO `tb_card` VALUES ('73', '1', '3', '方法区的特点', '2022-07-11 17:56:35', '2022-07-11 17:56:35');
INSERT INTO `tb_card` VALUES ('74', '1', '3', '方法区参数设置及OOM', '2022-07-11 17:56:35', '2022-07-11 17:56:35');
INSERT INTO `tb_card` VALUES ('75', '1', '3', '方法区的内部组成部分', '2022-07-11 17:56:35', '2022-07-11 17:56:35');
INSERT INTO `tb_card` VALUES ('76', '1', '3', '方法区的垃圾回收', '2022-07-11 17:56:35', '2022-07-11 17:56:35');
INSERT INTO `tb_card` VALUES ('77', '1', '3', '对象实例化过程和存储结构', '2022-07-11 17:56:35', '2022-07-11 17:56:35');
INSERT INTO `tb_card` VALUES ('78', '1', '3', '什么是执行引擎', '2022-07-11 17:56:35', '2022-07-11 17:56:35');
INSERT INTO `tb_card` VALUES ('79', '1', '3', '什么是JIT编译器', '2022-07-11 17:56:35', '2022-07-11 17:56:35');
INSERT INTO `tb_card` VALUES ('80', '1', '3', 'JIT什么时候使用（热点探测）', '2022-07-11 17:56:35', '2022-07-11 17:56:35');
INSERT INTO `tb_card` VALUES ('81', '1', '3', '如何使用JIT', '2022-07-11 17:56:35', '2022-07-11 17:56:35');
INSERT INTO `tb_card` VALUES ('82', '1', '3', 'JIT的分类（C1编译器和C2编译器）', '2022-07-11 17:56:35', '2022-07-11 17:56:35');
INSERT INTO `tb_card` VALUES ('83', '1', '3', '什么是本地方法库', '2022-07-11 17:56:35', '2022-07-11 17:56:35');
INSERT INTO `tb_card` VALUES ('84', '1', '3', '垃圾回收概念', '2022-07-11 17:56:35', '2022-07-11 17:56:35');
INSERT INTO `tb_card` VALUES ('85', '1', '3', '垃圾标记算法', '2022-07-11 17:56:35', '2022-07-11 17:56:35');
INSERT INTO `tb_card` VALUES ('86', '1', '3', '可达性分析法的GCRoot', '2022-07-11 17:56:36', '2022-07-11 17:56:36');
INSERT INTO `tb_card` VALUES ('87', '1', '3', '垃圾回收的finalization 机制', '2022-07-11 17:56:36', '2022-07-11 17:56:36');
INSERT INTO `tb_card` VALUES ('88', '1', '3', '垃圾清除算法', '2022-07-11 17:56:36', '2022-07-11 17:56:36');
INSERT INTO `tb_card` VALUES ('89', '1', '3', '简述分代回收算法', '2022-07-11 17:56:36', '2022-07-11 17:56:36');
INSERT INTO `tb_card` VALUES ('90', '1', '3', '手动垃圾回收：System.gc()', '2022-07-11 17:56:36', '2022-07-11 17:56:36');
INSERT INTO `tb_card` VALUES ('91', '1', '3', '内存溢出和内存泄露的区别', '2022-07-11 17:56:36', '2022-07-11 17:56:36');
INSERT INTO `tb_card` VALUES ('92', '1', '3', '什么是STW', '2022-07-11 17:56:36', '2022-07-11 17:56:36');
INSERT INTO `tb_card` VALUES ('93', '1', '3', '垃圾回收的并行和并发', '2022-07-11 17:56:36', '2022-07-11 17:56:36');
INSERT INTO `tb_card` VALUES ('94', '1', '3', 'GC时候的安全点和安全区域', '2022-07-11 17:56:36', '2022-07-11 17:56:36');
INSERT INTO `tb_card` VALUES ('95', '1', '3', '四种引用（强软弱虚）', '2022-07-11 17:56:36', '2022-07-11 17:56:36');
INSERT INTO `tb_card` VALUES ('96', '1', '3', '不同垃圾回收器的概述', '2022-07-11 17:56:36', '2022-07-11 17:56:36');
INSERT INTO `tb_card` VALUES ('97', '1', '3', '简述CMS垃圾回收器', '2022-07-11 17:56:36', '2022-07-11 17:56:36');
INSERT INTO `tb_card` VALUES ('98', '1', '3', '简述G1 垃圾收集器', '2022-07-11 17:56:36', '2022-07-11 17:56:36');
INSERT INTO `tb_card` VALUES ('99', '1', '3', '不同的类加载器有什么区别', '2022-07-11 17:56:36', '2022-07-11 17:56:36');
INSERT INTO `tb_card` VALUES ('100', '1', '3', '为什么要违背双亲委派机制', '2022-07-11 17:56:36', '2022-07-11 17:56:36');
INSERT INTO `tb_card` VALUES ('101', '1', '3', '如何打破双亲委派模型', '2022-07-11 17:56:36', '2022-07-11 17:56:36');
INSERT INTO `tb_card` VALUES ('102', '1', '3', '什么是SPI', '2022-07-11 17:56:36', '2022-07-11 17:56:36');
INSERT INTO `tb_card` VALUES ('103', '1', '3', '热部署原理', '2022-07-11 17:56:36', '2022-07-11 17:56:36');
INSERT INTO `tb_card` VALUES ('104', '1', '3', '三次破坏双亲委派机制', '2022-07-11 17:56:36', '2022-07-11 17:56:36');
INSERT INTO `tb_card` VALUES ('105', '1', '3', '为什么使用程序计数器记录执行地址', '2022-07-11 17:56:36', '2022-07-11 17:56:36');
INSERT INTO `tb_card` VALUES ('106', '1', '3', '虚拟机栈溢出的情况？', '2022-07-11 17:56:36', '2022-07-11 17:56:36');
INSERT INTO `tb_card` VALUES ('107', '1', '3', '方法中定义的局部变量是线程安全的嘛？', '2022-07-11 17:56:37', '2022-07-11 17:56:37');
INSERT INTO `tb_card` VALUES ('108', '1', '3', '虚拟机栈_栈顶缓存技术', '2022-07-11 17:56:37', '2022-07-11 17:56:37');
INSERT INTO `tb_card` VALUES ('109', '1', '3', '为什么生产环境中堆初始内存和最大内存设置成一样的值', '2022-07-11 17:56:37', '2022-07-11 17:56:37');
INSERT INTO `tb_card` VALUES ('110', '1', '3', '如何查看堆空间信息', '2022-07-11 17:56:37', '2022-07-11 17:56:37');
INSERT INTO `tb_card` VALUES ('111', '1', '3', '为什么要将堆进行分代', '2022-07-11 17:56:37', '2022-07-11 17:56:37');
INSERT INTO `tb_card` VALUES ('112', '1', '3', '什么是TLAB（私有缓存区域）', '2022-07-11 17:56:37', '2022-07-11 17:56:37');
INSERT INTO `tb_card` VALUES ('113', '1', '3', '介绍下堆的逃逸分析技术', '2022-07-11 17:56:37', '2022-07-11 17:56:37');
INSERT INTO `tb_card` VALUES ('114', '1', '3', '为什么JDK7要将原本放在永久代（方法区）中的字符串常量和静态变量的引用放到了堆空间中？', '2022-07-11 17:56:37', '2022-07-11 17:56:37');
INSERT INTO `tb_card` VALUES ('115', '1', '3', '标记整理算法的缺点', '2022-07-11 17:56:37', '2022-07-11 17:56:37');
INSERT INTO `tb_card` VALUES ('116', '1', '3', '静态变量和局部变量的区别', '2022-07-11 17:56:37', '2022-07-11 17:56:37');
INSERT INTO `tb_card` VALUES ('117', '1', '3', 'hotSpot的Java8和Java7在虚拟机上的区别', '2022-07-11 17:56:37', '2022-07-11 17:56:37');
INSERT INTO `tb_card` VALUES ('118', '1', '3', '字符串常量为什么这么特别', '2022-07-11 17:56:37', '2022-07-11 17:56:37');
INSERT INTO `tb_card` VALUES ('119', '1', '5', '简述hashMap的结构', '2022-07-12 17:14:48', '2022-07-12 17:14:48');
INSERT INTO `tb_card` VALUES ('120', '1', '5', 'hashMap为什么会需要链表呢', '2022-07-12 17:14:48', '2022-07-12 17:14:48');
INSERT INTO `tb_card` VALUES ('121', '1', '5', 'hashMap为什么引入红黑树', '2022-07-12 17:14:48', '2022-07-12 17:14:48');
INSERT INTO `tb_card` VALUES ('122', '1', '5', 'hashmap用了哪些数据结构', '2022-07-12 17:14:48', '2022-07-12 17:14:48');
INSERT INTO `tb_card` VALUES ('123', '1', '5', 'hashMap的头插法和尾插法', '2022-07-12 17:14:48', '2022-07-12 17:14:48');
INSERT INTO `tb_card` VALUES ('124', '1', '5', 'hashMap的put、get和resize', '2022-07-12 17:14:48', '2022-07-12 17:14:48');
INSERT INTO `tb_card` VALUES ('125', '1', '5', 'ConcurrentHashMap底层结构分析', '2022-07-12 17:14:48', '2022-07-12 17:14:48');
INSERT INTO `tb_card` VALUES ('126', '1', '5', 'hashMap、concurrentHashMap与hashTable', '2022-07-12 17:14:48', '2022-07-12 17:14:48');
INSERT INTO `tb_card` VALUES ('127', '1', '5', 'hashMap的默认初始化长度为什么是16？', '2022-07-12 17:14:48', '2022-07-12 17:14:48');
INSERT INTO `tb_card` VALUES ('128', '1', '5', 'HashMap的工作原理是什么?', '2022-07-12 17:14:48', '2022-07-12 17:14:48');
INSERT INTO `tb_card` VALUES ('129', '1', '5', '如果两个键hashcode相同，如何找到对应的对象', '2022-07-12 17:14:48', '2022-07-12 17:14:48');
INSERT INTO `tb_card` VALUES ('130', '1', '5', '扩容，what扩容？why扩容？when扩容？how扩容？', '2022-07-12 17:14:48', '2022-07-12 17:14:48');
INSERT INTO `tb_card` VALUES ('131', '1', '5', 'HashMap的并发问题', '2022-07-12 17:14:48', '2022-07-12 17:14:48');
INSERT INTO `tb_card` VALUES ('132', '1', '5', '如果指定的hashMap长度不是2的次幂就打破规则了吗', '2022-07-12 17:14:48', '2022-07-12 17:14:48');
INSERT INTO `tb_card` VALUES ('133', '1', '5', 'hashMap与hashTable的区别', '2022-07-12 17:14:48', '2022-07-12 17:14:48');
INSERT INTO `tb_card` VALUES ('134', '1', '5', '什么是Java集合的fail-fast(快速失败)机制', '2022-07-12 17:14:48', '2022-07-12 17:14:48');
INSERT INTO `tb_card` VALUES ('135', '1', '5', 'HashMap和LinkedHashMap,TreeMap有什么区别?', '2022-07-12 17:14:48', '2022-07-12 17:14:48');
INSERT INTO `tb_card` VALUES ('136', '1', '5', '如何使HashMap变的线程安全', '2022-07-12 17:14:48', '2022-07-12 17:14:48');
INSERT INTO `tb_card` VALUES ('137', '1', '5', '简述Jdk8对HashMap的优化', '2022-07-12 17:14:48', '2022-07-12 17:14:48');
INSERT INTO `tb_card` VALUES ('138', '1', '5', '简述hashMap的结构', '2022-07-13 15:50:16', '2022-07-13 15:50:16');
INSERT INTO `tb_card` VALUES ('139', '1', '5', 'hashMap为什么会需要链表呢', '2022-07-13 15:50:16', '2022-07-13 15:50:16');
INSERT INTO `tb_card` VALUES ('140', '1', '5', 'hashMap为什么引入红黑树', '2022-07-13 15:50:16', '2022-07-13 15:50:16');
INSERT INTO `tb_card` VALUES ('141', '1', '5', 'hashmap用了哪些数据结构', '2022-07-13 15:50:16', '2022-07-13 15:50:16');
INSERT INTO `tb_card` VALUES ('142', '1', '5', 'hashMap的头插法和尾插法', '2022-07-13 15:50:16', '2022-07-13 15:50:16');
INSERT INTO `tb_card` VALUES ('143', '1', '5', 'hashMap的put、get和resize', '2022-07-13 15:50:16', '2022-07-13 15:50:16');
INSERT INTO `tb_card` VALUES ('144', '1', '5', 'ConcurrentHashMap底层结构分析', '2022-07-13 15:50:16', '2022-07-13 15:50:16');
INSERT INTO `tb_card` VALUES ('145', '1', '5', 'hashMap、concurrentHashMap与hashTable', '2022-07-13 15:50:16', '2022-07-13 15:50:16');
INSERT INTO `tb_card` VALUES ('146', '1', '5', 'hashMap的默认初始化长度为什么是16？', '2022-07-13 15:50:16', '2022-07-13 15:50:16');
INSERT INTO `tb_card` VALUES ('147', '1', '5', 'HashMap的工作原理是什么?', '2022-07-13 15:50:16', '2022-07-13 15:50:16');
INSERT INTO `tb_card` VALUES ('148', '1', '5', '如果两个键hashcode相同，如何找到对应的对象', '2022-07-13 15:50:16', '2022-07-13 15:50:16');
INSERT INTO `tb_card` VALUES ('149', '1', '5', '扩容，what扩容？why扩容？when扩容？how扩容？', '2022-07-13 15:50:16', '2022-07-13 15:50:16');
INSERT INTO `tb_card` VALUES ('150', '1', '5', 'HashMap的并发问题', '2022-07-13 15:50:16', '2022-07-13 15:50:16');
INSERT INTO `tb_card` VALUES ('151', '1', '5', '如果指定的hashMap长度不是2的次幂就打破规则了吗', '2022-07-13 15:50:16', '2022-07-13 15:50:16');
INSERT INTO `tb_card` VALUES ('152', '1', '5', 'hashMap与hashTable的区别', '2022-07-13 15:50:16', '2022-07-13 15:50:16');
INSERT INTO `tb_card` VALUES ('153', '1', '5', '什么是Java集合的fail-fast(快速失败)机制', '2022-07-13 15:50:16', '2022-07-13 15:50:16');
INSERT INTO `tb_card` VALUES ('154', '1', '5', 'HashMap和LinkedHashMap,TreeMap有什么区别?', '2022-07-13 15:50:16', '2022-07-13 15:50:16');
INSERT INTO `tb_card` VALUES ('155', '1', '5', '如何使HashMap变的线程安全', '2022-07-13 15:50:16', '2022-07-13 15:50:16');
INSERT INTO `tb_card` VALUES ('156', '1', '5', '简述Jdk8对HashMap的优化', '2022-07-13 15:50:16', '2022-07-13 15:50:16');
INSERT INTO `tb_card` VALUES ('157', '1', '5', '简述hashMap的结构', '2022-07-13 15:50:43', '2022-07-13 15:50:43');
INSERT INTO `tb_card` VALUES ('158', '1', '5', 'hashMap为什么会需要链表呢', '2022-07-13 15:50:43', '2022-07-13 15:50:43');
INSERT INTO `tb_card` VALUES ('159', '1', '5', 'hashMap为什么引入红黑树', '2022-07-13 15:50:43', '2022-07-13 15:50:43');
INSERT INTO `tb_card` VALUES ('160', '1', '5', 'hashmap用了哪些数据结构', '2022-07-13 15:50:43', '2022-07-13 15:50:43');
INSERT INTO `tb_card` VALUES ('161', '1', '5', 'hashMap的头插法和尾插法', '2022-07-13 15:50:43', '2022-07-13 15:50:43');
INSERT INTO `tb_card` VALUES ('162', '1', '5', 'hashMap的put、get和resize', '2022-07-13 15:50:43', '2022-07-13 15:50:43');
INSERT INTO `tb_card` VALUES ('163', '1', '5', 'ConcurrentHashMap底层结构分析', '2022-07-13 15:50:43', '2022-07-13 15:50:43');
INSERT INTO `tb_card` VALUES ('164', '1', '5', 'hashMap、concurrentHashMap与hashTable', '2022-07-13 15:50:43', '2022-07-13 15:50:43');
INSERT INTO `tb_card` VALUES ('165', '1', '5', 'hashMap的默认初始化长度为什么是16？', '2022-07-13 15:50:43', '2022-07-13 15:50:43');
INSERT INTO `tb_card` VALUES ('166', '1', '5', 'HashMap的工作原理是什么?', '2022-07-13 15:50:43', '2022-07-13 15:50:43');
INSERT INTO `tb_card` VALUES ('167', '1', '5', '如果两个键hashcode相同，如何找到对应的对象', '2022-07-13 15:50:43', '2022-07-13 15:50:43');
INSERT INTO `tb_card` VALUES ('168', '1', '5', '扩容，what扩容？why扩容？when扩容？how扩容？', '2022-07-13 15:50:43', '2022-07-13 15:50:43');
INSERT INTO `tb_card` VALUES ('169', '1', '5', 'HashMap的并发问题', '2022-07-13 15:50:43', '2022-07-13 15:50:43');
INSERT INTO `tb_card` VALUES ('170', '1', '5', '如果指定的hashMap长度不是2的次幂就打破规则了吗', '2022-07-13 15:50:43', '2022-07-13 15:50:43');
INSERT INTO `tb_card` VALUES ('171', '1', '5', 'hashMap与hashTable的区别', '2022-07-13 15:50:43', '2022-07-13 15:50:43');
INSERT INTO `tb_card` VALUES ('172', '1', '5', '什么是Java集合的fail-fast(快速失败)机制', '2022-07-13 15:50:43', '2022-07-13 15:50:43');
INSERT INTO `tb_card` VALUES ('173', '1', '5', 'HashMap和LinkedHashMap,TreeMap有什么区别?', '2022-07-13 15:50:43', '2022-07-13 15:50:43');
INSERT INTO `tb_card` VALUES ('174', '1', '5', '如何使HashMap变的线程安全', '2022-07-13 15:50:43', '2022-07-13 15:50:43');
INSERT INTO `tb_card` VALUES ('175', '1', '5', '简述Jdk8对HashMap的优化', '2022-07-13 15:50:43', '2022-07-13 15:50:43');
INSERT INTO `tb_card` VALUES ('180', '1', '2', 'equals与==的区别', '2022-07-14 17:36:58', '2022-07-14 17:36:58');
INSERT INTO `tb_card` VALUES ('181', '1', '2', 'Java常量池（class常量池、字符串常量池和运行时常量池）', '2022-07-14 17:38:08', '2022-07-14 17:38:08');
INSERT INTO `tb_card` VALUES ('182', '1', '2', '字符串拼接的实现', '2022-07-14 17:38:23', '2022-07-14 17:38:23');
INSERT INTO `tb_card` VALUES ('183', '1', '2', 'new String(\"ab\")会创建几个对象', '2022-07-14 17:38:40', '2022-07-14 17:38:40');
INSERT INTO `tb_card` VALUES ('184', '1', '2', 'Java的四种引用，强弱软虚，用到的场景', '2022-07-14 17:39:01', '2022-07-14 17:39:01');
INSERT INTO `tb_card` VALUES ('185', '1', '2', 'Java中的Comparable和Comparator', '2022-07-14 17:49:07', '2022-07-14 17:49:07');
INSERT INTO `tb_card` VALUES ('186', '1', '2', 'intern()全解', '2022-07-14 17:49:25', '2022-07-14 17:49:25');
INSERT INTO `tb_card` VALUES ('187', '1', '2', 'clone()', '2022-07-14 18:48:17', '2022-07-14 18:48:17');
INSERT INTO `tb_card` VALUES ('188', '1', '2', '为什么重写equals方法时必须重写hashCode方法？', '2022-07-14 18:48:27', '2022-07-14 18:48:27');
INSERT INTO `tb_card` VALUES ('189', '1', '2', '谈一谈String、StringBuffer与StringBuilder', '2022-07-14 18:48:41', '2022-07-14 18:48:41');
INSERT INTO `tb_card` VALUES ('190', '1', '2', 'Java中的集合框架分类', '2022-07-15 14:58:56', '2022-07-15 14:58:56');
INSERT INTO `tb_card` VALUES ('191', '1', '4', '调用start()方法时会执行run()方法，为什么不直接调用run()方法？', '2022-07-18 11:47:25', '2022-07-18 11:47:25');
INSERT INTO `tb_card` VALUES ('192', '1', '2', 'ArrayList和LinkedList的区别', '2022-07-18 15:19:10', '2022-07-18 15:19:10');
INSERT INTO `tb_card` VALUES ('193', '1', '2', 'Object类的常见方法总结', '2022-07-18 15:19:24', '2022-07-18 15:19:24');
INSERT INTO `tb_card` VALUES ('194', '1', '2', 'Java中的值传递', '2022-07-18 15:21:01', '2022-07-18 15:21:01');
INSERT INTO `tb_card` VALUES ('195', '1', '2', '成员变量与局部变量的区别有那些？', '2022-07-18 15:21:14', '2022-07-18 15:21:14');
INSERT INTO `tb_card` VALUES ('196', '1', '2', 'catch异常捕捉的时候，如果try中有return还会执行finally中的语句吗', '2022-07-18 17:21:43', '2022-07-18 17:21:43');
INSERT INTO `tb_card` VALUES ('197', '1', '2', 'Override和Overload的区别', '2022-07-18 17:21:56', '2022-07-18 17:21:56');
INSERT INTO `tb_card` VALUES ('198', '1', '2', 'JNI', '2022-07-18 17:22:08', '2022-07-18 17:22:08');
INSERT INTO `tb_card` VALUES ('199', '1', '2', '常见的异常类', '2022-07-18 17:22:21', '2022-07-18 17:22:21');
INSERT INTO `tb_card` VALUES ('200', '1', '2', 'Exception和Error的区别', '2022-07-18 17:22:43', '2022-07-18 17:22:43');
INSERT INTO `tb_card` VALUES ('201', '1', '2', 'instanceof关键字的作用', '2022-07-18 17:22:52', '2022-07-18 17:22:52');
INSERT INTO `tb_card` VALUES ('202', '1', '2', 'Java自动拆装箱', '2022-07-18 17:23:05', '2022-07-18 17:23:05');
INSERT INTO `tb_card` VALUES ('203', '1', '2', '什么是OOP', '2022-07-18 17:39:13', '2022-07-18 17:39:13');
INSERT INTO `tb_card` VALUES ('204', '1', '2', '是否可以继承 String类', '2022-07-18 17:39:27', '2022-07-18 17:39:27');
INSERT INTO `tb_card` VALUES ('205', '6', '22', '简述事务四大特性（ACID）', '2022-07-20 16:22:43', '2022-07-20 16:22:43');
INSERT INTO `tb_card` VALUES ('206', '6', '22', '（脏读、幻读、不可重复读）并发情况下事务的问题', '2022-07-20 16:22:53', '2022-07-20 16:22:53');
INSERT INTO `tb_card` VALUES ('207', '6', '22', '事务的隔离级别', '2022-07-20 16:23:07', '2022-07-20 16:23:07');
INSERT INTO `tb_card` VALUES ('208', '6', '22', '简述MVCC', '2022-07-20 16:23:28', '2022-07-20 16:23:28');
INSERT INTO `tb_card` VALUES ('209', '6', '22', '事务的面试流程', '2022-07-29 14:27:49', '2022-07-29 14:27:49');
INSERT INTO `tb_card` VALUES ('210', '6', '22', 'MVCC在RR和RC中的区别', '2022-07-29 14:31:54', '2022-07-29 14:31:54');
INSERT INTO `tb_card` VALUES ('211', '6', '22', '默认隔离级别是什么？', '2022-07-29 14:32:04', '2022-07-29 14:32:04');
INSERT INTO `tb_card` VALUES ('212', '6', '22', '如何修改隔离级别', '2022-07-29 14:32:12', '2022-07-29 14:32:12');
INSERT INTO `tb_card` VALUES ('213', '6', '22', 'InnoDB事务是怎么实现的', '2022-07-29 14:32:20', '2022-07-29 14:32:20');
INSERT INTO `tb_card` VALUES ('214', '6', '22', '为什么标准Sql默认使用RC', '2022-07-29 14:32:30', '2022-07-29 14:32:30');
INSERT INTO `tb_card` VALUES ('215', '6', '22', '各个事务隔离级别如何解决三大问题', '2022-07-29 14:32:39', '2022-07-29 14:32:39');
INSERT INTO `tb_card` VALUES ('216', '6', '25', 'MyISAM 与 InnoDB 的区别是什么？', '2022-07-29 14:34:23', '2022-07-29 14:34:23');
INSERT INTO `tb_card` VALUES ('217', '6', '25', '简述redo log', '2022-07-29 14:34:33', '2022-07-29 14:34:33');
INSERT INTO `tb_card` VALUES ('218', '6', '25', 'redo log的刷盘策略', '2022-07-29 14:34:42', '2022-07-29 14:34:42');
INSERT INTO `tb_card` VALUES ('219', '6', '25', '简述undo Log', '2022-07-29 14:34:51', '2022-07-29 14:34:51');
INSERT INTO `tb_card` VALUES ('220', '6', '25', '什么是WAL', '2022-07-29 14:34:58', '2022-07-29 14:34:58');
INSERT INTO `tb_card` VALUES ('221', '6', '25', '简述binlog', '2022-07-29 14:35:05', '2022-07-29 14:35:05');
INSERT INTO `tb_card` VALUES ('222', '6', '25', 'redo log和binlog的区别', '2022-07-29 14:35:14', '2022-07-29 14:35:14');
INSERT INTO `tb_card` VALUES ('223', '6', '25', '为什么在有binlog的情况下还要有redo log？', '2022-07-29 14:35:21', '2022-07-29 14:35:21');
INSERT INTO `tb_card` VALUES ('224', '6', '25', '如何保证redo log 和binlog的数据一致性', '2022-07-29 14:35:29', '2022-07-29 14:35:29');
INSERT INTO `tb_card` VALUES ('225', '6', '9', '快照读和当前读', '2022-07-29 14:36:42', '2022-07-29 14:36:42');
INSERT INTO `tb_card` VALUES ('226', '6', '9', '简述全局锁', '2022-07-29 14:36:49', '2022-07-29 14:36:49');
INSERT INTO `tb_card` VALUES ('227', '6', '9', 'FTWRL和set global readonly=true的区别', '2022-07-29 14:36:58', '2022-07-29 14:36:58');
INSERT INTO `tb_card` VALUES ('228', '6', '9', '简述表级锁', '2022-07-29 14:37:05', '2022-07-29 14:37:05');
INSERT INTO `tb_card` VALUES ('229', '6', '9', '简述行级锁', '2022-07-29 14:37:18', '2022-07-29 14:37:18');
INSERT INTO `tb_card` VALUES ('230', '6', '9', '简述记录锁', '2022-07-29 14:37:27', '2022-07-29 14:37:27');
INSERT INTO `tb_card` VALUES ('231', '6', '9', '简述间隙锁', '2022-07-29 14:37:35', '2022-07-29 14:37:35');
INSERT INTO `tb_card` VALUES ('232', '6', '9', '简述临键锁', '2022-07-29 14:37:42', '2022-07-29 14:37:42');
INSERT INTO `tb_card` VALUES ('233', '6', '9', '简述乐观锁和悲观锁', '2022-07-29 14:37:49', '2022-07-29 14:37:49');
INSERT INTO `tb_card` VALUES ('234', '6', '8', '简述B+树', '2022-07-29 14:51:11', '2022-07-29 14:51:11');
INSERT INTO `tb_card` VALUES ('235', '6', '8', 'Mysql为什么选择B+树作为索引的结构', '2022-07-29 14:51:19', '2022-07-29 14:51:19');
INSERT INTO `tb_card` VALUES ('236', '6', '8', 'Mysql中的页的概念', '2022-07-29 14:51:27', '2022-07-29 14:51:27');
INSERT INTO `tb_card` VALUES ('237', '6', '8', 'Mysql如何使用页来构建索引', '2022-07-29 14:51:35', '2022-07-29 14:51:35');
INSERT INTO `tb_card` VALUES ('238', '6', '8', 'mysql索引及索引失效的各个情况', '2022-07-29 14:51:45', '2022-07-29 14:51:45');
INSERT INTO `tb_card` VALUES ('239', '6', '8', '简述最左前缀原则', '2022-07-29 14:51:53', '2022-07-29 14:51:53');
INSERT INTO `tb_card` VALUES ('240', '6', '8', '使用非聚簇索引的目的', '2022-07-29 14:51:59', '2022-07-29 14:51:59');
INSERT INTO `tb_card` VALUES ('241', '6', '8', '什么是哈希索引', '2022-07-29 14:52:07', '2022-07-29 14:52:07');
INSERT INTO `tb_card` VALUES ('242', '6', '8', '简单介绍下对mysql索引的理解', '2022-07-29 14:52:15', '2022-07-29 14:52:15');
INSERT INTO `tb_card` VALUES ('243', '6', '8', '说下聚簇索引和非聚簇索引的区别', '2022-07-29 14:52:23', '2022-07-29 14:52:23');
INSERT INTO `tb_card` VALUES ('244', '6', '8', '为什么主键建议使用自增的,而不是uuid', '2022-07-29 14:52:31', '2022-07-29 14:52:31');
INSERT INTO `tb_card` VALUES ('245', '6', '8', '为什么一般认定2500万行数据的表就会出现查询效率的骤降', '2022-07-29 14:52:40', '2022-07-29 14:52:40');
INSERT INTO `tb_card` VALUES ('246', '6', '8', '索引在查找中起到的作用?', '2022-07-29 14:52:48', '2022-07-29 14:52:48');
INSERT INTO `tb_card` VALUES ('247', '6', '8', '面试问你联合索引什么情况下会命中索引', '2022-07-29 14:52:56', '2022-07-29 14:52:56');
INSERT INTO `tb_card` VALUES ('248', '6', '8', '如果创建表时没有创建主键索引', '2022-07-29 14:53:04', '2022-07-29 14:53:04');
INSERT INTO `tb_card` VALUES ('249', '6', '8', '常见的面试索引命中问题', '2022-07-29 14:53:12', '2022-07-29 14:53:12');
INSERT INTO `tb_card` VALUES ('250', '6', '8', '什么叫做覆盖索引', '2022-07-29 14:53:25', '2022-07-29 14:53:25');
INSERT INTO `tb_card` VALUES ('251', '6', '8', '说下索引下推是什么', '2022-07-29 14:53:39', '2022-07-29 14:53:39');
INSERT INTO `tb_card` VALUES ('252', '6', '8', '简单介绍下explain的使用', '2022-07-29 14:53:47', '2022-07-29 14:53:47');
INSERT INTO `tb_card` VALUES ('253', '6', '8', '为什么innoDB的索引字段不建议过长', '2022-07-29 14:53:54', '2022-07-29 14:53:54');
INSERT INTO `tb_card` VALUES ('254', '6', '8', '普通索引和唯一索引的区别', '2022-07-29 14:54:05', '2022-07-29 14:54:05');
INSERT INTO `tb_card` VALUES ('255', '6', '8', '字符串字段创建索引', '2022-07-29 14:54:13', '2022-07-29 14:54:13');
INSERT INTO `tb_card` VALUES ('256', '6', '8', 'mysql的change buffer', '2022-07-29 14:54:21', '2022-07-29 14:54:21');
INSERT INTO `tb_card` VALUES ('257', '6', '8', '索引设置规范', '2022-07-29 14:54:34', '2022-07-29 14:54:34');
INSERT INTO `tb_card` VALUES ('258', '19', '26', 'redis如何实现分布式锁', '2022-12-19 13:39:38', '2022-12-19 13:39:38');
INSERT INTO `tb_card` VALUES ('259', '19', '26', 'redis线程模型，单线程为什么还这么快「内单多高」', '2022-12-19 13:39:55', '2022-12-19 13:39:55');
INSERT INTO `tb_card` VALUES ('260', '19', '26', 'redis集群如何保证单线程运行', '2022-12-19 13:40:18', '2022-12-19 13:40:18');
INSERT INTO `tb_card` VALUES ('261', '19', '26', 'redis淘汰策略', '2022-12-19 13:40:26', '2022-12-19 13:40:26');
INSERT INTO `tb_card` VALUES ('262', '19', '26', 'redis过期策略', '2022-12-19 13:40:36', '2022-12-19 13:40:36');
INSERT INTO `tb_card` VALUES ('263', '19', '26', '存储结构-跳表', '2022-12-19 13:40:57', '2022-12-19 13:40:57');
INSERT INTO `tb_card` VALUES ('264', '19', '26', '底层存储结构', '2022-12-19 13:41:18', '2022-12-19 13:41:18');
INSERT INTO `tb_card` VALUES ('265', '19', '26', 'redis集群', '2022-12-19 13:41:40', '2022-12-19 13:41:40');
INSERT INTO `tb_card` VALUES ('266', '19', '26', 'redis带来的业务问题', '2022-12-19 13:41:50', '2022-12-19 13:41:50');
INSERT INTO `tb_card` VALUES ('267', '19', '26', 'redis线程模型', '2022-12-19 13:42:05', '2022-12-19 13:42:05');
INSERT INTO `tb_card` VALUES ('268', '19', '26', 'redis的过期策略问题', '2022-12-19 13:42:35', '2022-12-19 13:42:35');
INSERT INTO `tb_card` VALUES ('269', '19', '26', 'redis持久化', '2022-12-19 13:42:48', '2022-12-19 13:42:48');
INSERT INTO `tb_card` VALUES ('270', '19', '26', '主从复制的原理', '2022-12-19 13:42:57', '2022-12-19 13:42:57');
INSERT INTO `tb_card` VALUES ('271', '19', '26', 'mysql与redis数据一致性解决方案', '2022-12-19 13:43:07', '2022-12-19 13:43:07');
INSERT INTO `tb_card` VALUES ('272', '19', '26', 'redis的八种数据结构及使用场景', '2022-12-19 13:43:25', '2022-12-19 13:43:25');
INSERT INTO `tb_card` VALUES ('273', '19', '26', '数据量大的时候,如何保证redis中缓存的都是热点数据', '2022-12-19 13:44:01', '2022-12-19 13:44:01');
INSERT INTO `tb_card` VALUES ('274', '11', '12', 'RocketMQ Broker中的消息被消费后会立即删除吗？', '2022-12-19 17:02:39', '2022-12-19 17:02:39');
INSERT INTO `tb_card` VALUES ('275', '11', '12', 'broker集群', '2022-12-19 18:01:17', '2022-12-19 18:01:17');
INSERT INTO `tb_card` VALUES ('276', '11', '12', '如何保证全链路数据不丢失', '2022-12-19 18:01:26', '2022-12-19 18:01:26');
INSERT INTO `tb_card` VALUES ('277', '11', '12', '如何保证消息有序', '2022-12-19 18:01:34', '2022-12-19 18:01:34');
INSERT INTO `tb_card` VALUES ('278', '11', '12', '如何处理大量积压的消息？', '2022-12-19 18:01:41', '2022-12-19 18:01:41');
INSERT INTO `tb_card` VALUES ('279', '11', '12', '消息的消费模式有哪几种', '2022-12-19 18:01:55', '2022-12-19 18:01:55');
INSERT INTO `tb_card` VALUES ('280', '11', '12', 'pull和push', '2022-12-19 18:02:03', '2022-12-19 18:02:03');
INSERT INTO `tb_card` VALUES ('281', '11', '12', 'RocketMq的存储机制了解吗？', '2022-12-19 18:02:12', '2022-12-19 18:02:12');
INSERT INTO `tb_card` VALUES ('282', '11', '12', 'RocketMq的存储结构是怎样的？', '2022-12-19 18:02:21', '2022-12-19 18:02:21');
INSERT INTO `tb_card` VALUES ('283', '11', '12', 'RocketMq性能比较高的原因', '2022-12-19 18:02:38', '2022-12-19 18:02:38');
INSERT INTO `tb_card` VALUES ('284', '11', '12', '重复消费', '2022-12-19 18:02:50', '2022-12-19 18:02:50');
INSERT INTO `tb_card` VALUES ('285', '11', '12', '顺序消费', '2022-12-19 18:02:58', '2022-12-19 18:02:58');
INSERT INTO `tb_card` VALUES ('286', '11', '12', '消息丢失', '2022-12-19 18:03:06', '2022-12-19 18:03:06');
INSERT INTO `tb_card` VALUES ('287', '11', '12', '延时队列', '2022-12-19 18:03:15', '2022-12-19 18:03:15');
INSERT INTO `tb_card` VALUES ('288', '11', '12', '消息清理', '2022-12-19 18:03:27', '2022-12-19 18:03:27');
INSERT INTO `tb_card` VALUES ('289', '11', '12', '消息堆积', '2022-12-19 18:03:33', '2022-12-19 18:03:33');
INSERT INTO `tb_card` VALUES ('290', '11', '12', '分布式事务', '2022-12-19 18:03:40', '2022-12-19 18:03:40');
INSERT INTO `tb_card` VALUES ('291', '11', '12', '批量消息', '2022-12-19 18:03:46', '2022-12-19 18:03:46');
INSERT INTO `tb_card` VALUES ('292', '11', '12', 'queue的分配策略', '2022-12-19 18:03:56', '2022-12-19 18:03:56');
INSERT INTO `tb_card` VALUES ('293', '27', '28', '简述基础的排序算法原理', '2022-12-20 13:58:51', '2022-12-20 13:58:51');
INSERT INTO `tb_card` VALUES ('294', '1', '4', '简述Synchronized、Lock的区别', '2023-02-27 15:23:16', '2023-02-27 15:23:16');
INSERT INTO `tb_card` VALUES ('295', '1', '4', '为什么说arrayList、hashMap是线程不安全的', '2023-02-27 15:23:25', '2023-02-27 15:23:25');
INSERT INTO `tb_card` VALUES ('296', '1', '4', 'volatile关键字的工作原理', '2023-02-27 15:23:34', '2023-02-27 15:23:34');
INSERT INTO `tb_card` VALUES ('297', '1', '4', '简述synchronized和lock的区别', '2023-02-27 15:24:15', '2023-02-27 15:24:15');
INSERT INTO `tb_card` VALUES ('298', '1', '4', '简述synchronized的实现原理', '2023-02-27 15:24:27', '2023-02-27 15:24:27');
INSERT INTO `tb_card` VALUES ('299', '1', '4', '简述volatile关键字', '2023-02-27 15:24:35', '2023-02-27 15:24:35');
INSERT INTO `tb_card` VALUES ('300', '1', '4', '简述线程池的几个参数', '2023-02-27 15:24:44', '2023-02-27 15:24:44');
INSERT INTO `tb_card` VALUES ('301', '1', '4', 'execute和submit开启线程池的区别', '2023-02-27 15:24:53', '2023-02-27 15:24:53');
INSERT INTO `tb_card` VALUES ('302', '1', '4', 'CAS原理', '2023-02-27 15:25:02', '2023-02-27 15:25:02');
INSERT INTO `tb_card` VALUES ('303', '1', '4', 'AQS原理', '2023-02-27 15:25:10', '2023-02-27 15:25:10');
INSERT INTO `tb_card` VALUES ('304', '1', '4', '介绍你了解的各种锁', '2023-02-27 15:25:22', '2023-02-27 15:25:22');
INSERT INTO `tb_card` VALUES ('305', '1', '4', 'sleep和wait的区别', '2023-02-27 15:25:29', '2023-02-27 15:25:29');
INSERT INTO `tb_card` VALUES ('306', '1', '4', 'start和run方法的区别', '2023-02-27 15:25:36', '2023-02-27 15:25:36');
INSERT INTO `tb_card` VALUES ('307', '1', '4', '停止线程', '2023-02-27 15:25:43', '2023-02-27 15:25:43');
INSERT INTO `tb_card` VALUES ('308', '1', '4', '线程间通信', '2023-02-27 15:25:52', '2023-02-27 15:25:52');
INSERT INTO `tb_card` VALUES ('309', '1', '4', '锁的膨胀', '2023-02-27 15:26:00', '2023-02-27 15:26:00');
INSERT INTO `tb_card` VALUES ('310', '1', '3', '简述类加载过程', '2023-02-27 15:26:25', '2023-02-27 15:26:25');
INSERT INTO `tb_card` VALUES ('311', '1', '3', '简述运行时数据区分配', '2023-02-27 15:26:33', '2023-02-27 15:26:33');
INSERT INTO `tb_card` VALUES ('312', '1', '3', '简述垃圾回收过程', '2023-02-27 15:26:47', '2023-02-27 15:26:47');
INSERT INTO `tb_card` VALUES ('313', '1', '3', '简述各类垃圾回收器', '2023-02-27 15:26:55', '2023-02-27 15:26:55');
INSERT INTO `tb_card` VALUES ('314', '1', '3', '分代回收机制', '2023-02-27 15:27:02', '2023-02-27 15:27:02');
INSERT INTO `tb_card` VALUES ('315', '1', '3', 'MinorGC、MajorGC和FullGC', '2023-02-27 15:27:10', '2023-02-27 15:27:10');
INSERT INTO `tb_card` VALUES ('316', '1', '3', 'G1的分区算法', '2023-02-27 15:27:18', '2023-02-27 15:27:18');
INSERT INTO `tb_card` VALUES ('317', '1', '3', 'JIT即时编译技术', '2023-02-27 15:27:26', '2023-02-27 15:27:26');
INSERT INTO `tb_card` VALUES ('318', '1', '3', '关于字符串常量池', '2023-02-27 15:27:42', '2023-02-27 15:27:42');
INSERT INTO `tb_card` VALUES ('319', '1', '3', '类加载_三次破坏双亲委派机制', '2023-02-27 15:27:51', '2023-02-27 15:27:51');
INSERT INTO `tb_card` VALUES ('320', '11', '12', 'RocketMQ的存储结构', '2023-02-27 15:28:23', '2023-02-27 15:28:23');
INSERT INTO `tb_card` VALUES ('321', '11', '12', '## 顺序消费', '2023-02-27 15:28:41', '2023-02-27 15:28:41');
INSERT INTO `tb_card` VALUES ('322', '11', '12', '消息不丢失', '2023-02-27 15:28:47', '2023-02-27 15:28:47');
INSERT INTO `tb_card` VALUES ('323', '19', '26', '数据结构', '2023-02-27 15:29:06', '2023-02-27 15:29:06');
INSERT INTO `tb_card` VALUES ('324', '19', '26', '解决缓存雪崩和击穿', '2023-02-27 15:29:14', '2023-02-27 15:29:14');
INSERT INTO `tb_card` VALUES ('325', '19', '26', '集群', '2023-02-27 15:29:21', '2023-02-27 15:29:21');
INSERT INTO `tb_card` VALUES ('326', '17', '23', 'Spring的事务机制', '2023-02-27 15:29:48', '2023-02-27 15:29:48');
INSERT INTO `tb_card` VALUES ('327', '17', '23', 'Spring中的设计模式', '2023-02-27 15:29:55', '2023-02-27 15:29:55');
INSERT INTO `tb_card` VALUES ('328', '17', '23', '循环依赖', '2023-02-27 15:30:02', '2023-02-27 15:30:02');
INSERT INTO `tb_card` VALUES ('329', '17', '23', '详述一下代理模式', '2023-02-27 15:30:10', '2023-02-27 15:30:10');
INSERT INTO `tb_card` VALUES ('330', '17', '23', 'SpringBean的生命周期', '2023-02-27 15:30:33', '2023-02-27 15:30:33');
INSERT INTO `tb_card` VALUES ('331', '27', '29', '简述各种设计模式', '2023-02-27 15:31:40', '2023-02-27 15:31:40');
INSERT INTO `tb_card` VALUES ('332', '27', '28', '排序算法总结', '2023-02-27 15:32:11', '2023-02-27 15:32:11');
INSERT INTO `tb_card` VALUES ('333', '27', '30', '**大数据处理中的分治思想**', '2023-02-27 16:09:06', '2023-02-27 16:09:06');
INSERT INTO `tb_card` VALUES ('334', '27', '30', '统计 1 亿个 IP 地址中出现频率最高的 IP', '2023-02-27 16:09:16', '2023-02-27 16:09:16');
INSERT INTO `tb_card` VALUES ('335', '27', '30', '从 300 万个字符串中找出频率最高的 10 个', '2023-02-27 16:09:28', '2023-02-27 16:09:28');
INSERT INTO `tb_card` VALUES ('336', '27', '30', '有 10 个文件，每个 1G，每个文件的每一行是一个字符串，如何按照出现次数给所有字符串排序？', '2023-02-27 16:09:38', '2023-02-27 16:09:38');
INSERT INTO `tb_card` VALUES ('337', '27', '30', '给定两个文件 a、b，各存放 50 亿个 url，每个 url 占 64 字节，内存限制是 4G，找出两文件的共同 url。', '2023-02-27 16:09:47', '2023-02-27 16:09:47');
INSERT INTO `tb_card` VALUES ('338', '27', '30', '在 2.5 亿个 int 数中找出不重复的整数', '2023-02-27 16:09:55', '2023-02-27 16:09:55');
INSERT INTO `tb_card` VALUES ('339', '27', '30', '从 5 亿个数中找出中位数', '2023-02-27 16:10:48', '2023-02-27 16:10:48');
INSERT INTO `tb_card` VALUES ('340', '27', '31', '浏览器输入URL到返回页面的全过程', '2023-02-27 16:12:53', '2023-02-27 16:12:53');
INSERT INTO `tb_card` VALUES ('341', '27', '31', '一个TCP链接可以建立多少个HTTP请求', '2023-02-27 16:13:05', '2023-02-27 16:13:05');
INSERT INTO `tb_card` VALUES ('342', '27', '31', '一个 TCP 连接中 HTTP 请求发送可以一起发送么', '2023-02-27 16:13:11', '2023-02-27 16:13:11');
INSERT INTO `tb_card` VALUES ('343', '27', '31', '浏览器对同一Host建立TCP连接数量有没有限制？', '2023-02-27 16:13:20', '2023-02-27 16:13:20');
INSERT INTO `tb_card` VALUES ('344', '27', '31', 'TCP如果建立连接之后不发送数据会怎么样', '2023-02-27 16:13:26', '2023-02-27 16:13:26');
INSERT INTO `tb_card` VALUES ('345', '27', '31', '301和302的区别', '2023-02-27 16:13:36', '2023-02-27 16:13:36');
INSERT INTO `tb_card` VALUES ('346', '1', '32', 'CPU资源占用满了', '2023-02-27 17:46:08', '2023-02-27 17:46:08');
INSERT INTO `tb_card` VALUES ('347', '1', '32', '内存问题', '2023-02-27 17:46:23', '2023-02-27 17:46:23');
INSERT INTO `tb_card` VALUES ('348', '1', '32', 'IO密集型和CPU密集型', '2023-02-27 17:46:42', '2023-02-27 17:46:42');
INSERT INTO `tb_card` VALUES ('349', '1', '32', '方法区“内存溢出”OOM', '2023-02-27 17:46:53', '2023-02-27 17:46:53');
INSERT INTO `tb_card` VALUES ('350', '1', '32', 'java程序常见线上问题', '2023-02-27 17:47:26', '2023-02-27 17:47:26');

-- ----------------------------
-- Table structure for tb_card_answer
-- ----------------------------
DROP TABLE IF EXISTS `tb_card_answer`;
CREATE TABLE `tb_card_answer` (
  `id` int unsigned NOT NULL AUTO_INCREMENT,
  `question_id` int NOT NULL DEFAULT '0' COMMENT '问题id',
  `answer_msg` text NOT NULL COMMENT '答案信息',
  `answer_type` tinyint NOT NULL DEFAULT '0' COMMENT '答案类型 0-官方 1-个人',
  `answer_level` tinyint NOT NULL DEFAULT '0' COMMENT '答案可信度级别 1-完全可信 2-基本可信 3-可借阅 4-了解即可 5-不确定',
  `answer_creator_id` int NOT NULL DEFAULT '0' COMMENT '答案创建人ID',
  `status` tinyint NOT NULL DEFAULT '0' COMMENT '答案状态 0-未生效 1-待审核 2-已生效 3-已作废',
  `ctime` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
  `mtime` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '修改时间',
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=347 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci COMMENT='卡片答案集锦';

-- ----------------------------
-- Records of tb_card_answer
-- ----------------------------
INSERT INTO `tb_card_answer` VALUES ('6', '7', 'jvm虚拟机中对类的加载是只有用到某个类的时候才会进行这个类的加载\n\n懒加载时机：\n\n+ new/访问静态实例/访问静态方法时，访问final变量\n+ 反射时\n+ 初始化子类，父类先初始化\n+ 虚拟机启动，被执行的主类初始化', '0', '1', '1', '1', '2022-07-02 17:40:01', '2022-07-02 17:40:01');
INSERT INTO `tb_card_answer` VALUES ('7', '8', '总得来说，RocketMq具有以下几个优势：\n\n吞吐量高：单机吞吐量可达十万级\n可用性高：分布式架构\n消息可靠性高：经过参数优化配置，消息可以做到0丢失\n功能支持完善：MQ功能较为完善，还是分布式的，扩展性好\n支持10亿级别的消息堆积：不会因为堆积导致性能下降\n源码是java：方便我们查看源码了解它的每个环节的实现逻辑，并针对不同的业务场景进行扩展\n可靠性高：天生为金融互联网领域而生，对于要求很高的场景，尤其是电商里面的订单扣款，以及业务削峰，在大量交易涌入时，后端可能无法及时处理的情况\n稳定性高：RoketMQ在上可能更值得信赖，这些业务场景在阿里双11已经经历了多次考验', '0', '1', '1', '1', '2022-07-02 17:40:02', '2022-07-02 17:40:02');
INSERT INTO `tb_card_answer` VALUES ('8', '9', '![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/DCuWAM.jpg)\n\n\n\n\n\n\n\n这个是rocketMq的集群架构图，里面包含了四个主要部分：NameServer集群,Producer集群,Cosumer集群以及Broker集群\n\nNameServer 担任路由消息的提供者。生产者或消费者能够通过NameServer查找各Topic相应的Broker IP列表分别进行发送消息和消费消息。nameServer由多个无状态的节点构成，节点之间无任何信息同步\n\nbroker会定期向NameServer以发送心跳包的方式，轮询向所有NameServer注册以下元数据信息：\n\n1）broker的基本信息（ip port等）\n\n2）主题topic的地址信息\n\n3）broker集群信息\n\n4）存活的broker信息\n\n5）filter 过滤器\n\n也就是说，每个NameServer注册的信息都是一样的，而且是当前系统中的所有broker的元数据信息\n\nProducer负责生产消息，一般由业务系统负责生产消息。一个消息生产者会把业务应用系统里产生的消息发送到broker服务器。RocketMQ提供多种发送方式，同步发送、异步发送、顺序发送、单向发送。同步和异步方式均需要Broker返回确认信息，单向发送不需要\n\nBroker，消息中转角色，负责存储消息、转发消息。在RocketMQ系统中负责接收从生产者发送来的消息并存储、同时为消费者的拉取请求作准备\n\nConsumer负责消费消息，一般是后台系统负责异步消费。一个消息消费者会从Broker服务器拉取消息、并将其提供给应用程序。从用户应用的角度而言提供了两种消费形式：拉取式消费、推动式消费', '0', '1', '1', '1', '2022-07-02 17:40:02', '2022-07-02 17:40:02');
INSERT INTO `tb_card_answer` VALUES ('9', '10', 'RocketMQ有4种部署类型\n\n1）单Master\n\n单机模式, 即只有一个Broker, 如果Broker宕机了, 会导致RocketMQ服务不可用, 不推荐使用\n\n2）多Master模式\n\n组成一个集群, 集群每个节点都是Master节点, 配置简单, 性能也是最高, 某节点宕机重启不会影响RocketMQ服务\n\n缺点：如果某个节点宕机了, 会导致该节点存在未被消费的消息在节点恢复之前不能被消费\n\n3）多Master多Slave模式，异步复制\n\n每个Master配置一个Slave, 多对Master-Slave, Master与Slave消息采用异步复制方式, 主从消息一致只会有毫秒级的延迟\n\n优点是弥补了多Master模式（无slave）下节点宕机后在恢复前不可订阅的问题。在Master宕机后, 消费者还可以从Slave节点进行消费。采用异步模式复制，提升了一定的吞吐量。总结一句就是，采用多Master多Slave模式，异步复制模式进行部署，系统将会有较低的延迟和较高的吞吐量\n\n缺点就是如果Master宕机, 磁盘损坏的情况下, 如果没有及时将消息复制到Slave, 会导致有少量消息丢失\n\n4）多Master多Slave模式，同步双写\n\n与多Master多Slave模式，异步复制方式基本一致，唯一不同的是消息复制采用同步方式，只有master和slave都写成功以后，才会向客户端返回成功\n\n优点：数据与服务都无单点，Master宕机情况下，消息无延迟，服务可用性与数据可用性都非常高\n\n缺点就是会降低消息写入的效率，并影响系统的吞吐量\n\n实际部署中，一般会根据业务场景的所需要的性能和消息可靠性等方面来选择后两种', '0', '1', '1', '1', '2022-07-02 17:40:02', '2022-07-02 17:40:02');
INSERT INTO `tb_card_answer` VALUES ('10', '11', '1）集群化部署NameServer。Broker集群会将所有的broker基本信息、topic信息以及两者之间的映射关系，轮询存储在每个NameServer中（也就是说每个NameServer存储的信息完全一样）。因此，NameServer集群化，不会因为其中的一两台服务器挂掉，而影响整个架构的消息发送与接收；\n\n2）集群化部署多broker。producer发送消息到broker的master，若当前的master挂掉，则会自动切换到其他的master\n\ncosumer默认会访问broker的master节点获取消息，那么master节点挂了之后，该怎么办呢？它就会自动切换到同一个broker组的slave节点进行消费\n\n那么你肯定会想到会有这样一个问题：consumer要是直接消费slave节点，那master在宕机前没有来得及把消息同步到slave节点，那这个时候，不就会出现消费者不就取不到消息的情况了？\n\n这样，就引出了下一个措施，来保证消息的高可用性\n\n3）设置同步复制\n\n前面已经提到，消息发送到broker的master节点上，master需要将消息复制到slave节点上，rocketmq提供两种复制方式：同步复制和异步复制\n\n异步复制，就是消息发送到master节点，只要master写成功，就直接向客户端返回成功，后续再异步写入slave节点\n\n同步复制，就是等master和slave都成功写入内存之后，才会向客户端返回成功\n\n那么，要保证高可用性，就需要将复制方式配置成同步复制，这样即使master节点挂了，slave上也有当前master的所有备份数据，那么不仅保证消费者消费到的消息是完整的，并且当master节点恢复之后，也容易恢复消息数据\n\n在master的配置文件中直接配置brokerRole：SYNC_MASTER即可', '0', '1', '1', '1', '2022-07-02 17:40:03', '2022-07-02 17:40:03');
INSERT INTO `tb_card_answer` VALUES ('20', '24', '1. 继承的类不同\n\n   wait来自Object类\n\n   sleep来自Thread类\n\n2. 锁的释放\n\n   wait会释放锁\n\n   sleep不会释放锁\n\n3. 使用范围不同\n\n   wait必须在同步代码块中\n\n   sleep可以在任何地方\n\n4. 异常\n\n   wait不需要捕获异常\n\n   sleep需要捕获异常', '0', '1', '1', '1', '2022-07-04 18:22:49', '2022-07-04 18:22:49');
INSERT INTO `tb_card_answer` VALUES ('21', '25', '并发：多个线程访问一个资源；春运抢票\n\n并行：多个线程一起执行一个任务，每个线程执行一部分操作；边刷牙边烧水\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/并行和并发.drawio.png)', '0', '1', '1', '1', '2022-07-04 18:22:49', '2022-07-04 18:22:49');
INSERT INTO `tb_card_answer` VALUES ('22', '26', '**Sychronized**\n\n> 使用方式\n\n针对上锁的操作方法，可以实现每次只允许一个线程访问\n\n```java\npublic sychronized int saleTicket(){\n   .....\n}\n```\n\n**Lock**\n\n> 使用方式\n\n```java\n//创建可重入锁\nprivate final ReenrantLock lock=new ReentrantLock();\n\npublic void lockSale(){\n  //加锁\n  lock.lock();\n  ...\n  //解锁\n  lock.unlock();\n}\n```\n\n> 概念和实现原理\n\n可重入锁：在进入操作方法的第一步上锁，出操作方法的最后一步解锁\n\n> Lock和Sychronized的区别\n\n1、`Lock`需要手动上锁和释放锁，`Sychronized`不需要手动操作（异常自动释放锁），只需要加到对应的操作方法上即可\n\n2、`Lock`比`Sychronized`功能强大。`Lock`可扩展性更强（知道是否获取到锁、可以让那个等待线程响应中断）\n\n3、`Lock`性能要高于`Sychronized`', '0', '1', '1', '1', '2022-07-04 18:22:49', '2022-07-04 18:22:49');
INSERT INTO `tb_card_answer` VALUES ('23', '27', '1. 创建资源类，在类中创建属性和操作方法\n2. 操作方法\n   1. 判断是否有锁（this.wait()）\n   2. 业务处理\n   3. 通知另一个线程 notify()\n3. 创建多个线程，调用资源类的操作方法\n\n使用`synchnorized`实现线程交替执行\n\n`this.wait()`线程等待\n\n`this.notifyAll()`线程唤醒\n\n```java\n/**\n * 1. 创建资源类，创建属性和操作方法\n * 2. 判断、操作、通知\n * 3. 创建多个线程调用操作方法\n */\npublic class AlternateThread {\n    public static void main(String[] args) {\n        AlternateTicket ticket = new AlternateTicket();\n        new Thread(() -> {\n            for (int i = 0; i < 10; i++) {\n                try {\n                    ticket.incr();\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            }\n        }, \"A\").start();\n        new Thread(() -> {\n            for (int i = 0; i < 10; i++) {\n                try {\n                    ticket.decr();\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            }\n        }, \"B\").start();\n    }\n}\nclass AlternateTicket {\n    private int num = 10;\n    public synchronized void incr() throws InterruptedException {\n        //判断\n        if (num > 10) {\n            this.wait();\n        }\n        //操作\n        num++;\n        System.out.println(Thread.currentThread().getName() + \":\" + num);\n        //通知\n        this.notifyAll();\n    }\n    public synchronized void decr() throws InterruptedException {\n        //判断\n        if (num <= 10) {\n            this.wait();\n        }\n        //操作\n        num--;\n        System.out.println(Thread.currentThread().getName() + \":\" + num);\n        //通知\n        this.notifyAll();\n    }\n}\n\n可以看到A和B交替执行且输出10、11\n```\n\n使用`lock`实现线程交替执行\n\n+ 使用Lock.condition()对象进行线程等待和线程唤醒\n+ `lock.await()`线程等待\n\n+ `lock.signalAll()`唤醒所有线程\n\n```java\n/**\n * 1. 创建资源类，创建属性和操作方法\n * 2. 判断、操作、通知\n * 3. 创建多个线程调用操作方法\n */\npublic class LockThread {\n    public static void main(String[] args) {\n        AlternateLockTicket ticket = new AlternateLockTicket();\n        new Thread(() -> {\n            for (int i = 0; i < 10; i++) {\n                try {\n                    ticket.incr();\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            }\n        }, \"A\").start();\n        new Thread(() -> {\n            for (int i = 0; i < 10; i++) {\n                try {\n                    ticket.decr();\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            }\n        }, \"B\").start();\n    }\n}\n\nclass AlternateLockTicket{\n    private int num=10;\n    //创建锁对象\n    private final Lock lock =new ReentrantLock();\n    Condition condition=lock.newCondition();\n    public void incr() throws InterruptedException {\n        lock.lock();\n        try{\n            //判断\n            if (num>10){\n                condition.await();\n            }\n            //操作\n            num++;\n            System.out.println(Thread.currentThread().getName() + \":\" + num);\n            //通知\n            condition.signalAll();\n        }finally {\n            lock.unlock();\n        }\n    }\n    public void decr() throws InterruptedException {\n        lock.lock();\n        try{\n            //判断\n            if (num<=10){\n                condition.await();\n            }\n            //操作\n            num--;\n            System.out.println(Thread.currentThread().getName() + \":\" + num);\n            //通知\n            condition.signalAll();\n        }finally {\n            lock.unlock();\n        }\n    }\n}\n\n```', '0', '1', '1', '1', '2022-07-04 18:22:50', '2022-07-04 18:22:50');
INSERT INTO `tb_card_answer` VALUES ('24', '28', '问题根由：读和写操作同步执行\n\n多个线程同时对同一个线程不安全的集合进行读和写操作导致出现`ConcurrentModificationException`异常\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/At528D.png)\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/RMZU93.png)', '0', '1', '1', '1', '2022-07-04 18:22:50', '2022-07-04 18:22:50');
INSERT INTO `tb_card_answer` VALUES ('25', '29', '不直接使用ArrayList而是使用一些代替类\n\n+ **Vector**：`Vector`替代`ArrayList`\n\n  不使用`ArrayList`，而是使用`Vector`。其实现的`add`方法是加了`synchronized`关键字\n\n  ```\n  List<String> list = new Vector<>();\n  ```\n\n+ **Collections工具类**：使用`Collections.synchronizedList(new ArrayList())`\n\n  ```\n  List<String> list= Collections.synchronizedList(new ArrayList<>());\n  ```\n\n+ **CopyOnWriteArrayList**：使用JUC中的`CopyOnWriteArrayList()`\n\n  ```\n  List<String> list=new CopyOnWriteArrayList<>();\n  ```\n\n  写时复制技术：并发读，写入并不直接写入list，而是写入一个copyList然后将copyList覆盖原本的list\n\n  进行add操作的时候\n\n  1. 将原本的list复制出来一份copyList\n  2. 在复制中的copyList进行写\n  3. 写完之后与原本的那个list进行覆盖\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/XzaoLF.jpg)', '0', '1', '1', '1', '2022-07-04 18:22:50', '2022-07-04 18:22:50');
INSERT INTO `tb_card_answer` VALUES ('26', '30', '1. 后者有返回值\n2. 如果出现异常会抛出\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/XWWaYA.jpg)', '0', '1', '1', '1', '2022-07-04 18:22:50', '2022-07-04 18:22:50');
INSERT INTO `tb_card_answer` VALUES ('27', '31', '**countdownLatch**计数器\n\n直到所有线程运行一定次数才执行await里面的方法\n\n1. 使用\n2. 每个线程调用countDown使计数器-1\n3. 调用await方法，使值减到0的时候执行其中的代码\n\n**cyclicBarrier**循环栅栏\n\n让所有线程都等待，直到所有线程都达到一个固定的点才执行barrierAction方法\n\n\n\n相当于多段操作，每段操作使用await()方法阻塞等待在那。比如部队里士兵训练。当所有士兵都跑完步才开始去往食堂，当所有士兵都打完饭才开始吃饭，当所有士兵都吃完饭才去洗澡\n\n需要注意的是，协调好ThreadSize、PartiesSize、TaskSize之间的关系，不然就会导致永远等待\n\n**semaphore**信号灯\n\n多个资源被相互竞争，只有一个线程释放占用的资源，才能会有一个线程能占用这个资源\n\n汽车抢占车位', '0', '1', '1', '1', '2022-07-04 18:22:50', '2022-07-04 18:22:50');
INSERT INTO `tb_card_answer` VALUES ('28', '32', '> 首先先声明一个事情。这些这锁那锁其实本身不存在这些锁，也就是说他们不是名词，应该说他们是动词。他们是用来解决各种问题而提出来的各种解决方案。\n\n+ 自旋锁和适应性自旋锁（是否放弃已获取的CPU资源来等待阻塞）\n\n+ 无锁、偏向锁、轻量级锁、重量级锁（按照锁的资源消耗来区分）\n\n+ 公平锁、非公平锁（多个线程对同一资源竞争是否公平）\n\n+ 可重入锁、非可重入锁（多个锁的嵌套是否允许获取一把钥匙打开所有锁）\n\n+ 独享锁、共享锁（写锁和读锁）\n\n+ 乐观锁、悲观锁（乐观（亡羊补牢）和悲观（殚精竭虑）的看待是否会被别人修改数据这回事）', '0', '1', '1', '1', '2022-07-04 18:22:50', '2022-07-04 18:22:50');
INSERT INTO `tb_card_answer` VALUES ('29', '33', '**悲观锁**\n\n每个线程对同一个资源进行操作的时候，都需要进行加锁，使用完资源之后释放锁。\n\n优点：解决所有并发问题\n\n缺点：不支持并发执行，效率很低\n\n**乐观锁**\n\n对同一个数据操作的时候，记录一个版本号。每次进行修改的时候更新这个版本号。然后所有线程进行更新操作的时候都需要判断该版本号和第一次获取的时候的版本号是否一致\n\n\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/vjTUx4.png)', '0', '1', '1', '1', '2022-07-04 18:22:50', '2022-07-04 18:22:50');
INSERT INTO `tb_card_answer` VALUES ('30', '34', '> 两者关系\n\n后者是前者的补充（优化）\n\n> 自旋锁的由来\n\n线程1和线程2竞争锁。线程1没有获得锁，但是如果这个时候切换CPU去执行线程2释放锁。可能切换还没完成线程2就释放了锁。又得切换回来。所以如果CPU是多核的，就不如直接**线程1先自己玩会并循环看着这个资源的释放（自旋）来获得锁**\n\n适应性自旋锁就是：线程1告诉了线程3我等了一会就等到了资源的释放，你也等会。本来线程3想等10。结果听了这话觉得有门，就准备等20s。（反之也是一样，线程1告诉线程3我等了10s还没等到，那你觉得线程3应该怎么办？）这里的10s只是举例子，默认是指自旋10次\n\n所以**自旋锁的本质其实是锁的优化**也是一种乐观锁的实现过程\n\n> 自旋锁的优缺点\n\n如果这种代码执行的很快（锁释放的很快），这就避免了切换CPU带来的资源消耗。这就是优点\n\n优点带来了缺点，如果这块代码执行的很慢，或者很多的线程竞争这个资源，这个时候就会导致这个自旋的线程一直消耗CPU资源在这玩不干活。\n\n> 自旋锁的使用\n\n在JDK1.4.2到JDK1.6之间的版本，需要手动使用`-XX:+UseSpinning`来开启。如果是JDK1.6之后就是默认开启的（自适应自旋锁）', '0', '1', '1', '1', '2022-07-04 18:22:51', '2022-07-04 18:22:51');
INSERT INTO `tb_card_answer` VALUES ('31', '35', '> 区分原因\n\n按照锁对资源消耗的级别区分：一般能用低级就不用高级\n\n> 四锁的概念\n\n无锁（直接放行）：没有对资源进行锁定，所有线程访问同一个资源。但是同时只有一个线程进行修改。循环修改的一种实现 CAS就是无锁\n\n偏向锁（有吊牌）：这个关键代码只有一个线程会访问。那么这个访问的时候看到是这个线程，就自动给他锁而不用检查锁的状态（相当于管大门的认识了老王，就不需要登记就直接放行）\n\n轻量级锁（需要登记）：有一个线程访问偏向锁，偏向锁发现这个线程不是我等的那个线程，所以就将该锁进化成轻量级锁。其他线程需要进行自旋等待来尝试获取锁（多个线程的多次CAS）（门卫本来以为只有老王会来，结果来了老杨，就让后面来的都进行登记并且玩会手机等着老杨出来才能进入）\n\n重量级锁（厕所关门）：就是遇到没有钥匙就得阻塞该线程，CPU切换到别的线程执行（门卫跟老杨说，今天只能老王进来，你明天再来吧）\n\n> 四锁的关系\n\n这个过程可以称为锁的升级，也可以称为锁的膨胀\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/四级别锁.drawio.png)\n\n只能正向升级，不能降级。\n\n`偏向锁`相对于`无锁`增加了**Mark Word**来标示锁\n\n`轻量级锁`相对于`偏向锁`增加了**自旋锁（适应性自旋锁）**操作来竞争锁\n\n`重量级锁`相对于`轻量级锁`增加了阻塞等待或者说悲观锁来实现\n\n> 四锁的实现\n\n**锁的实现**\n\n锁存放在对象头的`Mark word`中（对象存放在堆中，对象包含对象头、实例数据、对齐填充），对象头包括`Mark word`，类指针，arrayLength（数组的时候有数组长度）。\n\n![](/Users/kaochong/Documents/锁.drawio.png)\n\nmarkword的最后两位：\n\n| 锁类型   | 锁标示 | 对象头中存储的内容（依次增加）                   |\n| -------- | ------ | ------------------------------------------------ |\n| 无锁     | 01     | 1. hashCode<br>2. 分代年龄<br>3. 是否是偏向锁(0) |\n| 偏向锁   | 01     | 4. 偏向线程<br>5. 偏向时间戳<br>6. 是偏向锁（1） |\n| 轻量级锁 | 00     | 指向栈中Monitor的指针                            |\n| 重量级锁 | 10     | 指向重量级锁的指针                               |\n\n**无锁**：通过不断的尝试修改进行对同一个资源的修改\n\n**偏向锁**：通过记录偏向锁的线程id，来允许对应线程直接访问资源。而如果出现一个其他线程访问。两种情况\n\n+ 仍然是偏向锁：将该次访问的线程id记录下来。之后该偏向锁归该线程id所有（老王儿子来了）\n+ 不是偏向锁：升级成轻量级锁（门卫看管严了）\n\n具体偏向锁升级成轻量级锁可以看[大佬：java 偏向锁怎么升级为轻量级锁](https://www.cnblogs.com/baxinhua/p/9391981.html)\n\n这里有一个暂停原始线程的一个过程\n\n对象头中存储的一些信息这里偏向锁用到的有这几个\n\n+ 锁标志位\n+ 是否是偏向锁\n+ 偏向锁的线程ID\n\n如果`锁标志位`是01，就去判断`是否是偏向锁`的值来决定是不是偏向锁。如果是，就去比较当前获取锁的ID是否是`偏向锁的线程ID`如果是就直接放行允许获取锁。\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/eB9Get.jpg)\n\n**轻量级锁**：多个线程访问同一个资源，使用自旋的方式进行等待。如果自旋超过一定的次数。对于其他线程来说，就会将该锁升级成重量级锁\n\n**重量级锁**：阻塞等待，平常意义上的锁。CPU切换去干别的事情', '0', '1', '1', '1', '2022-07-04 18:22:51', '2022-07-04 18:22:51');
INSERT INTO `tb_card_answer` VALUES ('32', '36', '> 原理举例\n\n**公平锁**：多个线程对锁的竞争是差不多公平的\n\nA执行了20次，B执行了19次，C执行了19次\n\n特点：各个线程都会有执行的可能，但是效率相对于较低\n\n实现逻辑：其中有个方法将多个线程放入队列中进行排队执行\n\n**非公平锁**：\n\n多个线程对锁竞争是不公平的\n\nA执行20次，B执行0次，C执行1次\n\n特点：锁的竞争很不公平，但是执行的效率较高\n\n实现逻辑：直接进行业务执行，哪个线程能竞争到锁随意\n\n`new ReentrantLock()`的构造方法中可以传入`boolean`参数，`false`（默认）表示非公平锁\n\n> 公平锁优缺点\n\n优点：不会出现有的线程被饿死的情况\n\n缺点：效率相对于而言低一些。需要不停的唤醒阻塞线程\n\n> 公平锁实现\n\n通过维护一个线程的队列。每次获取锁必须是排队的第一个，释放锁之后就自动去队列末尾继续排队等待', '0', '1', '1', '1', '2022-07-04 18:22:51', '2022-07-04 18:22:51');
INSERT INTO `tb_card_answer` VALUES ('33', '37', '> 概念和实例\n\n递归锁：一个线程在外层获取到锁之后进入内层会自动获取锁（锁的对象是同一个）。\n\n```java\npublic void static main(String[] args){\n  synchronized (this){\n     //xxxxx\n    synchronized(this){\n      //xxxxx\n    }\n  }\n}\n```\n\n锁的内部如果还有锁，该线程都可以访问。也就是多重锁，只要线程竞争到了锁资源，就可以访问到最内部也不用再重新竞争锁\n\n`synchronized`是隐式的可重入锁\n\n`ReentrantLock`是显式（需要手动上锁和解锁）的可重入锁\n\n` NonReentrantLock`不可重入锁。\n\n\n\nReentrantLock和NonReentrantLock都继承AQS，其中维护了一个status来记录重入次数。\n\n> 优点\n\n优点：一定程度降低死锁的情况', '0', '1', '1', '1', '2022-07-04 18:22:51', '2022-07-04 18:22:51');
INSERT INTO `tb_card_answer` VALUES ('34', '38', '> 实现原理\n\n反编译的结果发现`monitorenter`和`monitorexit`将一块代码块包裹起来\n\n在方法内部的synchronized：\n\n+ `monitorenter`，针对监视器锁monitor（具体需要看synchronized的位置）\n\n  如果monitor的进入数为0，则该线程可以进入，进入之后将其加1\n\n  如果这个线程重新进入，则可以进入并再进行+1\n\n  如果有别的线程占用monitor，则该线程阻塞，直到monitor变成0才可以进入\n\n+ `monitorexit`，执行monitorexit必须是monitor的持久者，每次执行将monitor的进入数-1，直到减成0退出锁定状态。\n\n在方法上的synchronized：\n\n没有上述两个指令，只是在方法定义上有`ACC_SYNCHRONIZED`关键字，当方法调用时，会查看该线程是否获取了monitor，如果有就执行，没有就阻塞', '0', '1', '1', '1', '2022-07-04 18:22:51', '2022-07-04 18:22:51');
INSERT INTO `tb_card_answer` VALUES ('35', '39', '> 什么是CAS\n\nCAS全称Compare And Swap（比较和交换），乐观锁的一种实现，无锁算法。无锁的情况下实现多线程之间的变量同步。\n\n\n\n> 为什么要有这种东西？\n\n我也好恨啊，为什么有这么多晦涩难懂的东西，学的烦死了烦死了\n\n为了无锁的访问共享资源而不出现问题。\n\n那么为什么要无锁呢？为了免除加锁使用操作系统的mutex这种操作，避免内核态和用户态的频繁切换带来了效率的损耗\n\n> CAS算法原理\n\n涉及三个操作数\n\n+ 需要读写的内存值V\n+ 用来进行比较的A\n+ 需要写入的新值B\n\n```\n讲个故事：小红有三个追求者小甲、小乙、小丙\n\n小红发了个朋友圈，“今天看上了一款丝袜叫做巴黎世家”\n\n小甲、小乙、小丙第二天都拿着买好的礼物去登门拜访。结果小甲先到就带走了小红共进晚餐。然后小乙、小丙拿着巴黎世家去找小红，小红说我现在已经不喜欢这个了，我喜欢前男友面膜，于是乎小乙、小丙买到了前男友面膜又去找小红。小乙先到了共进晚餐。小丙拿着前男友面膜去找小红，小红说我现在不想要了我想要迪奥999\n\n这里的小红是一个共享资源\n小甲、小乙、小丙是三个线程\n小红想要的：巴黎世家、前男友面膜、迪奥999是需要读写的内存值V\n\n小甲、小乙、小丙他们拿的礼物是用来进行比较的A\n\n需要写入的新值B是小红的下一个想法\n```\n\n\n\n第一步：进入一个CAS循环\n\n第二步：判断A是否等于V。等于则B替换V。不等于则将V赋值给A\n\n第三步：再进入一个CAS循环\n\n```java\n1. V=10，线程1想要去对V进行自增1，所以线程1的A=10\n2. 线程2已经进行了自增，此时V=11\n3. 线程1发现，A!=V。所以将V赋值给A，则A=11\n4. 线程1再进行判断交换\n  \n//含义就是下面的代码（啥也不是的代码）这个代码是原子的\npublic JNI Integer cas(int A,int B){\n  if(A=v){\n    v1=v;\n    v=B;\n    return v1;\n  }else{\n    A=V;\n    return false;\n  }\n}\n```\n\n当且仅当V=A时（比较），将B替换V（替换）。**这个操作在Java的底层借助于一个CPU指令完成的。属于原子操作**，所以不会出现比较了还没更新另一个更新的情况。在更新的过程中可能会出现长时间的自旋来等待结果\n\n> CAS的三大问题\n\n1、ABA问题：就是内存中的值从A->B->A这个时候另一个线程就以为这个A是没有发生变化的，就可能会造成业务性的错误。解决办法就是增加版本号的概念 1A->2B->3A\n\n2、循环时间长开销大：多个线程进行修改，可能会导致线程之间反复更新一直不成功\n\n3、只能保证一个共享变量的原子操作：Java本身支持的只针对一个变量的修改可以进行CAS操作。不支持多个变量或者多个对象等的修改。（JDK1.5AtomicReference类可以保证对象之间原子性从而将多个变量放到对象中）\n\n> CAS的原子性\n\n依赖于底层的操作系统实现。也就是每种操作系统都有一个原语对应着CAS的操作。比如X86架构的cmpxchg。\n\n> CAS的实现`AtomicInteger`\n\n可以做到并发的情况下进行自增线程之间进行信息同步\n\n```java\n    public final int incrementAndGet() {\n        return unsafe.getAndAddInt(this, valueOffset, 1) + 1;\n    }    \npublic final int getAndAddInt(Object var1, long var2, int var4) {\n        int var5;\n        do {\n            var5 = this.getIntVolatile(var1, var2);\n        } while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4));\n\n        return var5;\n    }\n\n    public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5);\n\ndo-while就是自旋\ncompareAndSwapInt就是CAS的原子操作\nnative就是本地方法C++实现\n\n```', '0', '1', '1', '1', '2022-07-04 18:22:51', '2022-07-04 18:22:51');
INSERT INTO `tb_card_answer` VALUES ('36', '40', '`java.util.concurrent.locks.AbstractQueuedSynchronizer`\n\n> 问题：为啥要有AQS\n\n1、（业务不通用）虽然有了底层的CAS算法，但是开发者直接使用unsafe.compareAndSwap()并不能很切合的与业务结合。我们需要开发针对各种参数的实现方法compareAndSwapInt、compareAndSwapLong等\n\n2、（锁定的太局限）CAS底层只针对一个值进行了管理。如果我们想要锁定的是一个对象或者说一堆值呢\n\nAQS就是为了解决上述问题而出现的\n\n> 问题：AQS是什么\n\nAQS就是一个CAS算法的业务上层的真实实现的类库，为了解决CAS只能面向一个值锁定的通用性问题\n\n> AQS的实现原理\n\nAQS有两个关键的成员变量\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/Q82qSG.png)\n\n1. FIFO的双向链表队列。用于在阻塞的时候进行排队等待\n2. 一个state，用于标示是否持有锁，及持有锁的次数。释放锁state就是0 其他线程就可以抢这个锁。这个锁是乐观锁的CAS实现的\n\n\n\n锁肯定有这种方法，获取锁\n\n在AQS中的实现是`acquire`（尝试获取锁，如果获取不到就等待直到获取到锁）和`tryAcquire`（尝试获取锁，获取到获取不到都返回）\n\n```java\n//获取锁\npublic final void acquire(int arg) {\n          //尝试获取锁，如果获取不到就执行下面的代码（这里其实就是第一个判断条件不满足时就会执行下面的判断条件，是一种简单的判断写法）\n    if (!tryAcquire(arg) &&\n    //上面tryAcquire返回false就导致!false=true。所以就会执行acquireQueued(addWaiter(Node.EXCLUSIVE), arg)这个方法。下面这个方法就是将当前线程封装加入到等待队列\n        acquireQueued(addWaiter(Node.EXCLUSIVE), arg))\n        selfInterrupt();\n}\n\nfinal boolean acquireQueued(final Node node, int arg) {\n    boolean failed = true;\n    try {\n        boolean interrupted = false;\n        for (;;) {\n            final Node p = node.predecessor();\n            if (p == head && tryAcquire(arg)) {\n                setHead(node);\n                p.next = null; // help GC\n                failed = false;\n                return interrupted;\n            }\n            if (shouldParkAfterFailedAcquire(p, node) &&\n                parkAndCheckInterrupt())\n                interrupted = true;\n        }\n    } finally {\n        if (failed)\n            cancelAcquire(node);\n    }\n}\n\nprivate Node addWaiter(Node mode) {\n    Node node = new Node(Thread.currentThread(), mode);\n    // 将当前节点插入尾节点的方法：获取尾节点的指针，将当前节点的前指针指向尾节点的。原本尾节点的后指针指向当前节点\n    Node pred = tail;\n    if (pred != null) {\n        node.prev = pred;\n        if (compareAndSetTail(pred, node)) {\n            pred.next = node;\n            return node;\n        }\n    }\n  //如果尾节点不存在，就进行完整的入队操作\n    enq(node);\n    return node;\n}\n```\n\n+ 队列中只有head节点在自旋获取锁，其他的节点都被挂起\n+ 在正在操作共享资源的线程被释放的同时唤醒所有挂起的线程并执行头节点', '0', '1', '1', '1', '2022-07-04 18:22:51', '2022-07-04 18:22:51');
INSERT INTO `tb_card_answer` VALUES ('37', '41', '> 多线程下变量的不可见性\n\n```java\n//        private static volatile int count = 0;\n    private static int count = 0;\n\n    public static void main(String[] args) throws InterruptedException {\n        new Thread(() -> {\n            try {\n                Thread.sleep(1000);\n                count++;\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            System.out.println(\"附加线程count=\" + count);\n        }).start();\n        while (true) {\n            if (count > 0) {\n                System.out.println(\"变更后主线程中count=\" + count);\n                break;\n            }\n        }\n    }\n```\n\n参考上面代码。在先让线程A执行，再执行其他线程对变量进行修改，就会导致A获取的变量参数不会随着修改而改变。如果增加volatile之后发现，A获取的参数会随着其他线程的修改而被通知到。\n\n总结：线程1获取了变量的值。线程2对变量进行了修改，此时线程1再次获取仍然使用的是原本获取的值。\n\n> 不可见性的原因\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/线程变量不可见性原因.drawio.png)\n\n\n\n总结：共享变量存储在主内存中，每个线程都有自己的工作内存。主内存的数据修改不会主动同步到试用这个数据的线程独有的工作线程中。\n\n> 解决不可见性\n\n**1、加锁访问共享变量**\n\n```java\n    private static int count = 0;\n\n    public static void main(String[] args) throws InterruptedException {\n        Thread t = new Thread(() -> {\n            try {\n                Thread.sleep(1000);\n                count++;\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            System.out.println(\"附加线程count=\" + count);\n        });\n        t.start();\n        while (true) {\n            synchronized (t) {\n                if (count > 0) {\n                    System.out.println(\"变更后主线程中count=\" + count);\n                    break;\n                }\n            }\n        }\n    }\n```\n\n锁住的是对成员变量获取的那个线程（不是修改的线程）\n\n原因：一个线程进入synchronized代码块后执行过程\n\n1. 获取锁对象\n2. 清空工作线程\n3. **拷贝共享变量到工作内存（也就是重新获取，而不是直接使用工作内存中的数据）**所以每次进行while循环都会重新获取一次。\n4. 执行代码\n5. 将修改后的值刷新的主内存\n6. 释放锁\n\n**2、对共享变量增加volatile关键字修饰**\n\n```java\n    private static volatile int count = 0;\n//    private static int count = 0;\n\n    public static void main(String[] args) throws InterruptedException {\n        Thread t = new Thread(() -> {\n            try {\n                Thread.sleep(1000);\n                count++;\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            System.out.println(\"附加线程count=\" + count);\n        });\n        t.start();\n        while (true) {\n            if (count > 0) {\n                System.out.println(\"变更后主线程中count=\" + count);\n                break;\n            }\n        }\n    }\n```\n\n原因：\n\n**<font color=\"red\">volatile修饰的变量发生修改并通知到主内存之后，“主内存”会通知所有使用该变量的线程作废该变量在其工作内存中的值</font>**\n\n主线程中的值失效之后，就必须得去主内存中重新获取值\n\n\n\n\n\n> Volatile的特性\n\n**1、volatile不能保证原子性操作**\n\n原子性：一次操作中的所有行为，要么全部成功要么全部失败，且该线程期间状态一致。\n\n```java\n    private volatile static Integer count = 0;\n\n    public static void main(String[] args) throws InterruptedException {\n        for (int i = 0; i < 100; i++) {\n            new Thread(() -> {\n\n                for (int j = 0; j < 10000; j++) {\n                    count++;\n                }\n            }, String.valueOf(i)).start();\n        }\n        Thread.sleep(10000);\n        System.out.println(count);\n    }\n\nexport:978024\n```\n\n为什么：因为被volatile修饰的count进行自加并不是原子操作，需要先从主内存读取数据到工作内存，然后自增，然后将数据写回主内存。在这个过程中，如果有两个线程同时将数据从100自增到101，然后写入主内存，就会出现问题。结果只增加了一次。即使增加了volatile，也只是保证共享变量在所有线程的可见，而不能保证顺序执行\n\n解决办法：加锁来解决原子性的问题\n\n\n\n**2、禁止指令重排序**\n\n什么是重排序：编译器、指令解释器、操作系统等，为了更好的执行代码提升性能，可能会对代码的指令进行优化排序。如JIT，缓冲区，指令重排序等。\n\n重排序的问题：有些冲排序的情况会导致不按照代码的想法进行执行。比如CPU认为指令顺序调整之后对业务信息和逻辑没有影响。但是在高并发的情况下可能就会出现影响。这个时候如果CPU进行了代码优化，则可能会导致业务问题。（比如a=b;b=1;b=a调整了顺序就会出现结果不一致的问题）\n\n解决重排序：在要修改的变量上增加volatile来避免指令重排序。', '0', '1', '1', '1', '2022-07-04 18:22:52', '2022-07-04 18:22:52');
INSERT INTO `tb_card_answer` VALUES ('38', '42', '存在的意义：\n\n1、为了简化对线程的操作\n\n2、为了减少开发人员创建线程过多而带来问题\n\n3、为了减少在需要创建多个线程的时候，带来时间的开销\n\n\n\n> 如何使用线程池\n\n**使用Executors创建线程操作**\n\n实际开发中不建议使用，因为各种方法的创建都有局限性，不能满足多变业务情况的需要。\n\n1、创建线程池对象\n\n```java\n//根据传入的参数固定线程数，也就是给定的线程数越多处理线程越多。然后工作队列会按照线程数每次分配固定的任务数。缺点：线程处理不过来任务，任务就放到了队列中。会导致队列占用内存过大导致OOM\nExecutorService newFixedThreadPool = Executors.newFixedThreadPool(100);\n//没有核心线程，最大线程为2^31-1。且队列为非阻塞队列。也就是任务再多也没有上限，不会出现线程等待的情况。缺点：易出现CPU满（不安全，线程的创建被业务关联，容易造成CPU卡死，比如我100万个任务，可能就创建超过50w的线程，线程是被CPU调度执行的，和内存没关系。）\n        ExecutorService newCachedThreadPool = Executors.newCachedThreadPool();\n//线程池中只有一个线程，依次处理。缺点：线程处理不过来任务，任务就放到了队列中。会导致队列占用内存过大导致OOM \n        ExecutorService newSingleThreadExecutor = Executors.newSingleThreadExecutor();\n```\n\n2、使用线程池提交线程任务\n\n```java\nnewFixedThreadPool.execute(new MyTask(i));\n```\n\n\n\n**自定义的线程管理对象**\n\n直接调用`ThreadPoolExecutor`创建线程池管理对象。根据业务的特性设置其corePoolSize、maximumPoolSize等参数，所以这个时候就需要深入理解`ThreadPoolExecutor`。', '0', '1', '1', '1', '2022-07-04 18:22:52', '2022-07-04 18:22:52');
INSERT INTO `tb_card_answer` VALUES ('39', '43', 'newFixedThreadPool、newCachedThreadPool、newSingleThreadExecutor其底层都是调用的`ThreadPoolExecutor`构造方法\n\n```java\n    public ThreadPoolExecutor(int corePoolSize,\n                              int maximumPoolSize,\n                              long keepAliveTime,\n                              TimeUnit unit,\n                              BlockingQueue<Runnable> workQueue,\n                              ThreadFactory threadFactory,\n                              RejectedExecutionHandler handler) {\n        if (corePoolSize < 0 ||\n            maximumPoolSize <= 0 ||\n            maximumPoolSize < corePoolSize ||\n            keepAliveTime < 0)\n            throw new IllegalArgumentException();\n        if (workQueue == null || threadFactory == null || handler == null)\n            throw new NullPointerException();\n        this.acc = System.getSecurityManager() == null ?\n                null :\n                AccessController.getContext();\n        this.corePoolSize = corePoolSize;\n        this.maximumPoolSize = maximumPoolSize;\n        this.workQueue = workQueue;\n        this.keepAliveTime = unit.toNanos(keepAliveTime);\n        this.threadFactory = threadFactory;\n        this.handler = handler;\n    }\n```\n\n+ corePoolSize，核心线程数。可以理解成初始化线程数量\n+ maximumPoolSize，最大允许创建的线程数。在核心线程数之外，如果不满足业务需要，就会继续创建线程。直到线程总数达到该值为止。\n+ keepAliveTime，线程空闲多久释放\n+ unit，keepAliveTime的单位\n+ workQueue，工作队列，也就是任务超过了每个线程执行一个的时候进行阻塞等待时的队列\n+ threadFactory，线程工厂，创建线程的地方\n+ handler，如果任务超过阻塞队列允许承受的最大范围，选择的四种拒绝策略\n\n概述任务的执行（100个任务，corePoolSize=10、maximumPoolSize=50、keepAliveTime=10s、workQueue.size()=10）：\n\n1、将任务分配给10个核心线程进行执行（0-10）\n\n2、将剩下90个任务放到workqueue中，发现只能放十个（10-21）\n\n3、没记录一个任务就创建一个线程，直到新创建的线程+核心线程数=maximumPoolSize=50为止。这个时候是（21-70）\n\n4、发现还有没办法分配的任务，直接抛出异常，异常处理方式就俺咋后配置的handler拒绝策略来执行', '0', '1', '1', '1', '2022-07-04 18:22:52', '2022-07-04 18:22:52');
INSERT INTO `tb_card_answer` VALUES ('40', '44', '队列为ArrayBlockingQueue时（基本原理，不同的队列可能根据参数导致结果不太一样）\n\n提交优先级：\n\n1、核心线程\n\n2、工作队列\n\n3、非核心线程\n\n执行优先级\n\n1、核心线程\n\n2、非核心线程\n\n3、工作队列\n\n100个糖小明往嘴巴里塞了第1-10颗，往妈妈口袋里塞了第11-20颗。然后发现塞不下了，就喊了妹妹小红过来一起吃，小红就往嘴里也塞了第21-30颗。然后剩下就不要了。\n\n这个时候糖被拿出来的顺序是1-10->11-20->21-30\n\n但是糖被吃掉的顺序是1-10->21-30->11-20', '0', '1', '1', '1', '2022-07-04 18:22:52', '2022-07-04 18:22:52');
INSERT INTO `tb_card_answer` VALUES ('41', '45', 'AbortPolicy:丢弃任务并抛出RejectedExecutionException异常。 （默认），针对的是关键业务。如果丢弃会出现问题的情况\n\nDiscardPolicy：丢弃任务，但是不抛出异常。针对可执行可不执行或者有补偿措施的任务，比如（只是举个例子表达程度）日志记录往IO文件里面写入，真实丢了就丢了不能因为这个导致线上系统报警吧。\n\nDiscardOldestPolicy：丢弃队列最前面的任务，然后重新提交被拒绝的任务。喜新厌旧\n\nCallerRunsPolicy：由调用线程（提交任务的线程）处理该任务', '0', '1', '1', '1', '2022-07-04 18:22:52', '2022-07-04 18:22:52');
INSERT INTO `tb_card_answer` VALUES ('42', '46', '+ 直接提交队列（SynchronousQueue）：没有容量，执行一个插入操作就需要执行一个删除操作，否则就会阻塞等待；1\n+ 有界任务队列（ArrayBlockingQueue）：突出的特点就是上面的**提交优先级**。任务多余corePoolSize就会存入队列中，如果超过队列就会创建线程直到达到maximumPoolSize；有限大\n+ 无界任务队列（LinkedBlockingQueue）：没有maximumPoolSize的概念，队列会保存所有除了核心线程管理的任务。（易出现任务一直增长直到资源耗尽的情况）；无限大\n+ 优先任务队列（PriorityBlockingQueue）：正常队列是先进先出。这个队列可以自定义任务的优先级来执行；自定义执行顺序', '0', '1', '1', '1', '2022-07-04 18:22:52', '2022-07-04 18:22:52');
INSERT INTO `tb_card_answer` VALUES ('43', '47', 'runnable和callable的最大区别就在于callable可以获取到线程执行的结果\n\nexecute：（执行没有返回值）只能执行runnable类型的任务\n\nsubmit：（执行有返回值）两种都可以，submit有返回值，返回的是一个 future，也就是线程执行完成之后可以调用future中的get方法来显示的告诉开发者线程执行的顺利。', '0', '1', '1', '1', '2022-07-04 18:22:52', '2022-07-04 18:22:52');
INSERT INTO `tb_card_answer` VALUES ('44', '48', 'Shutdown：会等任务都执行完成之后再关闭线程池\n\nshotdownNow：遍历线程池中的所有线程，循环调用线程的`interrupt`方法。使线程结束并关闭线程池。', '0', '1', '1', '1', '2022-07-04 18:22:52', '2022-07-04 18:22:52');
INSERT INTO `tb_card_answer` VALUES ('45', '49', 'Java线程其实是对操作系统线程的一个**映射**，所以每当挂起或者唤醒一个线程都要**切换操作系统的内核态**。这种切换是重量级的，在很多时候**切换消耗的时间反倒低于本身线程执行需要的时间**。这样就会导致使用**synchronized**会对程序的性能产生很多的影响。\n\n\n\n从Java6开始对Synchronized进行了很多优化。引入了`无锁`，`偏向锁`，`轻量级锁`，`重量级锁`。就是为了各种业务的场景来完成对应的优化', '0', '1', '1', '1', '2022-07-04 18:22:52', '2022-07-04 18:22:52');
INSERT INTO `tb_card_answer` VALUES ('46', '50', '\n# 简单的markdown（一级标题）\n\n## 二级标题\n\n测试一下代码\n\n```java\npublic class testClass{\n  private String name;\n  private Integer id;\n}\n```\n\n测试一下表格\n\n| 属性 | 类型    | 名称 |\n| ---- | ------- | ---- |\n| id   | Integer | id   |\n| name | String  | 名称 |\n\n\n', '0', '1', '1', '1', '2022-07-05 14:49:38', '2022-07-05 14:49:39');
INSERT INTO `tb_card_answer` VALUES ('47', '51', '程序员可以手动执行System.gc()，通知GC运行， 但是Java语言规范并不保证GC一定会执行。', '0', '1', '1', '1', '2022-07-11 17:56:34', '2022-07-11 17:56:34');
INSERT INTO `tb_card_answer` VALUES ('48', '52', '![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/JVM内存结构.drawio.png)', '0', '1', '1', '1', '2022-07-11 17:56:34', '2022-07-11 17:56:34');
INSERT INTO `tb_card_answer` VALUES ('49', '53', '将Java编译后的类加载到Java虚拟机中的工具', '0', '1', '1', '1', '2022-07-11 17:56:34', '2022-07-11 17:56:34');
INSERT INTO `tb_card_answer` VALUES ('50', '54', '1. 启动类加载器（**BootStrap** classLoader）：最底层的加载器，加载/jre/lib/rt.jar和charset.jar包下的class文件。\n2. 扩展类加载器（Extension classLoader）：可以支持一些扩展的拦截类，加载/jre/lib/ext下的class文件。\n3. 应用（系统）类加载器（System/Application classLoader）：也就是加载我们日常写的Class文件。\n4. 自定义类加载器（Custome ClassLoader）\n\n所有加载加载器的加载器都是BootStrap加载器，也就是说这四者之间并不是父子关系的\n\nbootstrap是C++语言执行的加载操作（Native接口）Java是获取不到的', '0', '1', '1', '1', '2022-07-11 17:56:34', '2022-07-11 17:56:34');
INSERT INTO `tb_card_answer` VALUES ('51', '55', '双亲委派机制是指当一个类加载器收到某个类加载请求时,该类加载器首先会把请求委派给父类加载器（父类再委托给它的父类）。\n\n只有父加载器不能加载才进行加载，也就是从上至下进行加载。', '0', '1', '1', '1', '2022-07-11 17:56:34', '2022-07-11 17:56:34');
INSERT INTO `tb_card_answer` VALUES ('52', '56', '保证内置java类的安全。如果用户无意中创建了一个同样名称同样路径的类，那么没有双亲委派就会倾入损害jvm的基本功能了（当然有意的就另当别论）', '0', '1', '1', '1', '2022-07-11 17:56:34', '2022-07-11 17:56:34');
INSERT INTO `tb_card_answer` VALUES ('53', '57', '**检查缓存是否加载过顺序**是：Application->Extension->BootStrap\n\n**加载顺序**是：BootStrap->Extension->Application\n\n如果有同样的路径同样的命名的class文件，会按照这个顺序来执行\n\n1. 类加载器接收到加载请求\n2. 类加载器向上委托到父类进行父类加载器加载一些父类。循环往复，直到到跟加载器（BootStrap）\n3. 启动类加载器会检查是否能够加载当前这个类。能加载就结束并使用当前的加载器加载，否则抛出异常通知子类进行加载。循环往复直到最后报错“Class Not Found”（我们idea也是能写出来没有继承的类的，只是idea会报错来提示我们，在没有idea的时候这种操作会很频繁发生）\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/iCni7P.png)', '0', '1', '1', '1', '2022-07-11 17:56:34', '2022-07-11 17:56:34');
INSERT INTO `tb_card_answer` VALUES ('54', '58', 'jvm虚拟机中对类的加载是只有用到某个类的时候才会进行这个类的加载\n\n懒加载时机：\n\n+ new/访问静态实例/访问静态方法时，访问final变量\n+ 反射时\n+ 初始化子类，父类先初始化\n+ 虚拟机启动，被执行的主类初始化\n+ 其他', '0', '1', '1', '1', '2022-07-11 17:56:34', '2022-07-11 17:56:34');
INSERT INTO `tb_card_answer` VALUES ('55', '59', '类加载的时机：任何用到这个类的时候，比如new对象、反射该类、调用类的静态方法\n\n举个例子：流程其实和我们开发的时候的写代码顺序是一样的\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/类加载流程.drawio.png)\n\n### **第一步：加载**\n\n该步骤的目的就是将磁盘中的class文件加载到内存中\n\n加载之后，生成两个文件\n\n1. 本身的字节码文件\n2. 生成了一个指向该文件的一个Class对象（用于后续使用的时候能够找到该字节码文件并使用。一个间接访问的操作`nginx`）\n\n### **第二步：连接**\n\n##### 「1」验证\n\n验证加载的class文件\n\n1. 文件格式验证：验证是否为class文件的格式\n2. 元数据验证：对类的元数据进行语义的验证，比如是否有不允许的父类（循环继承等）\n3. 字节码验证：分析方法的代码逻辑是否正确，比如本来定义的是个int类型，结果计算的时候使用long类型\n4. 符号引用验证（符号的定义是java实现的，所以其每个符号的使用方式在jvm中都有一块内存空间对应着），比如Java中没有类似`......`的符号使用方式，这个地方就会报错\n\n\n\n将加载进来的class文件进行格式验证，其中的字节码规范验证，符号引用的验证（符号的定义是java实现的，所以其每个符号的使用方式在jvm中都有一块内存空间对应着）\n\n##### 「2」准备\n\n对类的静态变量分配内存并赋予其默认值\n\n##### 「3」解析\n\n将类中的符号引用替换成直接引用。举个例子，SpringBoot的资源文件我们可能在Java代码中使用的是`${\"aaa.xxx\"}`来获取。这个时候就是将这个符号转换成具体的存储数据的直接引用（只是举个例子方便理解，具体不是这样的哦）\n\n### 第三步：初始化\n\n对类的静态变量进行赋值', '0', '1', '1', '1', '2022-07-11 17:56:34', '2022-07-11 17:56:34');
INSERT INTO `tb_card_answer` VALUES ('56', '60', '第一步，继承ClassLoader\n\n第二步，重写findClass方法，在该方法中进行指定加载类就可以实现自己的类的加载\n\n第三步，找到二进制类的内容，转换成Class对象，用defineClass方法\n\n```java\npublic class UserDefinedClassLoader extends ClassLoader {\n\n    @Override\n    public Class<?> loadClass(String name) throws ClassNotFoundException {\n        FileInputStream fileInputStream = null;\n        ByteArrayOutputStream byteArrayOutputStream = null;\n        try {\n            //加载文件\n            File file = new File(name);\n            fileInputStream = new FileInputStream(file);\n            byteArrayOutputStream = new ByteArrayOutputStream();\n            int a = 0;\n            while ((a = fileInputStream.read()) != 0) {\n                byteArrayOutputStream.write(a);\n            }\n            //转换为字节数组\n            byte[] bytes = byteArrayOutputStream.toByteArray();\n            //加载Class文件返回Class对象\n            return defineClass(name, bytes, 0, bytes.length);\n        } catch (Exception e) {\n            e.printStackTrace();\n        } finally {\n            try {\n                byteArrayOutputStream.close();\n            } catch (IOException e) {\n                e.printStackTrace();\n            }\n            try {\n                fileInputStream.close();\n            } catch (IOException e) {\n                e.printStackTrace();\n            }\n        }\n        return super.loadClass(name);\n    }\n    public static void main(String[] args) {\n        //调用上面的加载器指定路径就好了\n    }\n}\n```', '0', '1', '1', '1', '2022-07-11 17:56:34', '2022-07-11 17:56:34');
INSERT INTO `tb_card_answer` VALUES ('57', '61', '执行引擎使用运行时数据区中的数据来将其翻译成机器指令，CPU解释执行，最后进行内存的回收\n\n就像是做饭的时候厨师（执行引擎）使用厨台上（运行时数据区）的各种蔬菜鱼肉（数据）做成饭菜，最后还需要清理厨台（GC）\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/jvm1.png)\n\n线程私有的:`虚拟机栈`、`本地方法栈`、`程序计数器`\n\n线程共享的:`方法区`、`堆`\n\n\n| 区域             | 共享 | 作用                                                         | 异常                                                         | 备注                                            |\n| ---------------- | ---- | ------------------------------------------------------------ | ------------------------------------------------------------ | ----------------------------------------------- |\n| **程序计数器**   | 私有 | 记录当前线程的执行字节码文件的行号信息                       | Java虚拟机规范中唯一一个没有规定OutOfMemoryError(内存不足错误)的区域。 | --                                              |\n| **Java虚拟机栈** | 私有 | 存放局部变量（基础数据类型和引用数据类型的引用）、操作数据栈、方法出口、动态链接 | 栈深大于允许的最大深度，抛出StackOverflowError(栈溢出错误)。<br/>内存不足时，抛出<br/>OutOfMemoryError(内存不足错误)。 |                                                 |\n| **本地方法栈**   | 私有 | 和Java虚拟机栈类似，不过是为JVM用到的本地方法服务。          | 同上                                                         |                                                 |\n| **堆**           | 共享 | 对象实例,数组等                                              | 内存不足时，抛出<br>OutOfMemoryError(内存不足错误)。         | 通过-Xmx和-Xms控制大小。<br/>GC的主要管理对象。 |\n| **方法区**       | 共享 | 存放类本身信息（版本、字段、方法、接口等）、常量、静态变量、即时编译后的代码等数据。 | 内存不足时，抛出OutOfMemoryError(内存不足错误)。             |                                                 |', '0', '1', '1', '1', '2022-07-11 17:56:34', '2022-07-11 17:56:34');
INSERT INTO `tb_card_answer` VALUES ('58', '62', '用来存储指向下一条指令的地址。由执行引擎读取来确定下一条指令\n\n存储的必然是**当前方法**的指令地址，如果是Native方法则为undefined', '0', '1', '1', '1', '2022-07-11 17:56:34', '2022-07-11 17:56:34');
INSERT INTO `tb_card_answer` VALUES ('59', '63', '![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/虚拟机栈结构.drawio.png)\n\n每个线程在创建的时候都会创建一个虚拟机栈，其中保存着一个一个的栈帧。一个栈帧就对应着一个Java方法\n\n保存方法的局部变量、部分结果以及方法的调用和返回信息', '0', '1', '1', '1', '2022-07-11 17:56:34', '2022-07-11 17:56:34');
INSERT INTO `tb_card_answer` VALUES ('60', '64', '通过-Xss参数设置栈内存大小`-Xss1024k`\n\n每个线程都有自己的栈，每个方法都对应着一个栈帧，每个方法的执行都对应着这个栈帧的入栈\n\n栈帧的入栈：调用一个新的方法时\n\n栈帧的出栈：当前方法执行结束/出现异常且自身未捕获\n\n+ **局部变量表**：其中保存该栈帧（方法）的局部变量。<br/>使用数组来实现\n\n  该局部变量包含\n\n  1. 基础数据类型（八大基础数据类型）\n  2. 引用数据类型的引用（实例存放在堆中）\n\n  > Slot\n  >\n  > 局部变量表中存储单元是Slot（变量槽）是32位的\n  >\n  > 针对基础类型中的long和double是64位的所以需要两个槽，其他都是一个槽\n  >\n  > 存放`引用数据类型的引用`是指存放在堆中的对象的地址信息\n\n  局部变量包括基础数据类型和引用数据类型的引用。局部变量表的大小决定这个栈帧的大小，其中最基本的存储单元是Slot（变量槽）。\n\n  > 栈的调优主要就是在针对局部变量表做的\n  >\n  > 1. 局部变量表中保存着**对象的引用**（GC的时候只有对象没有再使用才会进行回收）\n  > 2. 局部变量表的大小决定着栈帧的大小。当栈的大小固定的时候，局部变量表越大对应的栈帧就越少\n\n+ **操作数栈**：主要用来保存计算过程中的**中间结果**，同时作为计算过程中需要的变量的临时存储\n\n  ```\n  int i=1;\n  int j=2;\n  int x=i+j;\n  \n  这个时候i+j从局部变量表中取出来之后就在操作数栈中存储着，并将计算的3也存储在这里面。只是进行int x=3之后才又存储在了局部变量表中\n  ```\n\n+ 动态链接：**指向运行时常量池的方法引用**，也就是动态这个思想（只记录名字不记录人）方便Java开发中进行一方编写多方调用。所以这个地方**记录的就是运行时常量池中的该方法需要的其他方法/属性的引用**\n\n  每个类的字节码文件中都有一个`Constant pool`常量池，这里面记录了所有的方法、字段等的符号引用和对应的真实地址存储结构等。符号引用在字节码中就是类似#27之类\n\n  - 部分符号引用在类加载阶段的时候就转化为直接引用，这种转化就是静态链接\n  - 部分符号引用在运行期间转化为直接引用，这种转化就是动态链接\n\n+ 方法出口：方法返回地址，存放调用该方法的程序计数器的值。只针对正常退出该方法的时候这个时候需要给上层返回具体的信息，所以需要找到上层的调用', '0', '1', '1', '1', '2022-07-11 17:56:34', '2022-07-11 17:56:34');
INSERT INTO `tb_card_answer` VALUES ('61', '65', '主要就是栈内存的溢出异常\n\n+ 固定栈大小，如果递归调用方法出现栈帧数量超过栈的大小，则会抛出StackOverflowError\n+ 动态栈大小，如果超过栈的大小就进行扩充栈，如果没有申请到内存就会抛出OutOfMemoryError（OOM）', '0', '1', '1', '1', '2022-07-11 17:56:34', '2022-07-11 17:56:34');
INSERT INTO `tb_card_answer` VALUES ('62', '66', '区别于虚拟机栈是管理的Java方法的调用，本地方法栈是管理的本地方法的调用（别的语言的方法调用）\n\n当某个线程调用了本地方法的时候，就会完全脱离虚拟机的掌控，而使用本地处理器的寄存器等进行管理（就完全和Java无关了，而是使用C来管理）。权限也更高', '0', '1', '1', '1', '2022-07-11 17:56:35', '2022-07-11 17:56:35');
INSERT INTO `tb_card_answer` VALUES ('63', '67', '1. 线程：Java的堆区在Jvm启动的时候就创建，是线程共享的。\n2. 空间：物理上是不连续的内存空间，但是在逻辑上需要理解成连续的（虚拟内存，将物理内存的地址进行连续的存储）\n3. TLAB：将整个的堆空间按照每个线程区分出来，每个线程独有一块私有的缓冲区TLAB\n4. 存储：几乎所有的实例对象和数组都存储在堆上', '0', '1', '1', '1', '2022-07-11 17:56:35', '2022-07-11 17:56:35');
INSERT INTO `tb_card_answer` VALUES ('64', '68', 'Java7及之前：新生代（Eden和Survivor）、老年代和~~永久代~~（删除是后来没有了）\n\nJava8及之后：新生代（Eden和Survivor）、老年代和~~元空间（meta space）~~（删除是因为后来被定义成方法区了）', '0', '1', '1', '1', '2022-07-11 17:56:35', '2022-07-11 17:56:35');
INSERT INTO `tb_card_answer` VALUES ('65', '69', '-Xms，初始堆空间大小。-XX:InitialHeapSize。例-Xms1024m\n\n-Xmx，最大堆空间大小。-XX:MaxHeapSize。例-Xmx1024m。一旦堆内存大小超过Xmx设置的值就会抛出OOM异常。线上环境中建议将初始堆内存和最大堆内存设置成相同的值\n\n\n\n-XX:NewRatio=2，表示新生代占1，老年代占2，即新生代和老年代占堆大小比例是1:2。（-XX:NewRatio=4，表示新生代占1，老年代占4，比例是1:4）一般不调整该参数，除非是明确知道该程序中会有很多的存活对象的时候。\n\n-XX:SurvivorRatio=8，设置新生代内存分配大小中Eden:Suvivor0:Suvivor1=8:1:1\n\n-XX:+PrintGCDetails，表示将GC处理日志输出出来\n\n-Xmn，设置新生代的空间大小（NewRatio同时存在时候，以-Xmn为准）\n\n\n\n-XX:MaxTenuringThreshold=<N>进行设置新生代垃圾的最大年龄，默认情况下是15\n\n> -X是Jvm的运行参数\n>\n> ms：memory start\n>\n> 默认单位为字节，可以指定K、M、G等\n>\n> 默认初始大小=机器物理内存/64\n>\n> 最大堆大小=机器物理内存/4\n>\n> 真实在存储数据的时候，堆的内存是一个surivor区+eden+老年代。也就是两个surivor在同一时间，实际上只有一个起效用\n>\n> ![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/9SIWD4.png)\n>\n> 这里S0C/S1C+EC+OC=真实堆能使用的空间。但是设置的-Xms是S0C+S1C+EC+OC\n>\n> ![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/UoEKMW.png)\n\n其他\n\n```\n-XX:+PrintFlagsInitial：查看所有的参数的默认初始值\n-XX:+PrintFlagsFinal：查看所有的参数的最终值（可能会存在修改，不再是初始值）\n-XX:+PrintGC 或 -verbose:gc ：打印gc简要信息\n-XX:HandlePromotionFalilure：是否设置空间分配担保\n```', '0', '1', '1', '1', '2022-07-11 17:56:35', '2022-07-11 17:56:35');
INSERT INTO `tb_card_answer` VALUES ('66', '70', '是堆中空间按照其中存放对象的性质进行区分的类型\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/年轻代和老年代1.png)\n\n对象分配规则\n\n1. 优先分配到Eden\n2. 大对象直接分配到老年代（比如一次从数据库中取出来几百条几万条数据可能直接造成FullGC或者OOM）\n3. 动态对象年龄判断，一些细小的规则及空间分配担保\n\n学习自宋老师的图片：![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/f8Wq8h.jpg)\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/lhasNA.png)\n\n\n\n# 简述MinorGC、MajorGC和FullGC的区别\n\n|                | MinorGC                                                      | MajorGC                                                      | FullGC                                                       |\n| -------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |\n| 别名           | YGC                                                          | FGC                                                          |                                                              |\n| 简述           | 新生代收集                                                   | 老年代收集-CMS收集器特有<br>（还有一种MixedGC混合收集针对新生代和老年代G1收集器使用） | 整堆收集，包括方法区                                         |\n| 触发条件       | Eden满了                                                     | 老年代满了（一般是在一次MinorGC之后导致老年代满了进行MajorMC） | 1. System.gc()<br>2. 老年代空间不足<br>3. 方法区空间不足<br>4. 其他操作导致老年代空间不足 |\n| 处理           | 1. 将Eden和From中不满足阀值的对象未回收对象实例<br>使用**复制算法**复制到To。将原本的内存空间清除<br> 2. 超过阀值则复制到老年代 | 1. MinorGC之后发现老年代空间满了就进行MajorGC<br>2. 进行MajorGC之后如果发现老年代空间还是不足，就抛出OOM |                                                              |\n| 对用户线程影响 | ?，会触发STW，暂停其他用户线程                               | ???执行速度相对于MinorGC慢十倍以上。所以STW时间更长          | ?????                                                        |\n| 频率           | 最高，<br>Java大部分对象都是朝生夕死                         | 一般会在很多次MinorGC之后才进行一次                          |                                                              |', '0', '1', '1', '1', '2022-07-11 17:56:35', '2022-07-11 17:56:35');
INSERT INTO `tb_card_answer` VALUES ('67', '71', '现有虚拟机是对象只有分配在堆上的。只是逃逸分析这个技术可以做到将对象分配到栈上\n\n如果一个实例对象通过**逃逸分析**判断是只有这个方法使用的。那么这个实例对象就可以将内存分配到栈上。\n\n**逃逸分析**条件：一个对象在方法中定义之后，只在方法内部使用，则认为没有发生逃逸\n\n```\npublic void aaa(){\n A a=new A();\n ...\n ...\n a=null;\n}\n```\n\n在Java8及其以后，默认开启逃逸分析。在编译过程中JIT编译器根据分析结果，将对应的对象优化成**栈上分配**\n\n> ```java\n> /**\n>  * 逃逸分析\n>  *\n>  * 如何快速的判断是否发生了逃逸分析，大家就看new的对象实体是否有可能在方法外被调用。\n>  */\n> public class EscapeAnalysis {\n> \n>     public EscapeAnalysis obj;\n> \n>     /*\n>     方法返回EscapeAnalysis对象，发生逃逸\n>      */\n>     public EscapeAnalysis getInstance(){\n>         return obj == null? new EscapeAnalysis() : obj;\n>     }\n> \n>     /*\n>     为成员属性赋值，发生逃逸\n>      */\n>     public void setObj(){\n>         this.obj = new EscapeAnalysis();\n>     }\n>     //思考：如果当前的obj引用声明为static的？ 仍然会发生逃逸。\n> \n>     /*\n>     对象的作用域仅在当前方法中有效，没有发生逃逸\n>      */\n>     public void useEscapeAnalysis(){\n>         EscapeAnalysis e = new EscapeAnalysis();\n>     }\n> \n>     /*\n>     引用成员变量的值，发生逃逸\n>      */\n>     public void useEscapeAnalysis1(){\n>         EscapeAnalysis e = getInstance(); //这个e对象，本身就是从外面的方法逃逸进来的\n>         //getInstance().xxx()同样会发生逃逸\n>     }\n> }\n> \n> ```\n\n逃逸分析的代码优化\n\n1. **栈上分配**，就是没有发生逃逸的对象，在栈上进行内存的分配，这样在方法结束的时候出栈就释放了这个对象的内存空间\n\n2. **同步省略**，逃逸分析的对象实例进行了栈上分配，那么这个对象就是线程私有的。那么如果原本对这个线程进行了**加锁操作就是多余的**。所以这个时候就不用进行线程数据同步了。\n\n   JIT编译器分析该锁对象只有在该线程有效，不会影响到其他线程的数据。就不需要这个锁了，就进行了**锁消除**\n\n   ```java\n   public void f() {\n       Object hellis = new Object();\n       synchronized(hellis) {\n           System.out.println(hellis);\n       }\n   }\n   这个锁本身针对的这个hellis就是一个会被逃逸分析认定为栈上分配的。所以这个线程的对象就不会出现线程共享的问题。所以这个锁就没有必要\n   ```\n\n3. **分离对象/标量替换**\n\n   什么是标量：无法分解的数据，比如对象就是一个聚合量，但是一个int类型属性就是一个标量\n\n   ```java\n   class Point {\n       private int x;\n       private int y;\n   }\n   private static void alloc() {\n       Point point = new Point(1,2);\n       System.out.println(\"point.x\" + point.x + \";point.y\" + point.y);\n   }\n   ```\n\n   如果逃逸分析一个对象不会逃逸，那么就将这个对象（聚合量）分解成所有的标量。**标量（基础数据类型）肯定是分配在栈上的。所以就不需要分配堆内存**', '0', '1', '1', '1', '2022-07-11 17:56:35', '2022-07-11 17:56:35');
INSERT INTO `tb_card_answer` VALUES ('68', '72', '![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/堆、方法区和栈的关系.drawio.png)\n\n\n\n**一个对象的创建，对象的实例存储在堆中，这个方法使用了这个对象，那么就存储这个对象的引用。而这个对象他所代表的类的各个信息都在方法区中存储**\n\nA a=new A()\n\n+ A，类的基本信息，存储在**方法区**中\n+ a，对象的引用，在方法调用时候存储在**虚拟机栈**中 \n+ new A()，对象的实例，存放在**堆**中', '0', '1', '1', '1', '2022-07-11 17:56:35', '2022-07-11 17:56:35');
INSERT INTO `tb_card_answer` VALUES ('69', '73', '1. **线程共享**，启动时创建\n2. **大小**可以固定不变也可以设置可扩展。大小取决于加载的类的多少。如果类过多会抛出OOM异常（加载的jar文件类过多，tomcat部署的应用程序过多）\n3. 使用的是本地内存，也就是系统内存\n4. **演进**：**hotspot**中方法区的实现在1.8之前是永久代，1.8及其之后是metaspace。**metaSpace和方法区**。metaSpace是方法区在hotSpot中的实现', '0', '1', '1', '1', '2022-07-11 17:56:35', '2022-07-11 17:56:35');
INSERT INTO `tb_card_answer` VALUES ('70', '74', 'Java7之前：\n\n+ `-XX:PermSize`来设置永久代的初始大小，默认20.75M\n\n+ `-XX:MaxPermSize`来s何止永久代最大可分配空间大小，32位机默认是64M，64位默认是82M\n\n  超过就会OOM\n\nJava8之后：\n\n+ `-XX:MetaspaceSize`，默认21M，例如：`-XX:MetaspaceSize=21M`\n+ `-XX:MaxMetaspaceSize`，默认-1，表示**上限没有限制**，即虚拟机会一直使用系统内存，直到耗尽抛出OutFlowOfMemoryError: metaspce，例如：`-XX:MaxMetaspaceSize=1024M`\n\nJava8之后，一般MetaspaceSize是一个高水平线，如果超过这个高水平线就会触发一个FullGC进行卸载没用的类。**然后这个高水位线将会重置**。新的高水位线的值取决于GC后释放了多少元空间。\n\n+ 如果FullGC释放的空间不足，就会提高metaSpace空间（不会超过maxMetaspaceSize）\n+ 如果FullGC释放的空间足够，就会下调metaSpace空间\n\n\n\n造成方法区OOM的情况\n\n+ 反射的方式持续创建类\n+ 动态加载的类过多', '0', '1', '1', '1', '2022-07-11 17:56:35', '2022-07-11 17:56:35');
INSERT INTO `tb_card_answer` VALUES ('71', '75', '![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/eAdpxS.png)\n\n一般包含以下几部分\n\n+ **类信息**：类的名称，字段，方法，常量，修饰符，接口注解等等\n\n  ```java\n  public class A extends Params{\n    public int num=1;\n    \n    public void setA(A a){\n      this.num=a.num;\n    }\n  }\n  ```\n\n+ 静态变量\n\n  new byte[1024*1024*100]这个对象是放在堆空间中的。但是这个bytes的引用是在jdk7之后从方法区移到了堆中\n\n  ```java\n  public static byte[] bytes=new byte[1024*1024*100];\n  ```\n\n+ **运行时常量池**\n\n  > 常量池，其中存放着经过编译后的各种字面量，以及类型、字段和方法的符号引用（符号引用可以理解成就是一种引用）\n  >\n  > 为什么使用常量池，因为需要存放各种引用，如果直接将对应的类或者对应类的方法加载进来就会很大很麻烦。（我表上记个身份证号就好，我没必要将这个人挂表上）\n  >\n  > + 数量值\n  > + 字符串值\n  > + 类引用\n  > + 字段引用\n  > + 方法引用\n  >\n\n  通过ClassLoader将classFile中的常量池信息加载到方法区之后就是放到了运行时常量池中。在加载的过程中将这些**带#的符号引用，转换成真实的内存地址引用存放在运行时常量池中**\n\n+ JIT编译代码缓存\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/oi50AI.jpg)\n\n<font color=\"red\">**jdk7之后将原本放在方法区中的字符串常量和静态变量的引用放到了堆空间中**</font>', '0', '1', '1', '1', '2022-07-11 17:56:35', '2022-07-11 17:56:35');
INSERT INTO `tb_card_answer` VALUES ('72', '76', '可以回收可以不回收。Jdk11的ZGC收集器不关注方法区的内存空间回收\n\n方法区的垃圾回收主要就是进行**类卸载**和**废弃常量**\n\n**废弃常量**：和对象的回收很类似，都是没有了引用就可以回收内存\n\n**类卸载**条件：\n\n+ 该类的所有实例对象全部都被回收\n+ 该类的类加载器已被回收，通常可能性不大\n+ 该类的Class对象已被回收（防止再通过反射访问该类）\n\n只有满足上面三个条件才会被回收。', '0', '1', '1', '1', '2022-07-11 17:56:35', '2022-07-11 17:56:35');
INSERT INTO `tb_card_answer` VALUES ('73', '77', '### 创建对象的方式\n\n+ new，构造器的方式\n+ Class的newInstance()，只能调用空参的构造器，且构造器权限是public\n+ Constructor的newInstance()，可以调用空参/带参的，权限没有限制\n+ 使用clone()，对象的复制\n+ 使用反序列化，从文件中或者网络中获取二进制字节流\n+ 第三方库Objenesis\n\n### 创建对象的具体步骤\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/对象创建的步骤.drawio.png)\n\n### 对象的内存布局\n\n![](/Users/kaochong/Library/Application Support/typora-user-images/image-20220211173658002.png)\n\n+ **对象头**：运行时需要的元数据，该对象的类类型指针\n  + HashCode\n  + GC分代年龄\n  + 锁状态标志\n  + 线程持有的锁\n  + 其他锁相关的信息\n\n+ 实例数据，实际上该对象有的各种字段、方法等\n+ 对齐填充，保证Java对象大小是8bit的倍数\n\n### 对象的访问\n\n**直接指针（HotSpot使用）**：\n\n\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/对象的访问（对象的使用）.drawio.png)\n\n\n\n**句柄访问**：在堆中开辟一个空间，存储两个数据，到**对象实例数据的指针**和**到对象类型数据的指针**。\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/IcIcYE.png)', '0', '1', '1', '1', '2022-07-11 17:56:35', '2022-07-11 17:56:35');
INSERT INTO `tb_card_answer` VALUES ('74', '78', '作用：将字节码指令解释/编译为对应平台上的本地机器指令（将字节码翻译成机器语言）。并按照程序计数器来操作堆栈中的数据，并在虚拟机栈中进行对应的操作计算等', '0', '1', '1', '1', '2022-07-11 17:56:35', '2022-07-11 17:56:35');
INSERT INTO `tb_card_answer` VALUES ('75', '79', 'Hotspot执行代码有两种方式（协作执行）\n\n+ 针对常用的代码，使用JIT技术编译成机器码直接执行。\n+ 将源代码编译成字节码，在运行的时候通过解释器将字节码转换成机器码执行\n\nJIT（just in time）即使编译技术。\n\n只使用JIT的问题：程序启动需要耗时很长时间才能使用（启动需要编译所有代码 ）\n\n整合两者：虚拟机刚启动时，解释器先发挥作用，不用等待即使编译器全部编译完成，可以省去需要不必要的编译时间。随着程序时间的推移，即使编译器逐步发挥作用，根据**热点探测**功能，将有价值的字节码编译成机器码，来换取更高的程序执行效率', '0', '1', '1', '1', '2022-07-11 17:56:35', '2022-07-11 17:56:35');
INSERT INTO `tb_card_answer` VALUES ('76', '80', '+ 前端编译器：即在使用代码前就将代码编译好。比如将.java编译成.class的过程\n+ 后端运行期编译器：就是JIT，在代码执行期间即时的将字节码转变成机器码的过程\n+ 静态提前编译器：就是将.java直接编译成机器码。运行期间就没有编译的操作了（AOT编译器）\n\n\n\n**什么时候使用JIT**\n\n根据代码的执行频率。（一个多次调用的方法，或者方法体中循环较多次的方法体）执行较多的就是**热点代码**。\n\n**热点探测功能**：基于计数器的热点探测\n\n+ 方法调用计数器来统计方法的调用次数。\n+ 回变计数器来统计循环体的执行循环次数\n\n**热点衰减**：在一定时间限度内，如果方法调用次数仍然不足提交进行编译器编译。就将调用次数减少一半。（这个一定时间限度使用就是-XX:-UseCounterDecay）', '0', '1', '1', '1', '2022-07-11 17:56:35', '2022-07-11 17:56:35');
INSERT INTO `tb_card_answer` VALUES ('77', '81', '正常hotspot的默认模式是混合模式。也就是既有解释器也有JIT。\n\n可以通过`java -Xint -version`，将修改成解释器模式之下\n\n`java -Xcomp -version`修改成纯即时编译器的模式并打出信息。也就是第一次就进行编译进行之下\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/HllCGq.png)', '0', '1', '1', '1', '2022-07-11 17:56:35', '2022-07-11 17:56:35');
INSERT INTO `tb_card_answer` VALUES ('78', '82', '+ C1编译器：Client Compiler 表示Java虚拟机运行在client模式下（桌面客户端等）\n\n  会对字节码进行简单和可靠的优化，耗时短（开机时间短，但是开机后的运行速度稍微差点意思）\n\n+ C2编译器：Server Compiler 表示Java虚拟机运行在server上（网页的CS模式下的后台应用程序）\n\n  会进行耗时较长的优化以及激进优化，耗时长（开机时间长，但是开机后的运行速度稍微好一点）\n\n> Graal编译器，JDK10之后的编译器，需要显式的去开启。效率和C2差不多', '0', '1', '1', '1', '2022-07-11 17:56:35', '2022-07-11 17:56:35');
INSERT INTO `tb_card_answer` VALUES ('79', '83', '一个Native Method就是一个Java调用非Java代码的接口，主要就是C/C++。使用native修饰不需要实现，具体实现在别的代码中进行', '0', '1', '1', '1', '2022-07-11 17:56:35', '2022-07-11 17:56:35');
INSERT INTO `tb_card_answer` VALUES ('80', '84', '什么是垃圾：运行程序中没有指针指向的对象\n\n早期的垃圾回收：开发人员需要再new之后进行delete将内存释放出来，这样压力在开发人员，如果忘记释放就会出现问题。\n\nJava带有自动的内存管理机制。\n\n缺点：弱化开发人员在程序内存溢出之后的问题解决能力', '0', '1', '1', '1', '2022-07-11 17:56:35', '2022-07-11 17:56:35');
INSERT INTO `tb_card_answer` VALUES ('81', '85', '|              | 引用计数法                                                   | <font color=\"red\">可达性分析法<br>根搜索算法<br/>追踪性垃圾收集</font> |\n| ------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |\n| 实现方式     | 对每个对象保存一个引用计数器属性，<br>用来记录对象被引用的次数 | 按照从下至上的方式搜索被**根对象集合**连接的目标对象是否可达（也就是只能标记出来是可达的即不可回收的，其他就都是可回收的） |\n| 优点         | 实现简单；<br>判定效率高（只需要判断属性是否为0即可）        | 解决循环引用（Java、C#使用）                                 |\n| 缺点         | 1. 资源浪费，计数器需要单独的空间存储<br>2. 时间浪费，每次操作都需要更新计数器<br><font color=\"red\">3. 无法处理循环引用</font>：即根调用不用了，但是其他引用相互调用着导致计数器不为0一直无法回收 | 1. 检查性能相对于前者来说差一点<br>2. 需要快照，所以需要\"Stop the world\"，即使是CMS也在进行枚举根节点的时候需要停止 |\n| 内存泄露例子 | 循环引用                                                     |                                                              |', '0', '1', '1', '1', '2022-07-11 17:56:35', '2022-07-11 17:56:35');
INSERT INTO `tb_card_answer` VALUES ('82', '86', '可达性分析法：\n\n1. 先确定GCRoots\n2. 根据GCRoots的集合去找可触及标记为可存活的对象。其他的对象标记为可回收\n\n![可达性分析法.png](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/KXbk58.jpg)\n\nGC Roots包括以下几类元素\n\n+ **虚拟机栈/本地方法区中引用的对象**，说明正在使用\n+ **方法区/堆空间中类静态属性引用的对象**，静态数据只要需要类就需要这些参数\n+ **方法区/堆空间中常量引用的对象，字符串常量池中**\n+ 同步锁持有的对象\n+ 基本数据类型对应的Class对象，常驻的异常对象（NPE、OOM）系统类加载器', '0', '1', '1', '1', '2022-07-11 17:56:36', '2022-07-13 14:50:44');
INSERT INTO `tb_card_answer` VALUES ('83', '87', '调用时机：垃圾回收对象之前，会先调用这个对象的finalize()方法。\n\n作用：为了进行一些垃圾回收之前的逻辑处理（资源释放，连接释放等），比如我本来开启了一些资源，想要在这个对象被销毁之前进行一些资源的关闭操作。\n\n类似Servlet中的destory()方法\n\n注意点：\n\n1. 不要主动调用finalize()方法 \n   1. 可能导致复活\n   2. 执行时间是没有保障的，需要在GC环境下才能正常使用\n2. 重新要谨慎，因为是在GC之前执行，如果出现性能问题会影响很大的GC性能\n\n\n\n由于有该机制，所以虚拟机中对象有三种状态\n\n+ 可触及：从根节点检查，没法到达这个对象（可达性分析法）\n+ 可复活：该对象在调用finalize()方法中可以被复活\n+ 不可触及：调用finalize()没有复活，且无法触及这个对象，这个对象就会被销毁\n\n**判定一个对象是否可回收，需要两次标记**：\n\n1. 引用计数法判定该对象不可被访问——标记一\n2. 如果有finalize()方法，且执行之后该对象可以被触及。那么就不会被回收\n3. 如果没有重写finalize()，或者重新的逻辑中不会复活该对象。那么就第二次标记——标记二\n\n两次标记都满足才会被回收', '0', '1', '1', '1', '2022-07-11 17:56:36', '2022-07-11 17:56:36');
INSERT INTO `tb_card_answer` VALUES ('84', '88', '|              | 标记—清除算法                                                | 复制算法                                                     | 标记—整理算法                                                |\n| ------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |\n| 执行过程     | 1.  STW，停止主线程 <br>2. 标记：从根节点开始遍历，标记所有被引用的对象（标记在对象header中） <br>3. 清除：对堆内存从头到尾线性遍历，将没有被标记的对象进行清除 | 1. 遍历根节点，将关联到的对象复制到另外一片空间中 <br>2. 清除，将原本的空间全部清除 | 1、STW<br>2、标记<br>3、整理：将所有存活对象压缩到内存的一端<br>4、清除边界外其他所有空间 |\n| 图解         | ![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/QlQVw7.jpg) | ![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/Keyovw.jpg) | ![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/EmL5as.jpg) |\n| 优点         | 实现简单，理解简单                                           | 1、不会产生碎片空间，分配对象适用指针碰撞即可<br>2、效率较高 | 1、不会产生内存碎片<br>2、内存利用率高                       |\n| 缺点         | 1、效率较低，需要进行两次遍历<br>2、STW，影响用户线程<br>3、产生碎片空间，需要维护内存空闲列表 | 1、空间利用率低，只能适用一半<br>2、在对象存活比例较高时，消耗资源最大<br>3、STW | 1、效率最低<br>2、修改了存活对象的引用<br>3、STW             |\n| 适用情况     | 不需要存活对象的内存调整                                     | 对象存活比例低的情况（Survivor区）                           | 内存空间较大，存活率较高（老年代）                           |\n| 注意点       | 清除：清除并不是真的置空，只是将需要清除的对象地址保存在**空闲列表**中。后续帮忙放入新的对象 |                                                              |                                                              |\n| 对象内存分配 | 内存空闲列表                                                 | 指针碰撞                                                     | 指针碰撞                                                     |\n| 总结         | 速度：??<br>内存利用率：??<br>移动对象：??                   | 速度：???<br/>内存利用率：?<br/>移动对象：?                  | 速度：?<br/>内存利用率：??<br/>移动对象：?                   |', '0', '1', '1', '1', '2022-07-11 17:56:36', '2022-07-11 17:56:36');
INSERT INTO `tb_card_answer` VALUES ('85', '89', '年轻代：使用复制算法，效率高，同时使用survivor来缓解内存浪费的情况\n\n老年代：标记清除和标记整理的混合使用。也就是通常使用标记—清除，一段时间之后使用标记—整理算法\n\nCMS回收器：使用标记清除来实现。当内存回收不佳（碎片空间导致 ）则使用Serial Old执行Full GC来运行标记整理\n\n为了解决每种回收算法的侧重点不同，所以将对的内存空间分为新生代和老年代两种，然后针对这两种使用不同的回收算法\n\n新生代内存回收：复制算法\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/新生代垃圾回收.drawio.png)\n\n老年代回收：标记清除算法，时间长了使用一次标记整理算法来解决内存碎片化问题\n\n**新生代->老年代**每次回收针对未回收的对象进行记录，一旦记录次数到达阀值就会将新生代的未回收对象引用转移到老年代中。\n\n\n\n> <font color=\"green\">增量收集算法</font>：解决STW的问题\n>\n> 垃圾收集线程和用户线程**交替执行**。每次只收集一小片区域的内存空间，然后切换成用户线程执行\n>\n> 优点：低延时的解决STW；\n>\n> 缺点：增加消耗线程切换和上下文切换。\n>\n> \n>\n> <font color=\"green\">分区算法</font>：将一个大的堆分成若干个小区region，然后每次针对设置的目标停顿时间（按照业务配置）去回收若干个小区。从而减少一次GC所产生的停顿时间的限制', '0', '1', '1', '1', '2022-07-11 17:56:36', '2022-07-11 17:56:36');
INSERT INTO `tb_card_answer` VALUES ('86', '90', '开发通过`System.gc()`会触发Full GC。不一定立刻执行。\n\n用处：做性能测试的时候的准备工作', '0', '1', '1', '1', '2022-07-11 17:56:36', '2022-07-11 17:56:36');
INSERT INTO `tb_card_answer` VALUES ('87', '91', '**内存溢出（OOM）**：针对堆空间。没有空闲内存且垃圾收集器无法提供更多的内存。\n\n原因：\n\n1、设置的堆内存不够\n\n2、创建的大对象，长时间不能被垃圾收集器回收。比如从数据库中一次性查询出来几万条数据。循环创建了大量的对象。\n\nOOM之前一定会触发一次GC。会尝试回收**软引用**的对象\n\n\n\n**内存泄露**：对象不会被使用，但是GC又不能回收他们。\n\n内存泄露并不会直接导致程序崩溃，而是泄露的内存越来越多最终导致OOM来导致程序崩溃 \n\n例子：1. 代码中将单例对象关联了另外的业务对象数据。2. 一些资源没有关闭', '0', '1', '1', '1', '2022-07-11 17:56:36', '2022-07-11 17:56:36');
INSERT INTO `tb_card_answer` VALUES ('88', '92', 'stop the world\n\n因为GC的原因导致用户线程暂停下来\n\n情况：可达性分析算法，在分析哪些属于GCRoots的时候需要停顿下来（针对一个快照），确保计算的时候不会有新的对象产生——确保数据的一致性。', '0', '1', '1', '1', '2022-07-11 17:56:36', '2022-07-11 17:56:36');
INSERT INTO `tb_card_answer` VALUES ('89', '93', '并行：多个CPU针对多个进程。就是一直在一起执行。不会有资源的抢占\n\n并发：一个CPU执行多个进程，频繁的切换进程执行，一个时刻只有一个进程在执行', '0', '1', '1', '1', '2022-07-11 17:56:36', '2022-07-11 17:56:36');
INSERT INTO `tb_card_answer` VALUES ('90', '94', '**安全点**：程序执行过程中，并不是所有的地方都能停下来进行GC，只有特定的位置才能停顿\n\n一般选择在`方法调用`、`循环跳转`、`异常跳转`这种本身就会执行时间较长的时候\n\n如何保证所有线程都在最近的安全点停顿：\n\n+ **抢先式中断**：先中断所有线程，如果有线程不在安全点就继续该线程直到运行到安全点（虚拟机不使用）\n+ **主动式中断**：设置一个中断标志，各个线程运行到自动停下来。\n\n\n\n**安全区域**：一块区域都可以让当前用户线程停下来。该区域内对象的引用状态不会发生变化就可以进行GC。例如sleep等', '0', '1', '1', '1', '2022-07-11 17:56:36', '2022-07-11 17:56:36');
INSERT INTO `tb_card_answer` VALUES ('91', '95', '+ 强引用：只要强引用的关系还存在，那么垃圾回收器就永远不会回收掉这中引用对应的对象。百分之九十九\n+ 软引用（内存不够才会回收）：用来描述一些还有用，但并非必须的对象。这种对象会在OOM之前的GC回收的时候被回收掉。jdk1.2之后使用`SoftReference`类创建\n+ 弱引用（内存足够也会回收）：描述非必须的对象，这种对象会直接被下一次的垃圾回收回收掉。也就是说无论内存是否足够都会被回收。jdk1.2之后使用`WeakReference`类创建\n+ 虚引用：这是一种比较特殊的存在，他的目的是**能在这个对象被收集器回收的时候收到一个系统通知**。jdk1.2之后使用`PhantomReference`类创建', '0', '1', '1', '1', '2022-07-11 17:56:36', '2022-07-11 17:56:36');
INSERT INTO `tb_card_answer` VALUES ('92', '96', '只能回收新生代：Serial（串行） 、Parallel（并行） Scavenge 、ParNew （并行）\n\n只能回收老年代：Serial Old 、Parallel Old 、CMS（并发） \n\n都可以：G1（并发）\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/9fLp6n.jpg)\n\n\n\n不同垃圾回收器组合关系\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/0d713Z.jpg)\n\n|          | Serial                                              | Serial Old                                                   | ParNew                                                       | Parallel Scavenge                                            | Parallel Old                                                 | CMS            |\n| -------- | --------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | -------------- |\n| 特点     | 1、串行<br>2、单线程单核                            | 1、串行<br/>2、单线程单核                                    | 1、并行<br>2、多线程<br>3、par是parallel缩写，new指只回收新生代 | 1、并行<br>2、自适应调节策略                                 |                                                              | 面向停顿时间   |\n| 回收算法 | 复制算法                                            | 标记整理算法                                                 | 复制算法                                                     | 复制算法                                                     | 标记整理                                                     | 标记清除       |\n| 回收范围 | 新生代                                              | 老年代                                                       | 新生代                                                       | 新生代                                                       | 老年代                                                       | 老年代         |\n| 使用情况 | 目前针对一些单CPU使用（嵌入式设备）                 | 单CPU使用、server模式下与CMS配合作为补充使用（CMS是标记清除算法，隔一段时间需要标记整理一下） | 针对多CPU比Serial好写，单CPU不如Serial                       | parallel相对于ParNew<br>1、Parallel目标是达到可控制的吞吐量<br>2、自适应调节策略<br>3、吞吐量优先 | JDK1.6                                                       |                |\n| 配置方式 | `-XX:+UseSerialGC`                                  | `-XX:+UseSerialGC`                                           | 启动：`-XX:+UseParNewGC`<br>限制线程数量：`-XX:ParallelGCThreads` | 1、JDK8中默认`-XX:+UseParallelGC`<br>2、`-XX:ParallelThreads`设置并行收集器的线程数（CPU>8则`3+(5*CPU_COUNT)/8`）<br>3、`-XX:MaxGCPauseMillis`设置最大停顿时间<br>4、`-XX:GCTimeRatio`垃圾收集占总时间的比例<br>5、`-XX:+UseAdaptiveSizePolicy`自适应调节策略 | JDK8中默认`-XX:+UseParallelOldGC`与UseParallelGC互相激活<br> |                |\n| 优点     | 简单高效（相对于单CPU其他垃圾回收器）               | 简单高效（相对于单CPU其他垃圾回收器）                        | 相对于单线程来说STW暂停时间稍短一些                          | 自适应调节<br>基于吞吐量优先                                 | 并行执行性能更好<br>补充了Parallel Scavenge的老年代回收      | 标记整理的优点 |\n| 问题     | 串行执行导致STW时间较长。一般BS模式不会使用该收集器 | 串行执行导致STW时间较长。一般BS模式不会使用该收集器          |                                                              |                                                              |                                                              | 标记整理的缺点 |\n| 使用场景 | 最小化的使用内存和并行的开销                        | 最小化的使用内存和并行的开销                                 |                                                              | 注重吞吐量                                                   | 注重吞吐量                                                   | 注重停顿时间   |', '0', '1', '1', '1', '2022-07-11 17:56:36', '2022-07-11 17:56:36');
INSERT INTO `tb_card_answer` VALUES ('93', '97', 'CMS：Concurrent-Mark-Sweap，并发标记清除。\n\n+ 针对停顿时间\n+ 回收线程和用户线程同时工作\n+ 并发标记清除\n+ B/S使用较多\n+ 老年代\n\n### 工作原理\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/hNpvy4.jpg)\n\n1. 初始标记（STW）但是时间短。\n\n   标记出GCRoots**直接关联**的对象\n\n2. 并发标记\n\n   从GCRoots出发遍历关联到的所有对象\n\n3. 重新标记（STW）\n\n   修正并发标记期间产生变化的对象的标记记录（这个时候产生变动的对象不多）\n\n4. 并发清理\n\n   清除算法，也就是只是记录一个内存空闲列表\n\n### 弊端\n\n1. 由于是并发清理，所以CMS不能等到没有内存了再去回收，因为执行期间**需要拥有空闲内存给用户线程使用**。如果出现执行期间没有足够内存给用户使用，就会抛出`Cocurrent Mode Failure`这时就会启动Serial Old来进行垃圾回收，停顿时间就很长了\n2. 产生碎片化内存空间。会导致提前触发Full GC。触发会使用Serial 这种性能较低的\n3. 对CPU资源很敏感，虽然并发阶段不会停顿，但是对CPU有功能消耗，所以这个时候必然其他线程还是有一定影响的\n4. 标记的不完整\n\n### 发展\n\nJDK9的时候标记为Deprecate（后续不再维护并可能在未来版本废弃）。JDK14删除了CMS', '0', '1', '1', '1', '2022-07-11 17:56:36', '2022-07-11 17:56:36');
INSERT INTO `tb_card_answer` VALUES ('94', '98', '### 为什么有G1？\n\n随着业务的发展，内存和处理器的优化。进而在延迟可控的情况下提升高吞吐量，实现一个全功能的收集器（新生代和老年代）\n\n### 工作模式\n\n垃圾优先（Garbage First）\n\n1、将整个堆分成不同的Region。并将其分配给Eden、Survivor0、Survivor1、老年代。\n\n2、G1监控每个Region中垃圾堆积（回收能释放的空间和回收所需要的时间等）。在后台维护一个优先列表\n\n3、每次需要回收的时候，根据允许的收集时间来计算出合理的回收方式使回收能获取收益最大的Region。\n\n### 优势\n\n+ 并行和并发：\n\n  并行：多个CPU可以一起进行GC来加快GC的速度。会短暂STW\n\n  并发：有些操作可以和用户线程一起执行。\n\n+ 分代收集：\n\n  虽然还是分成老年代和年轻代。但是已经和之前的分代不一样，每个区域都可以不是连续的空间了。而是划分成不同的Region\n\n  ![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/G6Za7g.jpg)\n\n+ 空间整合：\n\n  空间上因为是分区，每次回收最小单位都是Region。所以针对每个Region的回收可以是复制算法。而整个大的堆可以看成是标记整理算法\n\n+ 可限制的停顿时间：\n\n  使用者可以指定在某个时间范围内，消耗在GC上的时间不超过多少\n\n### 缺点\n\n1. 相对于CMS，G1比不上最好回收时间的CMS。但是整体来看会更优一些\n2. 从经验上来看，**更大的内存G1的性能就更好**，平衡点在6～8GB。\n\n\n\n### 参数设置\n\n+ `-XX:UseG1GC`，设置使用G1\n+ `-XX:G1HeapRegionSize`：设置每个Region的大小。需要是2的N次幂。一般1～32M\n+ `-XX:MaxGCPauseMillis`设置期望达到的最大GC停顿时间指标，默认值是200ms\n+ `-XX:ParallelGCThread`设置STW工作线程数的值，最大的是8\n+ `-XX:ConcGCThreads`：设置并发标记的线程数。将 n 设置为并行垃圾回收线程数（ParallelGCThreads）的 1/4 左右。\n+ `-XX:InitiatingHeapOccupancyPercent`：设置触发并发 GC 周期的 Java 堆占用率阈值。超过此值，就触发 GC，默认值是 45。\n\n调优方式：\n\n+ 开启G1垃圾回收器\n+ 设置堆的最大内存\n+ 设置最大的允许停顿时间\n+ 测试来检测性能\n\nJDK7开始允许正常使用，JDK9及其之后都默认使用。\n\n\n\n### 分析\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/V0JJNh.jpg)\n\n\n\n1. G1将整个堆划分成约2048个Region，每个Region的大小都是相同的，根据参数设置可能是1M、2M、4M、8M、16M、32M。每个Region只有一个角色（空了之后可以转变成其他角色）\n2. 如果一个大对象的大小超过了1.5Region，就会被保存在Humongous中。如果一个H保存不下一个大对象，会找一个连续的H区域来存储。这个时候有可能会触发Full GC\n\n\n\n**Remembered Set**记忆集，记录当前Region被哪些Region所引用，免除了YoungGC回收的时候还需要遍历Old区等情况\n\n为了解决，堆中不同Region相互引用的时候（Eden被Old引用），进行YoungGC只回收Eden中的对象，但是这个对象被Old区引用着。不知道能不能回收。就又需要去检查Old区。\n\nRSet就是记录每个Region中被其他Region的引用信息。所以回收的时候，就只用看看RSet中的引用信息就好了。\n\n### 回收过程\n\n回收过程包括四个环节\n\n1. 年轻代GC（Young GC（MinorGC））并行独占\n\n2. 年轻代GC+老年代并发标记过程（当堆内存使用达到一定值（默认 45%）时，开始老年代并发标记过程。）\n\n3. 混合回收（Mixed GC）\n\n4. Full GC也存在（单线程，独占式），提供一种GC的保护机制防止OOM\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/PsPpw3.jpg)\n\n每个环节的具体实现[大佬的blog](https://blog.csdn.net/sj15814963053/article/details/122685365)', '0', '1', '1', '1', '2022-07-11 17:56:36', '2022-07-11 17:56:36');
INSERT INTO `tb_card_answer` VALUES ('95', '99', '读取二进制流的动作和范围不一样\n\n后续的加载逻辑是一样的。所以如果你非要用extension classloader加载自己写的class文件也是没有问题的，但是不建议', '0', '1', '1', '1', '2022-07-11 17:56:36', '2022-07-11 17:56:36');
INSERT INTO `tb_card_answer` VALUES ('96', '100', '一些业务需要，比如实现热插拔，热部署等操作。只需要将这个模块和对应的类加载器一起换掉就好了\n\nJDBC：连接数据库的Driver接口的定义是在jdk中的jre/lib/rt.jar，这个是由BootStrap进行类加载的。但是jdbc针对每个类型的数据库提供的jar文件和连接逻辑都不一样，所以需要自己实现。所以就不能让BootStrap去加载，而是由自定义的类加载器去加载。所以JDBC的出现就是违背了双亲委派机制。', '0', '1', '1', '1', '2022-07-11 17:56:36', '2022-07-11 17:56:36');
INSERT INTO `tb_card_answer` VALUES ('97', '101', '简而言之就是如何让本该bootstrap/extension classloader加载的类不让他们加载而让自定义的类加载器加载/application classloader加载\n\n**jdbc**：jdk自带的lib/rt.jar/Driver.class进行的数据库连接，但是我们通常时候需要扩展这个类的方法来适配不同的厂商数据库（mysql/oracle/h2等）所以这个时候就不能主动的让bootstrap加载器加载了，就需要我们自己指定Application Classloader加载器加载这个Driver从而实现在我们的classpath中获取需要访问的静态资源文件（也就是对应的厂商jar文件）。\n\n只需要使用`ServiceLoader.load(需要违背的类)`就可以让他使用当前的上下文对象去加载这个`需要违背的类`\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/PbaG2p.png)\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/f7GEGt.png)', '0', '1', '1', '1', '2022-07-11 17:56:36', '2022-07-11 17:56:36');
INSERT INTO `tb_card_answer` VALUES ('98', '102', 'Service Provider Interface，服务发现机制\n\nJava实现的SPI就是去扫描classPath路径下的META-INF/services文件夹中的文件。\n\n如何使用：\n\n我们是去调用某个接口，具体的接口实现类我们通过导入的jar来决定，比如我们是调用Driver去创建数据库的连接，那么这个数据库连接的具体实现方式是通过我们导入的mysql-connect.jar文件来实现的\n\n实现步骤：\n\n1. 在META-INF下创建services文件夹，在这个文件夹中创建全路径的接口类的文件\n2. 在该文件中写入具体服务类的全限命名\n3. 将该项目打包成一个jar文件导入其他项目就好了。\n4. 导入该jar的项目会在项目启动时扫描所有的jar文件的META-INF来查看是否有需要实现的实现类\n\n\n\n举例子：\n\n1. JDBC的具体数据库服务提供的jar\n2. SpringBoot整合各种功能模块只需要导入需要的jar文件即可', '0', '1', '1', '1', '2022-07-11 17:56:36', '2022-07-11 17:56:36');
INSERT INTO `tb_card_answer` VALUES ('99', '103', '热部署就是Java动态的去加载一个文件夹中的class文件的变动来重新加载到项目缓存中\n\n所以用类加载的知识理解就是\n\n1. 某个目录的class文件变动了\n2. 类加载器将原本这个class文件的缓存信息删除\n3. 类加载器重新加载这个class文件\n\n那么实现方式就变成了\n\nNACOS（一种配置中心）\n\n1. 实现一个自定义的类加载器\n2. 监听文件夹中的类文件的变动情况\n3. 自定义的类加载器能根据输入的类删除其原本的缓存信息\n4. 重新加载变动的类\n5. 一个配置文件能动态的配置这个文件夹中的文件', '0', '1', '1', '1', '2022-07-11 17:56:36', '2022-07-11 17:56:36');
INSERT INTO `tb_card_answer` VALUES ('100', '104', '**<font color=\"red\">第一次</font>**：JDK1.2之前有了ClassLoader的概念，但是没有双亲委派机制。这个时候的开发者如果已经有了一些自定义类加载器的代码就没法去强迫用户修改了。所以就只能妥协承认已出现的代码的破坏行为。\n\n<font color=\"red\">第二次</font>：越基础的类使用的加载器越上层。但是如果基础的类的实现是由用户编写的代码来实现也就是需要App加载器去加载如何处理呢？例如数据库连接的Driver对象SPI（就是一些接口是由启动类加载器加载，但是实现是需要app加载器加载）。\n\n所以提出了一种**线程上下文加载器**这个加载器不属于任何一种加载器，但是是加载用户代码（所以也可以说是App加载器）。**当SPI接口需要具体的用户代码来实现，启动类加载器就委托线程上下文加载器去调用APP加载器加载用户代码来达到最终启动类加载器能加载SPI接口**（宋老师举例子）\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/第二次破坏双亲委派机制.drawio.png)\n\n<font color=\"red\">第三次</font>：热替换，热部署。每一个代码模块（Bundle）都有自己的类加载器。需要替换这个Bundle，就将其和其类加载器一起替换掉。重新加载的时候就不是从上至下的委托加载而是平行结构的直接加载。', '0', '1', '1', '1', '2022-07-11 17:56:36', '2022-07-11 17:56:36');
INSERT INTO `tb_card_answer` VALUES ('101', '105', 'CPU需要不停的切换各个线程，所以每个线程都需要自己记录到底执行到哪了', '0', '1', '1', '1', '2022-07-11 17:56:36', '2022-07-11 17:56:36');
INSERT INTO `tb_card_answer` VALUES ('102', '106', '方法的循环递归调用，导致栈帧在超过了栈的大小。如果是固定大小超过限制就会抛出StackOverflowError。如果是固定大小但是申请不到内存空间的时候OutOfMeroryError。\n\n通过-Xss来调整虚拟机栈的大小', '0', '1', '1', '1', '2022-07-11 17:56:37', '2022-07-11 17:56:37');
INSERT INTO `tb_card_answer` VALUES ('103', '107', '首先什么是线程安全，只有一个线程可以操作此数据，就一定是线程安全的。\n\n看这个局部变量是否会在外部的调用中使用到。如果只是在该方法中使用，每个方法都是一个线程的栈帧，那么就是安全的。如果是作为方法参数或者方法的返回值，那么就可能是不安全的', '0', '1', '1', '1', '2022-07-11 17:56:37', '2022-07-11 17:56:37');
INSERT INTO `tb_card_answer` VALUES ('104', '108', '原因：基于栈式架构的虚拟机，频繁的使用入栈出栈操作，所以CPU需要与内存进行频繁的IO操作。\n\n目标：将栈顶的数据缓存在CPU的寄存器中。', '0', '1', '1', '1', '2022-07-11 17:56:37', '2022-07-11 17:56:37');
INSERT INTO `tb_card_answer` VALUES ('105', '109', '为了防止不断的扩容和缩容对CPU造成一定的压力\n\n服务器内存使用的时候，堆空间在系统繁忙时会进行扩容，这个扩容也对生产环境的CPU造成一定的压力，而在空闲时间的时候又需要释放对应的空闲堆内存，这个操作也是对CPU会有一定的压力的', '0', '1', '1', '1', '2022-07-11 17:56:37', '2022-07-11 17:56:37');
INSERT INTO `tb_card_answer` VALUES ('106', '110', '第一种：在服务器上使用`jps`查看所有正在运行的JVM，然后使用`jstat -gc 进程ID`查看堆的内存信息\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/9SIWD4.png)\n\n第二种：启动jvm的时候使用`-XX:+PrintGCDetails`参数即可在程序结束的时候输出 \n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/tGtgtO.png)', '0', '1', '1', '1', '2022-07-11 17:56:37', '2022-07-11 17:56:37');
INSERT INTO `tb_card_answer` VALUES ('107', '111', '可以不分代，但是分代是为了提高GC的性能。针对不同类型的对象进行不同类型的垃圾回收算法来提升性能，减少对用户线程的影响', '0', '1', '1', '1', '2022-07-11 17:56:37', '2022-07-11 17:56:37');
INSERT INTO `tb_card_answer` VALUES ('108', '112', '解决的问题：堆空间是所有线程共享的，但是这样就出现了**线程安全的问题**（虽然可以使用加锁来解决，但是会影响性能）。所以就在Eden区为每个线程分配了一个**私有缓存区域（TLAB）**\n\n优点：分配首选，线程私有\n\n缺点：空间小', '0', '1', '1', '1', '2022-07-11 17:56:37', '2022-07-11 17:56:37');
INSERT INTO `tb_card_answer` VALUES ('109', '113', '目的：针对GC操作的一种优化，将一些本身是只有在一个方法中才会使用到的对象的分配到栈上，这样就可以在方法结束的时候随着栈的出栈而销毁。而不需要进行GC\n\n优点：\n\n+ **栈上分配**，减少了堆空间的占用，进而减少了GC的次数\n+ **同步忽略**，由于分配的是在栈上，所以是线程私有的，所以不需要将这个对象的数据进行同步加锁等操作。\n+ **分解标量替换**，将整个的大对象拆分成基础数据类型从而存放在栈的局部变量表中，从而完成栈上分配\n\n缺点：\n\n+ 技术不够成熟，逃逸分析本身需要JIT（即时编译器）消耗性能进行代码的分析。如果分析结果极端发现没有对象需要逃逸，那么这个操作就是多余的\n+ HotSpot，使用的是标量替换来完成的栈上空间分配。完美实现只有阿里的自研虚拟机\n\n实践：阿里自研的VM使用的GCIH技术就通过硬件的手段完成对逃逸分析的优化（钱解决了多余的操作）', '0', '1', '1', '1', '2022-07-11 17:56:37', '2022-07-11 17:56:37');
INSERT INTO `tb_card_answer` VALUES ('110', '114', '1. 永久代大小默认较小，字符串常量比较多\n2. 永久代垃圾回收频率较低。字符串一般使用过就不用了', '0', '1', '1', '1', '2022-07-11 17:56:37', '2022-07-11 17:56:37');
INSERT INTO `tb_card_answer` VALUES ('111', '115', '在清理的过程中是并发执行的。所以如果进行内存整理势必会和其他线程出现空间抢占的情况，或者说用户线程执行期间找不到原本的对象地址信息了。这样会对其他用户线程造成延时影响\n\n所以说，标记压缩算法，必须在STW的情况下', '0', '1', '1', '1', '2022-07-11 17:56:37', '2022-07-11 17:56:37');
INSERT INTO `tb_card_answer` VALUES ('112', '116', '按照数据类型分类：\n\n```\n基础数据类型\n引用数据类型\n```\n\n按照在类中的声明位置分：\n\n```\n成员变量\n - 类变量（Static修饰，是类本身具有的属性），在类加载的linking的prepare阶段给类变量赋予初始值。在initial阶段进行赋予具体的值（还有静态代码块进行操作）。 \n - 实例变量（没有static修饰，是实例才有的属性），随着对象的创建，在堆中分配对应实例的内存空间，并进行默认的赋值。\n局部变量，在使用前必须进行初始化赋值，否则编译不通过\n```', '0', '1', '1', '1', '2022-07-11 17:56:37', '2022-07-11 17:56:37');
INSERT INTO `tb_card_answer` VALUES ('113', '117', '1. 堆内存空间将原本的永久代变成了metaSpace\n2. 默认开启逃逸分析来优化实例对象分配内存空间到栈上', '0', '1', '1', '1', '2022-07-11 17:56:37', '2022-07-11 17:56:37');
INSERT INTO `tb_card_answer` VALUES ('114', '118', '`int pre=\"abc\"`表示的就是字符串常量\n\n`int suf=a+\"d\"`表示的就是字符串变量\n\n字符串常量：在编译过程中，就确定了知道这个`pre`的值，所以就直接放到了常量池中（最后在加载之后放到了方法区中的运行时常量池中）\n\n字符串变量：需要在运行时通过运算才能得到，这个时候是运行结束之后在堆空间中创建了对应的String实例对象来存储这个`suf`。\n\n所以有个面试题`==`和`equal`\n\n```java\npublic void StringEqual(){\n  String a=\"abc\";\n  String b=a+\"\";\n  //表面上看起来两个值都是一样的，但是进行==比较时返回false。因为存储的地方不一样，前者存储在方法区的运行时常量池中，后者存放在堆的实例对象中\n  //所以这个时候就需要进行equal比较，来比较两个值是否一样\n}\n```\n\njdk7的时候将字符串常量从永久代放到了堆空间中。因为永久代一般不进行回收，所以放在堆中', '0', '1', '1', '1', '2022-07-11 17:56:37', '2022-07-11 17:56:37');
INSERT INTO `tb_card_answer` VALUES ('115', '119', '+ 1.8之前是数组+链表，每个节点叫做Entry\n+ 1.8及其之后是数组+链表+红黑树，每个节点叫做Node\n\n数组中每个地方都是保存了key-value这样的实例，本身所有位置都是null。在put的时候会根据key的hash值计算一个index值\n\n![链表+数组](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/hashMap结构.png)\n\n\n\n\n\n```java\nhashMap的源码\n\n    static class Node<K,V> implements Map.Entry<K,V> {\n        final int hash;\n        final K key;\n        V value;\n        Node<K,V> next;\n    }\n```\n\n可以看到每个hashmap都需要四个参数，hash、key、value及next', '0', '1', '1', '1', '2022-07-12 17:14:48', '2022-07-12 17:14:48');
INSERT INTO `tb_card_answer` VALUES ('116', '120', '为了解决哈希冲突，即因为key进行hash计算的原因会导致不同key值计算出来的hashCode相同。所以index就相同。\n对于一个index会出现多个key-value。这个时候就需要使用链表来存储多个\n\n```java\nMap<String,String> map=new HashMap<>();\n\nmap.put(\"蛋炒饭\",\"我爱吃蛋炒饭\");\nmap.put(\"饭炒蛋\",\"我爱吃蛋炒饭\");\n```\n\n即比如`蛋炒饭`和`饭炒蛋`两个值计算的hash数值一样的时候。就会导致存入的index是同一个，这个时候就需要使用链表来将其存储在同一个index上', '0', '1', '1', '1', '2022-07-12 17:14:48', '2022-07-12 17:14:48');
INSERT INTO `tb_card_answer` VALUES ('117', '121', '链表查询效率较低。在数量特别大的时候查询销量是O(n)不利于。所以在链表的长度超过了8之后，链表就转换成红黑树的数据结构，红黑树的特性让它的查询效率基本平均。', '0', '1', '1', '1', '2022-07-12 17:14:48', '2022-07-12 17:14:48');
INSERT INTO `tb_card_answer` VALUES ('118', '122', '### 数组\n\n一段连续的内存空间隔开不同node的结构\n\n优点：按照下标寻址速度快\n\n缺点：插入操作复杂（需要操作当前节点的所有后续节点）需要连续的内存空间\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/fWcHB3.jpg)\n\n### 链表\n\n使用指针指向将不同的node进行连接起来\n\n优点：插入删除等操作执行方便，只需要执行前中后三个节点即可\n\n缺点：使用下标寻址需要从头节点一直遍历到尾节点，不太方便\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/0h0kHP.jpg)\n\n\n### 红黑树\n\n**特性**\n\n1. 满足基本的平衡二叉查找树\n2. 根节点是黑色的,且叶子节点是黑色的不存储数据的NIL\n3. 任何相邻的两个节点不能都是红色\n4. 从任意节点到叶子节点包含相同的黑色节点\n\n近乎平衡,所以查询、插入、删除的操作的时间复杂度都是O(log2^n)', '0', '1', '1', '1', '2022-07-12 17:14:48', '2022-07-12 17:14:48');
INSERT INTO `tb_card_answer` VALUES ('119', '123', '针对链表的插入，也就是hash值相同时，java8之前使用的头插法，即新来的值会在插入链表头部。因为开发者认为新来的值检索的可能性更大，这样可以提升查询效率。\n\njava8之后，都改成了尾插法。因为hashMap的扩容机制\n\n**为什么不是用头插法了，而使用尾插法呢？**\n\n因为在多线程的时候，如果一个线程在插入头部的时候，处理器或者其他问题中间插入了一条新的。由于头插法会改变链表中的顺序，所以会在resize扩容的时候出现环形链表的情况。这也就是为什么hashMap是线程不安全的原因\n\njdk8之后，链表使用了红黑树。红黑树将链表的时间复杂度从O(n)降到了O(logn)。如果**使用尾插**，在扩容时会保持链表元素原本的顺序，就不会出现链表成环的问题了。\n\n但是这样仍然没办法解决线程不安全的问题，毕竟存在一个线程在做put的时候还有其他在做get。还是需要使用加锁来解决这个问题。', '0', '1', '1', '1', '2022-07-12 17:14:48', '2022-07-12 17:14:48');
INSERT INTO `tb_card_answer` VALUES ('120', '124', '### put\n\nPut步骤：\n1、hash运算：进行Hash获取对应的HashCode，这个操作减少了hash冲突的可能，将所有的32位全部参与运算（高位的数据右移到低位的16位，然后与自己做异或，那就是把高位和低位的数据进行混合，以此来加大低位的随机性）<br/>\n2、是否初始化：判断数组是否为空，如果为空就进行第一次扩容（初始化类似）<br/>\n3、定位数组下标：按照key的hash值找到在数组的下标位置。判断数组上的第一个元素的key是否等于该key。如果等于就直接覆盖，如果不等于就去遍历该下标下面的链表结构<br/>\n4、更新或者新增：判断结构是红黑树还是链表，并按照对应的结构进行遍历，如果找到key一致的就进行更新，如果没找到就在尾部新增一条数据。<br/>\n5、转换红黑树：然后判断是否大于8如果大于8就转换成红黑树（对于该结构为链表的时候）\n\nput代码：\n\n```java\n    \n    public V put(K key, V value) {\n        //先进行hash操作\n        return putVal(hash(key), key, value, false, true);\n    }\n\n    final V putVal(int hash, K key, V value, boolean onlyIfAbsent,\n                   boolean evict) {\n        //tab：就是数组，p：是数组上链接的那个链表的首节点，n：是数组的长度，i：是hash取模后的下标\n        HashMap.Node<K,V>[] tab; HashMap.Node<K,V> p; int n, i;\n        //如果是空的时候就进行初始化\n        if ((tab = table) == null || (n = tab.length) == 0)\n            n = (tab = resize()).length;\n        //如果要插入的数组下标节点的链表是空的就会创建一个链表\n        if ((p = tab[i = (n - 1) & hash]) == null)\n            tab[i] = newNode(hash, key, value, null);\n        //不为空的链表就直接在链表上进行操作\n        else {\n            HashMap.Node<K,V> e; K k;\n            //如果当前的k-v与首节点哈希值和key都相等，赋值p->e，也就是插入的是同一个key就进行更新操作即可\n            if (p.hash == hash &&\n                    ((k = p.key) == key || (key != null && key.equals(k))))\n                e = p;\n            //结构为红黑树，则按照红黑树的方式进行添加\n            else if (p instanceof HashMap.TreeNode)\n                e = ((HashMap.TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);\n            //遍历整个链表来找到最后的节点进行增加元素\n            else {\n                //1。 遍历整个链表\n                for (int binCount = 0; ; ++binCount) {\n                    //2。 如果是找到了最后的节点还没跳出整个循环则将数据添加到尾节点上，即next==null\n                    if ((e = p.next) == null) {\n                        //3。 创建新的节点\n                        p.next = newNode(hash, key, value, null);\n                        //4。 如果链表的长度超过了8（上面是先遍历后+所以这个地方判断是否>=7）将链表转变成红黑树\n                        if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st\n                            //4。1将链表转变成红黑树\n                            treeifyBin(tab, hash);\n                        break;\n                    }\n                    //当前遍历到的节点e的哈希值和key与k-v的相等则退出循环，因为这里只处理新增（一般不会出现这种情况，应该在上面就已经拦截住了）\n                    if (e.hash == hash &&\n                            ((k = e.key) == key || (key != null && key.equals(k))))\n                        break;\n                    //当前节点e不为尾结点，将e->p，继续遍历\n                    p = e;\n                }\n            }\n            //处理更新操作，新值换旧值\n            if (e != null) { // existing mapping for key\n                V oldValue = e.value;\n                if (!onlyIfAbsent || oldValue == null)\n                    e.value = value;\n                afterNodeAccess(e);\n                return oldValue;\n            }\n        }\n        ++modCount;\n        //如果当前map中包含的k-v键值数超过了阈值threshold则扩容resize\n        if (++size > threshold)\n            resize();\n        afterNodeInsertion(evict);\n        return null;\n    }\n```\n\n结论：\n\n1. 如果链表长度超过8则转换成红黑树：`if (binCount >= TREEIFY_THRESHOLD - 1)  treeifyBin(tab, hash); `\n2. 如果数组元素超过阀值则进行扩容；默认值：`(int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY)`即 16*0.75=12；`if (++size > threshold) resize();`\n3. 先将key进行hash（(h = key.hashCode()) ^ (h >>> 16)）也就是先将原始值右移16位然后再和原始值进行异或处理，这样做的目的就是为了将16位数字全部参加运算（相当于这个数值是完整的32位操作得出来的）这样可以降低hash冲突的可能性。 ![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/hashMap1.png)\n\n![借用大佬的一张流程图](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/hashMap.png)\n\n### Get\n\nGet步骤：\n1、hash获取hashCode：和Put一样的Hash规则<br/>\n2、使用hashCode获取数组下标<br/>\n3、判断其衔接的结构是红黑树还是链表，按照对应的结构进行遍历来比对key值\n\n### Resize\n\n原理：\n\n两个因素\n\n+ Capcity，及hashMap的当前长度，默认16\n+ LoadFactor，负载因子，默认0.75f\n\n这个0.75即插入的数据在hashmap中占用了75%的空间之后就会进行扩容\n\n扩容方式：\n\n> 创建一个新的Entry空数组，长度是原有数组的两倍\n> 遍历原有的Entry数组，将所有的Entry重新计算hash到新数组中\n\n为什么要重新hash呢。因为长度变大了，hash值就变了\n\nhash的公式：`index=HashCode(Key)&(Length-1)`', '0', '1', '1', '1', '2022-07-12 17:14:48', '2022-07-12 17:14:48');
INSERT INTO `tb_card_answer` VALUES ('121', '125', '我们知道最基础的ConcurrentHashMap和HashMap的区别在于前者是线程安全的。那什么是线程安全，就是多个线程对一个资源或者一个数据进行访问的时候得遵循加锁原则也就是只有上一个访问完成之后才允许下一个访问\n\n<font color=\"red\">**Java7**</font>及其之前：\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/qfgARp.jpg)\n\n其中有一个Segment的概念，使用分段锁的概念（一个Segment就是一个分段锁，一个线程访问一个Segment的时候不会影响到其他的Segment的操作）\n\n\n\n\n<font color=\"red\">**Java8**</font>之后：\n\n1. 加锁范围尽量的小，抛弃了Segment的概念而采用CAS + synchronized来保证线程安全\n2. 也和HashMap的优化一样增加了红黑树来协助取数据链表的速度慢的问题\n3. 扩容\n4. 将原本的HashEntry 改为 Node。其中的val next 都用了 volatile', '0', '1', '1', '1', '2022-07-12 17:14:48', '2022-07-12 17:14:48');
INSERT INTO `tb_card_answer` VALUES ('122', '126', '### concurrentHashMap相较于hashMap\n\n1. concurrentHashMap对桶数组进行了分割分段成Segment。对每个Segment使用lock进行锁住保证线程安全\n2. concurrentHashmap不允许存储null\n3. 结构上和hashMap一样，1.8之后也是增加了红黑树\n\n### hashmap和hashTable\n\n1. hashTable将整个数组锁住，所以是线程安全的\n2. hashTable不允许存储null\n3. hashTable结构是数组+链表，没有红黑树\n\n### concurrentHashMap和hashTable的区别\n\nhashTable对整个数组上锁（锁的粒度太大导致效率更低）\n\nhashTable不支持红黑树\n\n### 总结\n\nhashTable属于即将废弃的，不建议使用\n\nhashMap是线程不安全的，如果要处理并发的业务逻辑的时候要使用concurrentHashMap。但相较的就要牺牲一部分性能问题', '0', '1', '1', '1', '2022-07-12 17:14:48', '2022-07-12 17:14:48');
INSERT INTO `tb_card_answer` VALUES ('123', '127', '为什么默认长度是16且扩容一般按照2的次幂扩容\n\n```\n源码:\n    static final int DEFAULT_INITIAL_CAPACITY = 1 << 4; // aka 16\n    默认初始化容量\n    1 << 4相当于位运算，及1*2的4次方\n```\n\n1. 这里是位运算，首先需要是2的幂次方，为了使扩容之后原有的key对应的code的index转换二进制的时候，只有最左边新增了一个1，这样可以\n2. 为什么选择16呢，因为在使用不是2的幂的数字的时候，Length-1的值是所有二进制位全为1，这种情况下，index的结果等同于HashCode后几位的值。只要输入的HashCode本身分布均匀，Hash算法的结果就是均匀的。（简而言之，其他数进行hash的时候出现同一个链表的情况较多，不均匀）\n\nhashMap的值在put的时候才会分配内存空间。如果toSize<16分配的内存空间是16。大于则按照2的幂次方往上累加\n\n不是其他小于16的2次幂是因为为了减少扩容的概率。一般不会用到超过16但是会超过8等', '0', '1', '1', '1', '2022-07-12 17:14:48', '2022-07-12 17:14:48');
INSERT INTO `tb_card_answer` VALUES ('124', '128', '使用数组和链表来存储数据，当链表长度超过8的时候就会转换成红黑树。在存储的时候首先使用hashcode进行取模获得索引值。如果发生碰撞就使用equals来判断是否与之相等\n\nHashMap采用Entry数组来存储key-value对，每一个键值对组成了一个Entry实体，Entry类实际上是一个单向的链表结构，它具有Next指针，可以连接下一个Entry实体。 只是在JDK1.8中，链表长度大于8的时候，链表会转成红黑树。为6转换成链表', '0', '1', '1', '1', '2022-07-12 17:14:48', '2022-07-12 17:14:48');
INSERT INTO `tb_card_answer` VALUES ('125', '129', '1. 首先使用`hashcode`找到对应的`bucket`\n2. 然后使用`equals`方法找到链表上对应的元素', '0', '1', '1', '1', '2022-07-12 17:14:48', '2022-07-12 17:14:48');
INSERT INTO `tb_card_answer` VALUES ('126', '130', '1. hashmap是有数组和链表组成的，但是一般为了提升效率，所以将存储的值均匀分布，也就是保证一个链表上只有一个值。当数组达到上限的时候，就需要**增大数组容量**。这个过程就是扩容\n\n2. 为了能提高查询效率，也为了能够存储更多的数据\n\n3. 一般在元素个数到达（数据大小*负载因子）的时候扩容\n\n4. 按照2^n扩容\n\n注：\n\n1. 扩容会带来的问题是resize\n2. 负载因子就是loadFactor，默认是0.75。在创建对象的时候可以传入', '0', '1', '1', '1', '2022-07-12 17:14:48', '2022-07-12 17:14:48');
INSERT INTO `tb_card_answer` VALUES ('127', '131', '产生原因，hashMap并不是线程安全的。所以在并发的情况下可能会出现多个线程同时使用同一个数据。这样就有可能会出现一个数据被修改的时候另一个线程也在修改。这就导致不一致的问题\n\n解决方案：使用HashTable或者ConCurrentHashMap这种线程安全的实现类。还有`vector`', '0', '1', '1', '1', '2022-07-12 17:14:48', '2022-07-12 17:14:48');
INSERT INTO `tb_card_answer` VALUES ('128', '132', '不会的，HashMap 的tableSizeFor方法做了处理，能保证n永远都是2次幂。\n\n```java\n/**\n * Returns a power of two size for the given target capacity.\n */\nstatic final int tableSizeFor(int cap) {\n    //cap-1后，n的二进制最右一位肯定和cap的最右一位不同，即一个为0，一个为1，例如cap=17（00010001），n=cap-1=16（00010000）\n    int n = cap - 1;\n    //n = (00010000 | 00001000) = 00011000\n    n |= n >>> 1;\n    //n = (00011000 | 00000110) = 00011110\n    n |= n >>> 2;\n    //n = (00011110 | 00000001) = 00011111\n    n |= n >>> 4;\n    //n = (00011111 | 00000000) = 00011111\n    n |= n >>> 8;\n    //n = (00011111 | 00000000) = 00011111\n    n |= n >>> 16;\n    //n = 00011111 = 31\n    //n = 31 + 1 = 32, 即最终的cap = 32 = 2 的 (n=5)次方\n    return (n < 0) ? 1 : (n >= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;\n}\n\n```', '0', '1', '1', '1', '2022-07-12 17:14:48', '2022-07-12 17:14:48');
INSERT INTO `tb_card_answer` VALUES ('129', '133', '几乎等价于hashTable，除了hashMap是**非线程安全**的以及**允许key=null**', '0', '1', '1', '1', '2022-07-12 17:14:48', '2022-07-12 17:14:48');
INSERT INTO `tb_card_answer` VALUES ('130', '134', '针对一些非线程安全的集合框架来说。如果使用**iterator**对集合遍历的同时，出现本身或其他线程对该集合的结构进行了修改。就会抛出ConcurrentModificationException异常。\n\n实际上就是系统发现自己要iterator的对象出现了无法预料的变更就会立即终止进行遍历\n\n```java\nif (size > 0 && (tab = table) != null) {\n    int mc = modCount;\n    for (int i = 0; i < tab.length; ++i) {\n        for (Node<K, V> e = tab[i]; e != null; e = e.next)\n            action.accept(e.key);\n    }\n    if (modCount != mc)\n        throw new ConcurrentModificationException();\n}\n```\n\n在遍历`table`的过程中，该线程或者其他线程如果对`hashMap`进行了修改操作,那么 `++modCount`。这个时候遍历的过程就会出现`modCount != mc`', '0', '1', '1', '1', '2022-07-12 17:14:48', '2022-07-12 17:14:48');
INSERT INTO `tb_card_answer` VALUES ('131', '135', '- `LinkedHashMap`保存了记录的插入顺序，在用`Iterator`遍历时,先取到的记录肯定是先插入的；遍历比`HashMap`慢；在需要输出的顺序和输入的顺序相同的情况下。\n- `TreeMap`实现`SortMap`接口，能够把它保存的记录根据键排序(默认按键值升序排序，也可以指定排序的比较器)；在需要按自然顺序或自定义顺序遍历键的情况下;', '0', '1', '1', '1', '2022-07-12 17:14:48', '2022-07-12 17:14:48');
INSERT INTO `tb_card_answer` VALUES ('132', '136', '使用 java.util.Collections 类的 `synchronizedMap` 方法包装`HashMap`，这样的创建的对象就相当于所有的方法上都加上了`synchorized`关键字，就可以保证线程安全\n\n```\nCollections中的synchronized方法：\npublic static <K,V> Map<K,V> synchronizedMap(Map<K,V> m) {\n    return new SynchronizedMap<>(m);\n}\n\n调用的时候：\nMap<String, String> map = Collections.synchronizedMap(new HashMap<>());\n```', '0', '1', '1', '1', '2022-07-12 17:14:48', '2022-07-12 17:14:48');
INSERT INTO `tb_card_answer` VALUES ('133', '137', '+ 从链表插入的头插法转换成尾插法。解决可能出现的死锁和循环链表的情况\n\n  > 循环链表原因：原本使用头插法在进行扩容的时候，数据转移就会从`A->B->C`变成`C->B->A`。转移期间如果出现另一个线程也插入数据发现需要扩容了也进行转移，就会出现B一直需要指向的next元素是A导致循环链表\n\n+ 从数组+链表变成了数组+链表+红黑树的结构\n\n+ JDK8中对算哈希值的哈希算法进行了简化以提高运算效率', '0', '1', '1', '1', '2022-07-12 17:14:48', '2022-07-12 17:14:48');
INSERT INTO `tb_card_answer` VALUES ('134', '138', '+ 1.8之前是数组+链表，每个节点叫做Entry\n+ 1.8及其之后是数组+链表+红黑树，每个节点叫做Node\n\n数组中每个地方都是保存了key-value这样的实例，本身所有位置都是null。在put的时候会根据key的hash值计算一个index值\n\n![链表+数组](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/hashMap结构.png)\n\n\n\n\n\n```java\nhashMap的源码\n\n    static class Node<K,V> implements Map.Entry<K,V> {\n        final int hash;\n        final K key;\n        V value;\n        Node<K,V> next;\n    }\n```\n\n可以看到每个hashmap都需要四个参数，hash、key、value及next', '0', '1', '1', '1', '2022-07-13 15:50:16', '2022-07-13 15:50:16');
INSERT INTO `tb_card_answer` VALUES ('135', '139', '为了解决哈希冲突，即因为key进行hash计算的原因会导致不同key值计算出来的hashCode相同。所以index就相同。\n对于一个index会出现多个key-value。这个时候就需要使用链表来存储多个\n\n```java\nMap<String,String> map=new HashMap<>();\n\nmap.put(\"蛋炒饭\",\"我爱吃蛋炒饭\");\nmap.put(\"饭炒蛋\",\"我爱吃蛋炒饭\");\n```\n\n即比如`蛋炒饭`和`饭炒蛋`两个值计算的hash数值一样的时候。就会导致存入的index是同一个，这个时候就需要使用链表来将其存储在同一个index上', '0', '1', '1', '1', '2022-07-13 15:50:16', '2022-07-13 15:50:16');
INSERT INTO `tb_card_answer` VALUES ('136', '140', '链表查询效率较低。在数量特别大的时候查询销量是O(n)不利于。所以在链表的长度超过了8之后，链表就转换成红黑树的数据结构，红黑树的特性让它的查询效率基本平均。', '0', '1', '1', '1', '2022-07-13 15:50:16', '2022-07-13 15:50:16');
INSERT INTO `tb_card_answer` VALUES ('137', '141', '### 数组\n\n一段连续的内存空间隔开不同node的结构\n\n优点：按照下标寻址速度快\n\n缺点：插入操作复杂（需要操作当前节点的所有后续节点）需要连续的内存空间\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/fWcHB3.jpg)\n\n### 链表\n\n使用指针指向将不同的node进行连接起来\n\n优点：插入删除等操作执行方便，只需要执行前中后三个节点即可\n\n缺点：使用下标寻址需要从头节点一直遍历到尾节点，不太方便\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/0h0kHP.jpg)\n\n\n### 红黑树\n\n**特性**\n\n1. 满足基本的平衡二叉查找树\n2. 根节点是黑色的,且叶子节点是黑色的不存储数据的NIL\n3. 任何相邻的两个节点不能都是红色\n4. 从任意节点到叶子节点包含相同的黑色节点\n\n近乎平衡,所以查询、插入、删除的操作的时间复杂度都是O(log2^n)', '0', '1', '1', '1', '2022-07-13 15:50:16', '2022-07-13 15:50:16');
INSERT INTO `tb_card_answer` VALUES ('138', '142', '针对链表的插入，也就是hash值相同时，java8之前使用的头插法，即新来的值会在插入链表头部。因为开发者认为新来的值检索的可能性更大，这样可以提升查询效率。\n\njava8之后，都改成了尾插法。因为hashMap的扩容机制\n\n**为什么不是用头插法了，而使用尾插法呢？**\n\n因为在多线程的时候，如果一个线程在插入头部的时候，处理器或者其他问题中间插入了一条新的。由于头插法会改变链表中的顺序，所以会在resize扩容的时候出现环形链表的情况。这也就是为什么hashMap是线程不安全的原因\n\njdk8之后，链表使用了红黑树。红黑树将链表的时间复杂度从O(n)降到了O(logn)。如果**使用尾插**，在扩容时会保持链表元素原本的顺序，就不会出现链表成环的问题了。\n\n但是这样仍然没办法解决线程不安全的问题，毕竟存在一个线程在做put的时候还有其他在做get。还是需要使用加锁来解决这个问题。', '0', '1', '1', '1', '2022-07-13 15:50:16', '2022-07-13 15:50:16');
INSERT INTO `tb_card_answer` VALUES ('139', '143', '### put\n\nPut步骤：\n1、hash运算：进行Hash获取对应的HashCode，这个操作减少了hash冲突的可能，将所有的32位全部参与运算（高位的数据右移到低位的16位，然后与自己做异或，那就是把高位和低位的数据进行混合，以此来加大低位的随机性）<br/>\n2、是否初始化：判断数组是否为空，如果为空就进行第一次扩容（初始化类似）<br/>\n3、定位数组下标：按照key的hash值找到在数组的下标位置。判断数组上的第一个元素的key是否等于该key。如果等于就直接覆盖，如果不等于就去遍历该下标下面的链表结构<br/>\n4、更新或者新增：判断结构是红黑树还是链表，并按照对应的结构进行遍历，如果找到key一致的就进行更新，如果没找到就在尾部新增一条数据。<br/>\n5、转换红黑树：然后判断是否大于8如果大于8就转换成红黑树（对于该结构为链表的时候）\n\nput代码：\n\n```java\n    \n    public V put(K key, V value) {\n        //先进行hash操作\n        return putVal(hash(key), key, value, false, true);\n    }\n\n    final V putVal(int hash, K key, V value, boolean onlyIfAbsent,\n                   boolean evict) {\n        //tab：就是数组，p：是数组上链接的那个链表的首节点，n：是数组的长度，i：是hash取模后的下标\n        HashMap.Node<K,V>[] tab; HashMap.Node<K,V> p; int n, i;\n        //如果是空的时候就进行初始化\n        if ((tab = table) == null || (n = tab.length) == 0)\n            n = (tab = resize()).length;\n        //如果要插入的数组下标节点的链表是空的就会创建一个链表\n        if ((p = tab[i = (n - 1) & hash]) == null)\n            tab[i] = newNode(hash, key, value, null);\n        //不为空的链表就直接在链表上进行操作\n        else {\n            HashMap.Node<K,V> e; K k;\n            //如果当前的k-v与首节点哈希值和key都相等，赋值p->e，也就是插入的是同一个key就进行更新操作即可\n            if (p.hash == hash &&\n                    ((k = p.key) == key || (key != null && key.equals(k))))\n                e = p;\n            //结构为红黑树，则按照红黑树的方式进行添加\n            else if (p instanceof HashMap.TreeNode)\n                e = ((HashMap.TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);\n            //遍历整个链表来找到最后的节点进行增加元素\n            else {\n                //1。 遍历整个链表\n                for (int binCount = 0; ; ++binCount) {\n                    //2。 如果是找到了最后的节点还没跳出整个循环则将数据添加到尾节点上，即next==null\n                    if ((e = p.next) == null) {\n                        //3。 创建新的节点\n                        p.next = newNode(hash, key, value, null);\n                        //4。 如果链表的长度超过了8（上面是先遍历后+所以这个地方判断是否>=7）将链表转变成红黑树\n                        if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st\n                            //4。1将链表转变成红黑树\n                            treeifyBin(tab, hash);\n                        break;\n                    }\n                    //当前遍历到的节点e的哈希值和key与k-v的相等则退出循环，因为这里只处理新增（一般不会出现这种情况，应该在上面就已经拦截住了）\n                    if (e.hash == hash &&\n                            ((k = e.key) == key || (key != null && key.equals(k))))\n                        break;\n                    //当前节点e不为尾结点，将e->p，继续遍历\n                    p = e;\n                }\n            }\n            //处理更新操作，新值换旧值\n            if (e != null) { // existing mapping for key\n                V oldValue = e.value;\n                if (!onlyIfAbsent || oldValue == null)\n                    e.value = value;\n                afterNodeAccess(e);\n                return oldValue;\n            }\n        }\n        ++modCount;\n        //如果当前map中包含的k-v键值数超过了阈值threshold则扩容resize\n        if (++size > threshold)\n            resize();\n        afterNodeInsertion(evict);\n        return null;\n    }\n```\n\n结论：\n\n1. 如果链表长度超过8则转换成红黑树：`if (binCount >= TREEIFY_THRESHOLD - 1)  treeifyBin(tab, hash); `\n2. 如果数组元素超过阀值则进行扩容；默认值：`(int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY)`即 16*0.75=12；`if (++size > threshold) resize();`\n3. 先将key进行hash（(h = key.hashCode()) ^ (h >>> 16)）也就是先将原始值右移16位然后再和原始值进行异或处理，这样做的目的就是为了将16位数字全部参加运算（相当于这个数值是完整的32位操作得出来的）这样可以降低hash冲突的可能性。 ![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/hashMap1.png)\n\n![借用大佬的一张流程图](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/hashMap.png)\n\n### Get\n\nGet步骤：\n1、hash获取hashCode：和Put一样的Hash规则<br/>\n2、使用hashCode获取数组下标<br/>\n3、判断其衔接的结构是红黑树还是链表，按照对应的结构进行遍历来比对key值\n\n### Resize\n\n原理：\n\n两个因素\n\n+ Capcity，及hashMap的当前长度，默认16\n+ LoadFactor，负载因子，默认0.75f\n\n这个0.75即插入的数据在hashmap中占用了75%的空间之后就会进行扩容\n\n扩容方式：\n\n> 创建一个新的Entry空数组，长度是原有数组的两倍\n> 遍历原有的Entry数组，将所有的Entry重新计算hash到新数组中\n\n为什么要重新hash呢。因为长度变大了，hash值就变了\n\nhash的公式：`index=HashCode(Key)&(Length-1)`', '0', '1', '1', '1', '2022-07-13 15:50:16', '2022-07-13 15:50:16');
INSERT INTO `tb_card_answer` VALUES ('140', '144', '我们知道最基础的ConcurrentHashMap和HashMap的区别在于前者是线程安全的。那什么是线程安全，就是多个线程对一个资源或者一个数据进行访问的时候得遵循加锁原则也就是只有上一个访问完成之后才允许下一个访问\n\n<font color=\"red\">**Java7**</font>及其之前：\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/qfgARp.jpg)\n\n其中有一个Segment的概念，使用分段锁的概念（一个Segment就是一个分段锁，一个线程访问一个Segment的时候不会影响到其他的Segment的操作）\n\n\n\n\n<font color=\"red\">**Java8**</font>之后：\n\n1. 加锁范围尽量的小，抛弃了Segment的概念而采用CAS + synchronized来保证线程安全\n2. 也和HashMap的优化一样增加了红黑树来协助取数据链表的速度慢的问题\n3. 扩容\n4. 将原本的HashEntry 改为 Node。其中的val next 都用了 volatile', '0', '1', '1', '1', '2022-07-13 15:50:16', '2022-07-13 15:50:16');
INSERT INTO `tb_card_answer` VALUES ('141', '145', '### concurrentHashMap相较于hashMap\n\n1. concurrentHashMap对桶数组进行了分割分段成Segment。对每个Segment使用lock进行锁住保证线程安全\n2. concurrentHashmap不允许存储null\n3. 结构上和hashMap一样，1.8之后也是增加了红黑树\n\n### hashmap和hashTable\n\n1. hashTable将整个数组锁住，所以是线程安全的\n2. hashTable不允许存储null\n3. hashTable结构是数组+链表，没有红黑树\n\n### concurrentHashMap和hashTable的区别\n\nhashTable对整个数组上锁（锁的粒度太大导致效率更低）\n\nhashTable不支持红黑树\n\n### 总结\n\nhashTable属于即将废弃的，不建议使用\n\nhashMap是线程不安全的，如果要处理并发的业务逻辑的时候要使用concurrentHashMap。但相较的就要牺牲一部分性能问题', '0', '1', '1', '1', '2022-07-13 15:50:16', '2022-07-13 15:50:16');
INSERT INTO `tb_card_answer` VALUES ('142', '146', '为什么默认长度是16且扩容一般按照2的次幂扩容\n\n```\n源码:\n    static final int DEFAULT_INITIAL_CAPACITY = 1 << 4; // aka 16\n    默认初始化容量\n    1 << 4相当于位运算，及1*2的4次方\n```\n\n1. 这里是位运算，首先需要是2的幂次方，为了使扩容之后原有的key对应的code的index转换二进制的时候，只有最左边新增了一个1，这样可以\n2. 为什么选择16呢，因为在使用不是2的幂的数字的时候，Length-1的值是所有二进制位全为1，这种情况下，index的结果等同于HashCode后几位的值。只要输入的HashCode本身分布均匀，Hash算法的结果就是均匀的。（简而言之，其他数进行hash的时候出现同一个链表的情况较多，不均匀）\n\nhashMap的值在put的时候才会分配内存空间。如果toSize<16分配的内存空间是16。大于则按照2的幂次方往上累加\n\n不是其他小于16的2次幂是因为为了减少扩容的概率。一般不会用到超过16但是会超过8等', '0', '1', '1', '1', '2022-07-13 15:50:16', '2022-07-13 15:50:16');
INSERT INTO `tb_card_answer` VALUES ('143', '147', '使用数组和链表来存储数据，当链表长度超过8的时候就会转换成红黑树。在存储的时候首先使用hashcode进行取模获得索引值。如果发生碰撞就使用equals来判断是否与之相等\n\nHashMap采用Entry数组来存储key-value对，每一个键值对组成了一个Entry实体，Entry类实际上是一个单向的链表结构，它具有Next指针，可以连接下一个Entry实体。 只是在JDK1.8中，链表长度大于8的时候，链表会转成红黑树。为6转换成链表', '0', '1', '1', '1', '2022-07-13 15:50:16', '2022-07-13 15:50:16');
INSERT INTO `tb_card_answer` VALUES ('144', '148', '1. 首先使用`hashcode`找到对应的`bucket`\n2. 然后使用`equals`方法找到链表上对应的元素', '0', '1', '1', '1', '2022-07-13 15:50:16', '2022-07-13 15:50:16');
INSERT INTO `tb_card_answer` VALUES ('145', '149', '1. hashmap是有数组和链表组成的，但是一般为了提升效率，所以将存储的值均匀分布，也就是保证一个链表上只有一个值。当数组达到上限的时候，就需要**增大数组容量**。这个过程就是扩容\n\n2. 为了能提高查询效率，也为了能够存储更多的数据\n\n3. 一般在元素个数到达（数据大小*负载因子）的时候扩容\n\n4. 按照2^n扩容\n\n注：\n\n1. 扩容会带来的问题是resize\n2. 负载因子就是loadFactor，默认是0.75。在创建对象的时候可以传入', '0', '1', '1', '1', '2022-07-13 15:50:16', '2022-07-13 15:50:16');
INSERT INTO `tb_card_answer` VALUES ('146', '150', '产生原因，hashMap并不是线程安全的。所以在并发的情况下可能会出现多个线程同时使用同一个数据。这样就有可能会出现一个数据被修改的时候另一个线程也在修改。这就导致不一致的问题\n\n解决方案：使用HashTable或者ConCurrentHashMap这种线程安全的实现类。还有`vector`', '0', '1', '1', '1', '2022-07-13 15:50:16', '2022-07-13 15:50:16');
INSERT INTO `tb_card_answer` VALUES ('147', '151', '不会的，HashMap 的tableSizeFor方法做了处理，能保证n永远都是2次幂。\n\n```java\n/**\n * Returns a power of two size for the given target capacity.\n */\nstatic final int tableSizeFor(int cap) {\n    //cap-1后，n的二进制最右一位肯定和cap的最右一位不同，即一个为0，一个为1，例如cap=17（00010001），n=cap-1=16（00010000）\n    int n = cap - 1;\n    //n = (00010000 | 00001000) = 00011000\n    n |= n >>> 1;\n    //n = (00011000 | 00000110) = 00011110\n    n |= n >>> 2;\n    //n = (00011110 | 00000001) = 00011111\n    n |= n >>> 4;\n    //n = (00011111 | 00000000) = 00011111\n    n |= n >>> 8;\n    //n = (00011111 | 00000000) = 00011111\n    n |= n >>> 16;\n    //n = 00011111 = 31\n    //n = 31 + 1 = 32, 即最终的cap = 32 = 2 的 (n=5)次方\n    return (n < 0) ? 1 : (n >= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;\n}\n\n```', '0', '1', '1', '1', '2022-07-13 15:50:16', '2022-07-13 15:50:16');
INSERT INTO `tb_card_answer` VALUES ('148', '152', '几乎等价于hashTable，除了hashMap是**非线程安全**的以及**允许key=null**', '0', '1', '1', '1', '2022-07-13 15:50:16', '2022-07-13 15:50:16');
INSERT INTO `tb_card_answer` VALUES ('149', '153', '针对一些非线程安全的集合框架来说。如果使用**iterator**对集合遍历的同时，出现本身或其他线程对该集合的结构进行了修改。就会抛出ConcurrentModificationException异常。\n\n实际上就是系统发现自己要iterator的对象出现了无法预料的变更就会立即终止进行遍历\n\n```java\nif (size > 0 && (tab = table) != null) {\n    int mc = modCount;\n    for (int i = 0; i < tab.length; ++i) {\n        for (Node<K, V> e = tab[i]; e != null; e = e.next)\n            action.accept(e.key);\n    }\n    if (modCount != mc)\n        throw new ConcurrentModificationException();\n}\n```\n\n在遍历`table`的过程中，该线程或者其他线程如果对`hashMap`进行了修改操作,那么 `++modCount`。这个时候遍历的过程就会出现`modCount != mc`', '0', '1', '1', '1', '2022-07-13 15:50:16', '2022-07-13 15:50:16');
INSERT INTO `tb_card_answer` VALUES ('150', '154', '- `LinkedHashMap`保存了记录的插入顺序，在用`Iterator`遍历时,先取到的记录肯定是先插入的；遍历比`HashMap`慢；在需要输出的顺序和输入的顺序相同的情况下。\n- `TreeMap`实现`SortMap`接口，能够把它保存的记录根据键排序(默认按键值升序排序，也可以指定排序的比较器)；在需要按自然顺序或自定义顺序遍历键的情况下;', '0', '1', '1', '1', '2022-07-13 15:50:16', '2022-07-13 15:50:16');
INSERT INTO `tb_card_answer` VALUES ('151', '155', '使用 java.util.Collections 类的 `synchronizedMap` 方法包装`HashMap`，这样的创建的对象就相当于所有的方法上都加上了`synchorized`关键字，就可以保证线程安全\n\n```\nCollections中的synchronized方法：\npublic static <K,V> Map<K,V> synchronizedMap(Map<K,V> m) {\n    return new SynchronizedMap<>(m);\n}\n\n调用的时候：\nMap<String, String> map = Collections.synchronizedMap(new HashMap<>());\n```', '0', '1', '1', '1', '2022-07-13 15:50:16', '2022-07-13 15:50:16');
INSERT INTO `tb_card_answer` VALUES ('152', '156', '+ 从链表插入的头插法转换成尾插法。解决可能出现的死锁和循环链表的情况\n\n  > 循环链表原因：原本使用头插法在进行扩容的时候，数据转移就会从`A->B->C`变成`C->B->A`。转移期间如果出现另一个线程也插入数据发现需要扩容了也进行转移，就会出现B一直需要指向的next元素是A导致循环链表\n\n+ 从数组+链表变成了数组+链表+红黑树的结构\n\n+ JDK8中对算哈希值的哈希算法进行了简化以提高运算效率', '0', '1', '1', '1', '2022-07-13 15:50:16', '2022-07-13 15:50:16');
INSERT INTO `tb_card_answer` VALUES ('153', '157', '+ 1.8之前是数组+链表，每个节点叫做Entry\n+ 1.8及其之后是数组+链表+红黑树，每个节点叫做Node\n\n数组中每个地方都是保存了key-value这样的实例，本身所有位置都是null。在put的时候会根据key的hash值计算一个index值\n\n![链表+数组](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/hashMap结构.png)\n\n\n\n\n\n```java\nhashMap的源码\n\n    static class Node<K,V> implements Map.Entry<K,V> {\n        final int hash;\n        final K key;\n        V value;\n        Node<K,V> next;\n    }\n```\n\n可以看到每个hashmap都需要四个参数，hash、key、value及next', '0', '1', '1', '1', '2022-07-13 15:50:43', '2022-07-13 15:50:43');
INSERT INTO `tb_card_answer` VALUES ('154', '158', '为了解决哈希冲突，即因为key进行hash计算的原因会导致不同key值计算出来的hashCode相同。所以index就相同。\n对于一个index会出现多个key-value。这个时候就需要使用链表来存储多个\n\n```java\nMap<String,String> map=new HashMap<>();\n\nmap.put(\"蛋炒饭\",\"我爱吃蛋炒饭\");\nmap.put(\"饭炒蛋\",\"我爱吃蛋炒饭\");\n```\n\n即比如`蛋炒饭`和`饭炒蛋`两个值计算的hash数值一样的时候。就会导致存入的index是同一个，这个时候就需要使用链表来将其存储在同一个index上', '0', '1', '1', '1', '2022-07-13 15:50:43', '2022-07-13 15:50:43');
INSERT INTO `tb_card_answer` VALUES ('155', '159', '链表查询效率较低。在数量特别大的时候查询销量是O(n)不利于。所以在链表的长度超过了8之后，链表就转换成红黑树的数据结构，红黑树的特性让它的查询效率基本平均。', '0', '1', '1', '1', '2022-07-13 15:50:43', '2022-07-13 15:50:43');
INSERT INTO `tb_card_answer` VALUES ('156', '160', '### 数组\n\n一段连续的内存空间隔开不同node的结构\n\n优点：按照下标寻址速度快\n\n缺点：插入操作复杂（需要操作当前节点的所有后续节点）需要连续的内存空间\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/fWcHB3.jpg)\n\n### 链表\n\n使用指针指向将不同的node进行连接起来\n\n优点：插入删除等操作执行方便，只需要执行前中后三个节点即可\n\n缺点：使用下标寻址需要从头节点一直遍历到尾节点，不太方便\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/0h0kHP.jpg)\n\n\n### 红黑树\n\n**特性**\n\n1. 满足基本的平衡二叉查找树\n2. 根节点是黑色的,且叶子节点是黑色的不存储数据的NIL\n3. 任何相邻的两个节点不能都是红色\n4. 从任意节点到叶子节点包含相同的黑色节点\n\n近乎平衡,所以查询、插入、删除的操作的时间复杂度都是O(log2^n)', '0', '1', '1', '1', '2022-07-13 15:50:43', '2022-07-13 15:50:43');
INSERT INTO `tb_card_answer` VALUES ('157', '161', '针对链表的插入，也就是hash值相同时，java8之前使用的头插法，即新来的值会在插入链表头部。因为开发者认为新来的值检索的可能性更大，这样可以提升查询效率。\n\njava8之后，都改成了尾插法。因为hashMap的扩容机制\n\n**为什么不是用头插法了，而使用尾插法呢？**\n\n因为在多线程的时候，如果一个线程在插入头部的时候，处理器或者其他问题中间插入了一条新的。由于头插法会改变链表中的顺序，所以会在resize扩容的时候出现环形链表的情况。这也就是为什么hashMap是线程不安全的原因\n\njdk8之后，链表使用了红黑树。红黑树将链表的时间复杂度从O(n)降到了O(logn)。如果**使用尾插**，在扩容时会保持链表元素原本的顺序，就不会出现链表成环的问题了。\n\n但是这样仍然没办法解决线程不安全的问题，毕竟存在一个线程在做put的时候还有其他在做get。还是需要使用加锁来解决这个问题。', '0', '1', '1', '1', '2022-07-13 15:50:43', '2022-07-13 15:50:43');
INSERT INTO `tb_card_answer` VALUES ('158', '162', '### put\n\nPut步骤：\n1、hash运算：进行Hash获取对应的HashCode，这个操作减少了hash冲突的可能，将所有的32位全部参与运算（高位的数据右移到低位的16位，然后与自己做异或，那就是把高位和低位的数据进行混合，以此来加大低位的随机性）<br/>\n2、是否初始化：判断数组是否为空，如果为空就进行第一次扩容（初始化类似）<br/>\n3、定位数组下标：按照key的hash值找到在数组的下标位置。判断数组上的第一个元素的key是否等于该key。如果等于就直接覆盖，如果不等于就去遍历该下标下面的链表结构<br/>\n4、更新或者新增：判断结构是红黑树还是链表，并按照对应的结构进行遍历，如果找到key一致的就进行更新，如果没找到就在尾部新增一条数据。<br/>\n5、转换红黑树：然后判断是否大于8如果大于8就转换成红黑树（对于该结构为链表的时候）\n\nput代码：\n\n```java\n    \n    public V put(K key, V value) {\n        //先进行hash操作\n        return putVal(hash(key), key, value, false, true);\n    }\n\n    final V putVal(int hash, K key, V value, boolean onlyIfAbsent,\n                   boolean evict) {\n        //tab：就是数组，p：是数组上链接的那个链表的首节点，n：是数组的长度，i：是hash取模后的下标\n        HashMap.Node<K,V>[] tab; HashMap.Node<K,V> p; int n, i;\n        //如果是空的时候就进行初始化\n        if ((tab = table) == null || (n = tab.length) == 0)\n            n = (tab = resize()).length;\n        //如果要插入的数组下标节点的链表是空的就会创建一个链表\n        if ((p = tab[i = (n - 1) & hash]) == null)\n            tab[i] = newNode(hash, key, value, null);\n        //不为空的链表就直接在链表上进行操作\n        else {\n            HashMap.Node<K,V> e; K k;\n            //如果当前的k-v与首节点哈希值和key都相等，赋值p->e，也就是插入的是同一个key就进行更新操作即可\n            if (p.hash == hash &&\n                    ((k = p.key) == key || (key != null && key.equals(k))))\n                e = p;\n            //结构为红黑树，则按照红黑树的方式进行添加\n            else if (p instanceof HashMap.TreeNode)\n                e = ((HashMap.TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);\n            //遍历整个链表来找到最后的节点进行增加元素\n            else {\n                //1。 遍历整个链表\n                for (int binCount = 0; ; ++binCount) {\n                    //2。 如果是找到了最后的节点还没跳出整个循环则将数据添加到尾节点上，即next==null\n                    if ((e = p.next) == null) {\n                        //3。 创建新的节点\n                        p.next = newNode(hash, key, value, null);\n                        //4。 如果链表的长度超过了8（上面是先遍历后+所以这个地方判断是否>=7）将链表转变成红黑树\n                        if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st\n                            //4。1将链表转变成红黑树\n                            treeifyBin(tab, hash);\n                        break;\n                    }\n                    //当前遍历到的节点e的哈希值和key与k-v的相等则退出循环，因为这里只处理新增（一般不会出现这种情况，应该在上面就已经拦截住了）\n                    if (e.hash == hash &&\n                            ((k = e.key) == key || (key != null && key.equals(k))))\n                        break;\n                    //当前节点e不为尾结点，将e->p，继续遍历\n                    p = e;\n                }\n            }\n            //处理更新操作，新值换旧值\n            if (e != null) { // existing mapping for key\n                V oldValue = e.value;\n                if (!onlyIfAbsent || oldValue == null)\n                    e.value = value;\n                afterNodeAccess(e);\n                return oldValue;\n            }\n        }\n        ++modCount;\n        //如果当前map中包含的k-v键值数超过了阈值threshold则扩容resize\n        if (++size > threshold)\n            resize();\n        afterNodeInsertion(evict);\n        return null;\n    }\n```\n\n结论：\n\n1. 如果链表长度超过8则转换成红黑树：`if (binCount >= TREEIFY_THRESHOLD - 1)  treeifyBin(tab, hash); `\n2. 如果数组元素超过阀值则进行扩容；默认值：`(int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY)`即 16*0.75=12；`if (++size > threshold) resize();`\n3. 先将key进行hash（(h = key.hashCode()) ^ (h >>> 16)）也就是先将原始值右移16位然后再和原始值进行异或处理，这样做的目的就是为了将16位数字全部参加运算（相当于这个数值是完整的32位操作得出来的）这样可以降低hash冲突的可能性。 ![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/hashMap1.png)\n\n![借用大佬的一张流程图](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/hashMap.png)\n\n### Get\n\nGet步骤：\n1、hash获取hashCode：和Put一样的Hash规则<br/>\n2、使用hashCode获取数组下标<br/>\n3、判断其衔接的结构是红黑树还是链表，按照对应的结构进行遍历来比对key值\n\n### Resize\n\n原理：\n\n两个因素\n\n+ Capcity，及hashMap的当前长度，默认16\n+ LoadFactor，负载因子，默认0.75f\n\n这个0.75即插入的数据在hashmap中占用了75%的空间之后就会进行扩容\n\n扩容方式：\n\n> 创建一个新的Entry空数组，长度是原有数组的两倍\n> 遍历原有的Entry数组，将所有的Entry重新计算hash到新数组中\n\n为什么要重新hash呢。因为长度变大了，hash值就变了\n\nhash的公式：`index=HashCode(Key)&(Length-1)`', '0', '1', '1', '1', '2022-07-13 15:50:43', '2022-07-13 15:50:43');
INSERT INTO `tb_card_answer` VALUES ('159', '163', '我们知道最基础的ConcurrentHashMap和HashMap的区别在于前者是线程安全的。那什么是线程安全，就是多个线程对一个资源或者一个数据进行访问的时候得遵循加锁原则也就是只有上一个访问完成之后才允许下一个访问\n\n<font color=\"red\">**Java7**</font>及其之前：\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/qfgARp.jpg)\n\n其中有一个Segment的概念，使用分段锁的概念（一个Segment就是一个分段锁，一个线程访问一个Segment的时候不会影响到其他的Segment的操作）\n\n\n\n\n<font color=\"red\">**Java8**</font>之后：\n\n1. 加锁范围尽量的小，抛弃了Segment的概念而采用CAS + synchronized来保证线程安全\n2. 也和HashMap的优化一样增加了红黑树来协助取数据链表的速度慢的问题\n3. 扩容\n4. 将原本的HashEntry 改为 Node。其中的val next 都用了 volatile', '0', '1', '1', '1', '2022-07-13 15:50:43', '2022-07-13 15:50:43');
INSERT INTO `tb_card_answer` VALUES ('160', '164', '### concurrentHashMap相较于hashMap\n\n1. concurrentHashMap对桶数组进行了分割分段成Segment。对每个Segment使用lock进行锁住保证线程安全\n2. concurrentHashmap不允许存储null\n3. 结构上和hashMap一样，1.8之后也是增加了红黑树\n\n### hashmap和hashTable\n\n1. hashTable将整个数组锁住，所以是线程安全的\n2. hashTable不允许存储null\n3. hashTable结构是数组+链表，没有红黑树\n\n### concurrentHashMap和hashTable的区别\n\nhashTable对整个数组上锁（锁的粒度太大导致效率更低）\n\nhashTable不支持红黑树\n\n### 总结\n\nhashTable属于即将废弃的，不建议使用\n\nhashMap是线程不安全的，如果要处理并发的业务逻辑的时候要使用concurrentHashMap。但相较的就要牺牲一部分性能问题', '0', '1', '1', '1', '2022-07-13 15:50:43', '2022-07-13 15:50:43');
INSERT INTO `tb_card_answer` VALUES ('161', '165', '为什么默认长度是16且扩容一般按照2的次幂扩容\n\n```\n源码:\n    static final int DEFAULT_INITIAL_CAPACITY = 1 << 4; // aka 16\n    默认初始化容量\n    1 << 4相当于位运算，及1*2的4次方\n```\n\n1. 这里是位运算，首先需要是2的幂次方，为了使扩容之后原有的key对应的code的index转换二进制的时候，只有最左边新增了一个1，这样可以\n2. 为什么选择16呢，因为在使用不是2的幂的数字的时候，Length-1的值是所有二进制位全为1，这种情况下，index的结果等同于HashCode后几位的值。只要输入的HashCode本身分布均匀，Hash算法的结果就是均匀的。（简而言之，其他数进行hash的时候出现同一个链表的情况较多，不均匀）\n\nhashMap的值在put的时候才会分配内存空间。如果toSize<16分配的内存空间是16。大于则按照2的幂次方往上累加\n\n不是其他小于16的2次幂是因为为了减少扩容的概率。一般不会用到超过16但是会超过8等', '0', '1', '1', '1', '2022-07-13 15:50:43', '2022-07-13 15:50:43');
INSERT INTO `tb_card_answer` VALUES ('162', '166', '使用数组和链表来存储数据，当链表长度超过8的时候就会转换成红黑树。在存储的时候首先使用hashcode进行取模获得索引值。如果发生碰撞就使用equals来判断是否与之相等\n\nHashMap采用Entry数组来存储key-value对，每一个键值对组成了一个Entry实体，Entry类实际上是一个单向的链表结构，它具有Next指针，可以连接下一个Entry实体。 只是在JDK1.8中，链表长度大于8的时候，链表会转成红黑树。为6转换成链表', '0', '1', '1', '1', '2022-07-13 15:50:43', '2022-07-13 15:50:43');
INSERT INTO `tb_card_answer` VALUES ('163', '167', '1. 首先使用`hashcode`找到对应的`bucket`\n2. 然后使用`equals`方法找到链表上对应的元素', '0', '1', '1', '1', '2022-07-13 15:50:43', '2022-07-13 15:50:43');
INSERT INTO `tb_card_answer` VALUES ('164', '168', '1. hashmap是有数组和链表组成的，但是一般为了提升效率，所以将存储的值均匀分布，也就是保证一个链表上只有一个值。当数组达到上限的时候，就需要**增大数组容量**。这个过程就是扩容\n\n2. 为了能提高查询效率，也为了能够存储更多的数据\n\n3. 一般在元素个数到达（数据大小*负载因子）的时候扩容\n\n4. 按照2^n扩容\n\n注：\n\n1. 扩容会带来的问题是resize\n2. 负载因子就是loadFactor，默认是0.75。在创建对象的时候可以传入', '0', '1', '1', '1', '2022-07-13 15:50:43', '2022-07-13 15:50:43');
INSERT INTO `tb_card_answer` VALUES ('165', '169', '产生原因，hashMap并不是线程安全的。所以在并发的情况下可能会出现多个线程同时使用同一个数据。这样就有可能会出现一个数据被修改的时候另一个线程也在修改。这就导致不一致的问题\n\n解决方案：使用HashTable或者ConCurrentHashMap这种线程安全的实现类。还有`vector`', '0', '1', '1', '1', '2022-07-13 15:50:43', '2022-07-13 15:50:43');
INSERT INTO `tb_card_answer` VALUES ('166', '170', '不会的，HashMap 的tableSizeFor方法做了处理，能保证n永远都是2次幂。\n\n```java\n/**\n * Returns a power of two size for the given target capacity.\n */\nstatic final int tableSizeFor(int cap) {\n    //cap-1后，n的二进制最右一位肯定和cap的最右一位不同，即一个为0，一个为1，例如cap=17（00010001），n=cap-1=16（00010000）\n    int n = cap - 1;\n    //n = (00010000 | 00001000) = 00011000\n    n |= n >>> 1;\n    //n = (00011000 | 00000110) = 00011110\n    n |= n >>> 2;\n    //n = (00011110 | 00000001) = 00011111\n    n |= n >>> 4;\n    //n = (00011111 | 00000000) = 00011111\n    n |= n >>> 8;\n    //n = (00011111 | 00000000) = 00011111\n    n |= n >>> 16;\n    //n = 00011111 = 31\n    //n = 31 + 1 = 32, 即最终的cap = 32 = 2 的 (n=5)次方\n    return (n < 0) ? 1 : (n >= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;\n}\n\n```', '0', '1', '1', '1', '2022-07-13 15:50:43', '2022-07-13 15:50:43');
INSERT INTO `tb_card_answer` VALUES ('167', '171', '几乎等价于hashTable，除了hashMap是**非线程安全**的以及**允许key=null**', '0', '1', '1', '1', '2022-07-13 15:50:43', '2022-07-13 15:50:43');
INSERT INTO `tb_card_answer` VALUES ('168', '172', '针对一些非线程安全的集合框架来说。如果使用**iterator**对集合遍历的同时，出现本身或其他线程对该集合的结构进行了修改。就会抛出ConcurrentModificationException异常。\n\n实际上就是系统发现自己要iterator的对象出现了无法预料的变更就会立即终止进行遍历\n\n```java\nif (size > 0 && (tab = table) != null) {\n    int mc = modCount;\n    for (int i = 0; i < tab.length; ++i) {\n        for (Node<K, V> e = tab[i]; e != null; e = e.next)\n            action.accept(e.key);\n    }\n    if (modCount != mc)\n        throw new ConcurrentModificationException();\n}\n```\n\n在遍历`table`的过程中，该线程或者其他线程如果对`hashMap`进行了修改操作,那么 `++modCount`。这个时候遍历的过程就会出现`modCount != mc`', '0', '1', '1', '1', '2022-07-13 15:50:43', '2022-07-13 15:50:43');
INSERT INTO `tb_card_answer` VALUES ('169', '173', '- `LinkedHashMap`保存了记录的插入顺序，在用`Iterator`遍历时,先取到的记录肯定是先插入的；遍历比`HashMap`慢；在需要输出的顺序和输入的顺序相同的情况下。\n- `TreeMap`实现`SortMap`接口，能够把它保存的记录根据键排序(默认按键值升序排序，也可以指定排序的比较器)；在需要按自然顺序或自定义顺序遍历键的情况下;', '0', '1', '1', '1', '2022-07-13 15:50:43', '2022-07-13 15:50:43');
INSERT INTO `tb_card_answer` VALUES ('170', '174', '使用 java.util.Collections 类的 `synchronizedMap` 方法包装`HashMap`，这样的创建的对象就相当于所有的方法上都加上了`synchorized`关键字，就可以保证线程安全\n\n```\nCollections中的synchronized方法：\npublic static <K,V> Map<K,V> synchronizedMap(Map<K,V> m) {\n    return new SynchronizedMap<>(m);\n}\n\n调用的时候：\nMap<String, String> map = Collections.synchronizedMap(new HashMap<>());\n```', '0', '1', '1', '1', '2022-07-13 15:50:43', '2022-07-13 15:50:43');
INSERT INTO `tb_card_answer` VALUES ('171', '175', '+ 从链表插入的头插法转换成尾插法。解决可能出现的死锁和循环链表的情况\n\n  > 循环链表原因：原本使用头插法在进行扩容的时候，数据转移就会从`A->B->C`变成`C->B->A`。转移期间如果出现另一个线程也插入数据发现需要扩容了也进行转移，就会出现B一直需要指向的next元素是A导致循环链表\n\n+ 从数组+链表变成了数组+链表+红黑树的结构\n\n+ JDK8中对算哈希值的哈希算法进行了简化以提高运算效率', '0', '1', '1', '1', '2022-07-13 15:50:43', '2022-07-13 15:50:43');
INSERT INTO `tb_card_answer` VALUES ('176', '180', '`==`是判断两个变量或实例是不是指向同一个内存空间（比较的是内存地址）。 equals是判断两个变量或实例所指向的内存空间的值是不是相同（比较的是内容信息）。\n\n```java\nString a=new String(\"xyz\");\nString b=new String(\"xyz\");\n```\n\n| 条件        | 结果  | 原因                                                         |\n| ----------- | ----- | ------------------------------------------------------------ |\n| a==b        | false | 因为比较的是地址，创建了两个对象，<br>引用指向的地址肯定不是一个 |\n| a.equals(b) | true  | 比较的是具体的值                                             |\n\n```java\nString a=\"xyz\"\nString b=\"xyz\"\n```\n\n| 条件        | 结果 | 原因                                                         |\n| ----------- | ---- | ------------------------------------------------------------ |\n| a==b        | true | `String a =\"xyz\"`的时候就是将\"xyz\"放入常量池中<br>`String b =\"xyz\"`的时候就是去常量池中找\"xyz\"，找到之后将地址赋给b。所以此时他俩相同 |\n| a.equals(b) | true | 比较的还是值，值相同                                         |\n\n```\nString a=\"xyz\"\nString b=a+\"\"\n```\n\n| 条件        | 结果  | 原因                                                         |\n| ----------- | ----- | ------------------------------------------------------------ |\n| a==b        | false | 两者不是一个东西，a是字符串常量；b是字符串变量。字符串常量：在编译成class的时候存放在常量池中，在经过类加载之后就存放在了方法区的运行时常量池中。而对于b是变量，是属于实例对象存放在堆空间中 |\n| a.equals(b) | true  | 比较的还是值，值相同                                         |\n\n\n', '0', '1', '1', '1', '2022-07-14 17:36:58', '2022-07-14 17:36:58');
INSERT INTO `tb_card_answer` VALUES ('177', '181', '\n### class常量池\n\n将Java编译成class文件之后，会有一个`Constant pool`的区域，专门存放编译器生成的各种字面量(Literal)和符号引用(Symbolic References)；也就是每个class文件都有一个常量池。所以并不关注于整个JVM虚拟机的内存层次\n\n### 运行时常量池\n\n是经过了类加载之后，将class常量池符号引用解析为**直接引用**，加载到了运行时常量池。所以运行时常量池也不关注于整个JVM，也是每个class文件一个。解析的过程会去查询字符串常量池，也就是我们上面所说的StringTable，以保证运行时常量池所引用的字符串与字符串常量池中是一致的。\n\n### 字符串常量池\n\n**版本更迭**\n\n| 版本         | 存放位置         | 详解                                                         |\n| ------------ | ---------------- | ------------------------------------------------------------ |\n| JDK6及其之前 | 方法区（永久代） | 此时逻辑上属于运行时常量池                                   |\n| JDK7         | 堆               | JDK7将字符串常量池移到了堆中<br>（可能认为永久代的内存太小了，也为了统一管理实例对象内存。）<br>，此时运行时常量池还在永久代中 |\n| JDK8及其之后 | 堆               | JDK8移除了永久代，使用mateSpace来实现所谓的方法区            |\n\n**底层结构**\n\n在HotSpot VM里实现是一个**StringTable**类，是默认长度为1009的hash表（jdk6 默认1009 jdk7及之后默认 60013。jdk8要求最小值是1009）。相同hash的字符串是存储在同一个hash值的外接链表中的。\n\n底层存储的结构：**JDK1.9之前使用的是`char[] value` **,**JDK1.9及其之后使用的是`byte[] value`**\n\nJDK1.9之前是char数组结构，之后是byte数组结构+编码标记\n\n修改原因：一个char=2个byte。一般一个英文字符，一个byte就能存储下。所以修改成byte[]。同时补充一个字符集约束，只针对类似英文字符/拉丁文字等。其他还是存储两个byte\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/String底层结构.drawio.png)\n\n\n\n如果hash冲突过多导致链表长度过长，就会影响效率\n\n> 静态变量\n\n属于Class类的属性信息。所以和其他的类相关元数据等信息一起存放在方法区中\n\n', '0', '1', '1', '1', '2022-07-14 17:38:08', '2022-07-14 17:38:08');
INSERT INTO `tb_card_answer` VALUES ('178', '182', '\n1. **常量和常量结果在常量池中**     在编译器进行拼接获取结果\n2. **有一个变量   结果就存放在堆**中\n3. 如果拼接结果调用了.intern()方法。就会将其放入常量池中（常量池中有就不放，没有就放）\n\n```java\n//带有变量的拼接方式：StringBuilder来进行拼接\nString a = \"a\";   //\"a\"是常量，a是变量。此时放入了常量池中\nString b = \"b\";   //\"b\"是常量，b是变量。此时放在常量池中\nString ab = \"ab\";\n\nString result = a + b;//此时相当于是new String(\"\") 创建的一个result对象，计算结果在堆中\n/*\n底层实现步骤：\n	1. StringBuilder stringBuilder=new StringBuilder;\n	2. stringBuilder.append(a);\n	3. stringBuilder.append(b);\n	4. stringBuilder.toString();     相当于String result = new String(stringBuilder);\n*/\nSystem.out.println(ab==result);//false\n//说明ab和result的地址不相同\n```\n\n```java\n//不带变量的拼接方式  使用编译期优化\nfinal String a=\"a\";\nfinal String b=\"b\";\nString ab=\"ab\";\nString result=a+b;\n\nSysrem.out.println(ab==result);//true\n```\n\n`final`修饰类、方法、基本数据类型、引用数据类型的时候，有些时候可以进行编译期优化\n\n\n\n', '0', '1', '1', '1', '2022-07-14 17:38:23', '2022-07-14 17:38:23');
INSERT INTO `tb_card_answer` VALUES ('179', '183', '两个对象，可以通过字节码指令看出来\n\n+ `new`的一个字符串对象，存放在堆空间中\n+ 还有一个\"ab\"在常量池中的对象。\n\n> new String(\"a\")+new String(\"b\")？\n>\n> \n>\n> 1. StringBuilder 涉及拼接，就需要StringBuilder\n> 2. new String(\"a\")\n> 3. ldc将\"a\"放入常量池中\n> 4. new String(\"b\")\n> 5. ldc将\"b\"放入常量池中\n> 6. 结果调用toString()方法：new String()。这里的toString()方法的调用，在字符串常量池中不会生成result\n>\n> **所以最终创建了六个对象。且不会在常量池中生成\"ab\"字符串对象**\n\n', '0', '1', '1', '1', '2022-07-14 17:38:40', '2022-07-14 17:38:40');
INSERT INTO `tb_card_answer` VALUES ('180', '184', '下面描述回收的情况。指的是某对象只具有以下具体的某种引用的时候遇到GC，该对象是否会被回收。这个回收和引用没太大关系，回收的是对象，引用会在方法退出的时候销毁。\n\n### **强引用**\n\n只要强引用的关系还存在，那么垃圾回收器就永远不会回收掉这中引用对应的对象（即使OOM）。百分之九十九\n\n```java\nObject o=new Object()；\n  \n这里的o就是强引用\n```\n\n如果想要引用被回收。可以通过`o=null`来弱化引用\n\n在方法内部有强引用，如果退出方法这个引用就不存在了。如果关于这个对象实例的所有引用都不存在了就会在下一次回收这个实例\n\n注意点：上面说了方法内的变量在方法退出之后就会销毁引用。但是如果是全局变量就不会自动销毁，就需要在不需要使用的时候赋予null来弱化引用\n\n### **软引用（内存不够才会回收）**\n\n用来描述一些还有用，但并非必须的对象。这种对象会在OOM之前的GC回收的时候被回收掉。jdk1.2之后使用`SoftReference`类创建\n\n软引用可以搭配引用队列使用`ReferenceQueue`\n\n```java\nString str=new String(\"abc\");   //此时是强引用\nSoftReference<String> softRef=new SoftReference<String>(str);    //此时的softRef是软引用\n\n\nObject obj = new Object();\nReferenceQueue rq = new ReferenceQueue<>();\nSoftReference sr = new SoftReference(obj, rq);	     // 软引用\n```\n\n当内存不足的时候就会将这个软引用队列进行依次的赋予null进行GC\n\n### **弱引用**（内存足够也会回收）\n\n描述非必须的对象，这种对象会直接被下一次的垃圾回收回收掉。也就是说无论内存是否足够都会被回收。jdk1.2之后使用`WeakReference`类创建\n\n创建使用：\n\n```java\nString str = new String(\"aaa\");\nWeakReference<String> stringWeakReference = new WeakReference<>(str);\nstr = null;\nSystem.out.println(stringWeakReference.get());\n// 需要使用的时候stringWeakReference.get()可以获取对象值。\nString newStr=stringWeakReference.get();// 可以将弱引用的值赋予给强引用\n```\n\n\n\n### **虚引用**\n\n这是一种比较特殊的存在，他的目的是**能在这个对象被收集器回收的时候收到一个系统通知**。虚引用主要用来跟踪对象被垃圾回收器回收的活动。jdk1.2之后使用`PhantomReference`类创建\n\n虚引用与软引用和弱引用的一个区别在于：虚引用必须和引用队列（ReferenceQueue）联合使用。\n\n', '0', '1', '1', '1', '2022-07-14 17:39:01', '2022-07-14 17:39:01');
INSERT INTO `tb_card_answer` VALUES ('181', '185', '\n## Comparable是什么\n\n> 简介：实现该接口的类可以进行自比较\n\n自比较：自己对象本身和参数进行比较\n\n一个接口，实现了这个接口的类对象可以根据接口的方法compareTo进行比较来获取比较结果。同时这些对象可以被增加到Collaction集合中，使用`Collections.sort(xxx)`进行排序\n\n```java\n/**\n * 实现一个业务逻辑\n * 多张优惠券。\n * 1，金额大的在前面\n * 2，金额相同时，距离有效期最近的在前面\n * 3，前两个结果相同时，id小的在前面\n */\npublic class ComparableDemo {\n    public static void main(String[] args) {\n        List<Coupon> coupons = new ArrayList<>();\n        //添加了一堆coupon。然后调用下面方法就可以对coupon进行排序。这个方法参数必须是实现了Comparable接口并按照业务实现了compareTo方法\n        Collections.sort(coupons);\n    }\n}\n\n@Data\nclass Coupon implements Comparable<Coupon> {\n    private String id;\n    private Date endTime;\n    private int price;\n\n    @Override\n    public int compareTo(Coupon o) {\n        if (o.getPrice() > this.price) {\n            return 1;\n        } else if (o.getPrice() == this.price) {\n            if (this.endTime.compareTo(o.getEndTime()) == 0) {\n                return id.compareTo(o.getId());\n            } else {\n                return this.endTime.compareTo(o.getEndTime());\n            }\n        } else {\n            return -1;\n        }\n    }\n}\n```\n\n## Comparator是什么\n\n> 简介：可以辅助比较没有实现/想重写对方实现方法Comparable接口的对象进行比较\n\n作用场景一般是\n\n+ 预比较的对象没有实现Comparable接口或者实现的compareTo逻辑不是自己想要的，而且无法使用继承来实现（final）\n\n比如我觉得String的自比较方式我不喜欢，那么就可以\n\n```java\nclass Express implements Comparator<String> {\n    public static void main(String[] args) {\n        List<String> strings = new ArrayList<>();\n        //表示不使用String自带的compareTo方法而是使用Express对象中的比较方法\n        Collections.sort(strings, new Express());\n    }\n    @Override\n    public int compare(String o1, String o2) {\n        //xxxx各种逻辑实现\n        return 0;\n    }\n}\n```\n\n## 两者的区别\n\nComparable侧重于**自比较**。也就是对象本身和一个对象的比较。compareTo方法参数是一个对象。\n\n业务场景：将优惠券排序。\n\nComparator侧重于**外比较**，就像是帮助别人进行比较一样\n\n业务场景：对名称排序（有时候想按照首字母的拼音排序，有时候想按首字母的笔画排序。）这个时候就可以创建多个类实现Comparator接口。\n\n共同点：都可以使用Collections.sort()方法来对集合对象进行排序。\n\n## 扩展TreeMap\n\n相较于HashMap，TreeMap的主要特点在于可以比较元素的大小。在进行put的时候进行排序。其原理就是在创建Map的时候传入了一个比较器。在put方法的时候会调用这个比较器进行比较\n\n```java\nMap<String, String> map2 = new TreeMap<String, String>(\n                new Comparator<String>() {\n                    public int compare(String obj1, String obj2) {\n                        //升序排序（反过来就是降序排序）\n                        return obj1.compareTo(obj2);\n                    }\n                });\n```\n\n其中实现的逻辑可以用来进行比较；下面进行put的时候就会自动按照比较结果进行排序。\n\n\n', '0', '1', '1', '1', '2022-07-14 17:49:07', '2022-07-14 17:49:07');
INSERT INTO `tb_card_answer` VALUES ('182', '186', '\n### 是什么？\n\n一个native的方法\n\n**作用**：声明一个String对象，去常量池中查询是否该对象，如果不存在就将这个字符串放入常量池中（一判断二存入）\n\n(在JDK7及其之后，同时会检查堆中是否有这个对象，如果有就直接在字符串常量池中保存堆中那个对象的地址)\n\n`String s=\"蛋炒饭\"`和`String s=new String(\"蛋炒饭\").intern()`都会将“蛋炒饭”放入常量池中。（ps：String s=new String(\"蛋炒饭\")会在堆中生成一个对象、在常量池中生成一个对象；并返回堆中生成对象的地址）\n\n### 为什么要使用intern()\n\n节省空间，垃圾回收\n\n`arr[i]=new String(String.valueof(data[i].intern()))`\n\n调用intern()的时候，会返回对应的字符串常量池中的地址信息。则数组中存储的就是字符串常量池中的地址信息。然后创建在堆中的字符串对象因为没有引用会被垃圾回收给回收掉。\n\n1. 赋值的时候使用的是字符串常量的地址信息\n2. 原本创建的堆中对象因为没有使用会被回收\n\n总结：大量使用字符串的时候，推荐增加使用intern()来大大节省内存空间。\n\n### 如何使用intern()\n\n```java\npublic class StringInternTest{\n  	public static void main(String[] args){\n      	String s=new String(\"1\");//创建了对象，s中保存的是对象在堆中的地址信息\n      	s.intern();//此时是将\"1\"放入字符串常量池中。但是已经有了，所以该操作相当于什么都没做，只是返回了字符串常量池中的地址信息。但是没有接收\n      	String s2=\"1\";//返回字符串常量池\"1\"的地址信息\n      	System.out.println(s==s2);\n      \n      	String s3=new String(\"1\")+new String(\"1\");//创建了\"1\"的对象，并在常量池中生成了\"1\"（忽视上面）。创建了\"11\"的对象，将对象在堆中的地址赋值给了s3\n      	s3.intern();//将\"11\"放到字符串常量池中\n      	//JDK6，将\"11\"当到了永久代中的字符串常量池中\n      	//JDK7～，欲要将\"11\"放到堆的字符串常量池中，但是发现堆空间中有\"11\"的对象，所以字符串常量池中记录的就是堆空间这个对象的地址信息\n      	String s4=\"11\";//获取字符串常量池中的\"11\"的地址信息\n      	System.out.println(s3==s4);//JDK6-false，JDK7-true\n    }\n}\n```\n\nJDK6：false、false\n\ns!=s2：s是通过new出来的，保存的是堆中的地址。s2是获取的\"1\"常量池中的地址\n\ns3!=s4：s3经过intern()之后会在字符串常量池中创建\"11\"\n\nJDK7/8及其之后（和6的区别就是字符串常量池从永久代到了堆中）：false 、true\n\ns!=s2：s是通过new出来的，保存的是堆中的地址。s2是获取的\"1\"常量池中的地址\n\ns3==s4：s3经过intern()之后发现堆中有这个对象，所以就直接在字符串常量池中记录的是堆中这个对象的地址信息\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/字符串常量池.drawio.png)\n\n\n', '0', '1', '1', '1', '2022-07-14 17:49:25', '2022-07-14 17:49:25');
INSERT INTO `tb_card_answer` VALUES ('183', '187', '**作用**：对象调用时，在内存中复制一个该对象，然后将新对象的引用地址返回。\n\n### String.clone()的时候是深克隆还是浅克隆\n\nclone方法是浅克隆。\n\n深克隆：在对象的复制过程中，该对象的所有属性都是新的对象属性。内存的引用类型也进行拷贝\n\n浅克隆：在复制的时候将原对象的属性引用赋给新对象。拷贝出来的对象内部的引用类型变量和原来对象内部引用类型变量是同一引用（指向同一对象）。\n\n### 使用clone—Cloneable接口\n\n1、实现Cloneable接口\n\n2、重写clone方法\n\n', '0', '1', '1', '1', '2022-07-14 18:48:17', '2022-07-14 18:48:17');
INSERT INTO `tb_card_answer` VALUES ('184', '188', '\n首先，所有的类继承自Object类。而Object类中的`equals`方法是这样的\n\n```java\npublic boolean equals(Object obj) {\n  return (this == obj);\n}\n```\n\n也就是说，对象如果不重写`equals`方法，那么比较的时候就是使用`==`进行比较引用地址是否相等。那么就会出现一种情况。两个对象的所有属性都相同，但是使用`equals`比较的时候返回时false。可能就不满足对应业务的需要了。所以如果需要比较操作就必须重写`equals`方法\n\n然后一般业务比较这个对象是否相等，肯定会使用这个对象具体的值是否相等。最终都会转换成基础类型的比较。**基础类型的比较在底层其实也是比较其hashCode是否相等。但是比较hashCode会出现一种情况，多个值可能对应的是同一个hashCode编码（hash冲突）**所以这个时候如果不重写hashCode方法的话，就会出现业务上的异常', '0', '1', '1', '1', '2022-07-14 18:48:27', '2022-07-14 18:48:27');
INSERT INTO `tb_card_answer` VALUES ('185', '189', '\n| 特点       | String                                                       | StringBuffer                                                 | StringBuilder                        |\n| ---------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------ |\n| **可变性** | String和String的实现—char底层都是使用final修饰的，<br>表示String对象一旦被创建出来就不可修改。<br>对于：`a=\"abx\"`这种操作，<br>其实是new了一个新的String对象将该对象的引用赋予给了已经创建好了的`a` | **字符序列可变的字符串**。在创建该对象之后，<br>可以使用类似于`append()`、`insert()`等方法对该对象进行操作，这个时候操作的其实就是同一个对象。<br>而进行这些操作是如何完成的呢？<br>底层其实也是调用了String（再底层还是Char），进行append的时候就是将原引用地址的String对象+一个新的引用地址对应的String对象 | 与StringBuffer类似                   |\n| **安全性** | 不安全，但是底层就是完全独立的对象，所以也不关注是否安全     | **安全**，该类方法上都增加了`synchronized`关键字             | **不安全**                           |\n| **缓冲区** | —                                                            | StringBuffer 每次获取 toString 都会直接使用缓存区的 toStringCache 值来构造一个字符串。 | 和StringBuffer一致                   |\n| **性能**   | —                                                            | 使用了线程同步，所以效率稍低                                 | 性能较高，但是不建议进行多线程的操作 |\n\n**对于三者使用的总结：** \n\n1. 操作少量的数据 = String\n2. 单线程操作字符串缓冲区下操作大量数据 = StringBuilder\n3. 多线程操作字符串缓冲区下操作大量数据 = StringBuffer\n\n### 扩容机制\n\nStringBuffer与StringBuilder基本类似，只是一个是线程安全的一个是不安全的。在扩容机制上也是一样的\n\n首先初始容量都是默认16个Char，也可在创建的时候指定大小\n\n扩容的时机是在进行append的时候去判断是否足够容纳，不够的话新建一个更大的内存空间，将数据拷贝过去。然后将引用指向新的对象空间，然后再进行append基本操作\n\n\n', '0', '1', '1', '1', '2022-07-14 18:48:41', '2022-07-15 15:39:23');
INSERT INTO `tb_card_answer` VALUES ('186', '190', '\n|      | Linked                                                       | Array                                                        |\n| ---- | ------------------------------------------------------------ | ------------------------------------------------------------ |\n| 特点 | 链表，指针相连                                               | 数组，                                                       |\n| 优点 | 增删节点效率更高，不需要连续的空间进行存储                   | 使用下标查询元素效率高                                       |\n| 缺点 | 相较于array占用存储空间更大一些<br>查询的时候需要从头指针遍历到目标节点效率会慢一点 | 增加和删除的时候需要操作当前节点<br>和后续所有的节点，所以操作会慢一些<br>需要连续的空间进行存储 |\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/Java集合框架.png)\n\n### Collection\n\n**Set**\n\n可重复的集合\n\n+ HashSet\n\n  底层结构是哈希表，hash一般都是无序的结构。使用Hash增删改查的效率会很高\n\n+ LinkedHashSet\n\n  地层结构是hash表然后使用链表维护一个顺序。所以是有序的可重复集合\n\n+ TreeSet\n\n  底层结构是红黑树，一般用作排序使用，可以重写其中的Comparator方法进行业务排序\n\n**List**\n\n不可重复集合\n\n+ ArrayList\n\n  数组实现的顺序表，相对于数组来说长度可变\n\n+ LinkedList\n\n  双向链表实现的顺序表\n\n+ Vector\n\n  与ArrayList基本一致，只是使用锁保证了线程安全\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/image-20210607174350453.png)\n\n### Map\n\n键值对的形式，key不可重复\n\n+ HashMap\n\n  数组+链表+红黑树实现。自动扩容\n\n+ LinkedHashMap\n\n  有序的HashMap\n\n  相较于HashMap只是增加了一个链表用来维护hashmap的顺序\n\n+ TreeMap\n\n  基于红黑树实现的。可以指定排序的业务机制。专门用来排序使用\n\n+ HashTable和ConcurrentHashMap\n\n  两者都是hashMap的线程安全版。区别在于前者锁的是整个数组—粒度大，后者将数组区分出来不同的区块进行单独枷锁—粒度小。然后不建议使用HashTable因为没有红黑树，当链表长度过长的时候查询效率很低\n\n', '0', '1', '1', '1', '2022-07-15 14:58:56', '2022-07-15 14:58:56');
INSERT INTO `tb_card_answer` VALUES ('187', '191', '调用start()方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。 **start()会执行线程的相应准备工作，然后自动执行run()方法的内容**，这是真正的多线程工作。 \n\n而直接执行run()方法，只会在main方法中运行该run()方法。而不是创建一个新的线程去在新线程中运行，就和我们需要的效果不一样了。\n\n**总结： 调用start方法方可启动线程并使线程进入就绪状态，而run方法只是thread的一个普通方法调用，还是在主线程里执行。**', '0', '1', '1', '1', '2022-07-18 11:47:25', '2022-07-18 11:47:25');
INSERT INTO `tb_card_answer` VALUES ('188', '192', '\n+ 底层数据结构：ArrayList底层是数组，LinkedList底层是双向链表\n+ 插入和删除操作：ArrayList插入和删除操作需要更换该节点后面所有节点的地址空间，所以较复杂。LinkedList只需要操作前后指针的指向即可，所以较简单\n+ 是否支持快速随机访问（使用下标查找）：ArrayList支持，LinkedList不支持\n+ 内存空间占用：ArrayList需要一块完整的内存空间存储（连续存储），LinkedList不需要完整的空间，但是需要存储前后指针的空间，所以总的占用空间要比ArrayList更大些', '0', '1', '1', '1', '2022-07-18 15:19:10', '2022-07-18 15:19:10');
INSERT INTO `tb_card_answer` VALUES ('189', '193', '\n### getClass\n\nnative方法，用于返回当前实例对象的Class对象。\n\n### hashCode\n\nnative方法，用来返回哈希码，主要是用在需要用到hash的地方（hashMap、equals等）\n\n### equals\n\n比较两个对象的内存地址是否相等，String中比较字符串的值是否相等\n\n### clone\n\n创建一个内存空间，将该对象拷贝过去一份然后返回新空间的内存地址\n\n### toString\n\n返回类的名字@实例的哈希码的16进制字符串\n\n### notify\n\nnative方法，Thread中唤醒一个在此对象监视器下的等待进程\n\n### notifyAll\n\nnative方法，唤醒所有该对象监视下的等待进程\n\n### wait\n\nnative方法，暂停当前线程的执行。并释放锁\n\n### finalize\n\n实例被垃圾回收的时候触发的监听操作\n\n\n\n', '0', '1', '1', '1', '2022-07-18 15:19:24', '2022-07-18 15:19:24');
INSERT INTO `tb_card_answer` VALUES ('190', '194', '\nJava程序设计语言总是采用按值调用。也就是说，在调用方法传递参数时，传递给方法的总是这个参数的一个拷贝，而不是这个参数本身\n\n规则：\n\n1、**基础数据类型不能被方法更改**。因为基础数据类型。`public void swap(int a,int b)`交换失败\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/01YEf1.jpg)\n\n2、**对象的引用作为参数可以修改这个对象**。`public void editName(String stu)`修改名称成功\n\n传递过去的引用虽然也是拷贝出来的，但是引用指向的那个实例对象却是一个唯一的\n\n', '0', '1', '1', '1', '2022-07-18 15:21:01', '2022-07-18 15:21:01');
INSERT INTO `tb_card_answer` VALUES ('191', '195', '\n1、语法上：成员变量是属于类；局部变量属于方法。\n\n2、底层结构上：成员变量是对象的一部分，而对象存在于堆内存；局部变量是属于方法的，存在于栈内存\n\n', '0', '1', '1', '1', '2022-07-18 15:21:14', '2022-07-18 15:21:14');
INSERT INTO `tb_card_answer` VALUES ('192', '196', 'finally语句一定会执行。当执行到try的return的时候，并不会直接返回，而是先执行了finally中的操作再返回（除非System.exit(0)这个时候虚拟机会直接退出）', '0', '1', '1', '1', '2022-07-18 17:21:43', '2022-07-18 17:21:43');
INSERT INTO `tb_card_answer` VALUES ('193', '197', '**Override（重写）**子类重写父类方法，\n\n+ 返回值、参数、方法名一定相同。\n+ 作用权限不能缩小（不能public ->private）。\n+ 父类final修饰的不能重写\n\n**Overload（重载）**名称相同的方法\n\n+ 参数列表不同。\n+ 可以是子父类之间也可以是自己本身的方法之间\n\n', '0', '1', '1', '1', '2022-07-18 17:21:56', '2022-07-18 17:21:56');
INSERT INTO `tb_card_answer` VALUES ('194', '198', '**是什么**\n\njava native interface，提供若干API使得Java和其他语言进行通信（C/C++）\n\n**如何使用**\n\n1、Java中编写带有native的方法接口\n\n2、javac编译该类\n\n3、使用javah生成头文件\n\n4、使用C/C++实现该方法\n\n5、生成动态连接库\n\n6、在业务中调用该接口即可完成功能', '0', '1', '1', '1', '2022-07-18 17:22:08', '2022-07-18 17:22:08');
INSERT INTO `tb_card_answer` VALUES ('195', '199', '+ NullPointException，空指针异常，一般就是一个null调用了方法或属性\n+ SQLException，SQL相关的异常，SQL包提供\n+ IndexOutOfBoundException，数据下标越界异常，使用下标获取数据时，下标超过了该数组的最大长度\n+ FileNotFoundException，文件找不到的异常\n+ IOException，进行文件IO的时候出现的异常\n+ ClassCastException，类型强制转换失败的时候出现的异常，一般出现在转换类型不是该类或该类子类的时候\n+ NumberFormatException：当试图将字符串转换成数字时失败。字符串中不只有0～9的数字', '0', '1', '1', '1', '2022-07-18 17:22:21', '2022-07-18 17:22:21');
INSERT INTO `tb_card_answer` VALUES ('196', '200', '\n都是Throwable的子类\n\n**异常类型**\n\nException表示程序出现了异常，一般是业务逻辑上的异常\n\nError一般是系统级的异常，OOM、线程死锁、虚拟机错误等\n\n**处理方式**\n\nException需要开发者自行处理异常后的业务逻辑\n\nError是代码无法进行处理的，需要人为的干预', '0', '1', '1', '1', '2022-07-18 17:22:43', '2022-07-18 17:22:43');
INSERT INTO `tb_card_answer` VALUES ('197', '201', '\n判断一个实例对象是否是类的实例\n\n当对象是类的实例或该类子类的实例的时候返回true', '0', '1', '1', '1', '2022-07-18 17:22:52', '2022-07-18 17:22:52');
INSERT INTO `tb_card_answer` VALUES ('198', '202', '\n将基础数据类型转换成其包装类，装箱\n\n包装类转换成基础数据类型，拆箱\n\n\n\n从代码上来看，手动操作就是这样的\n\n装箱：int i=10;Integer x=Integer.valueOf(i)\n\n拆箱：Integer j=new Integer(8);int m=j.intValue();\n\n> Integer.valueOf()\n>\n> ```java\n>     public static Integer valueOf(int i) {\n>         if (i >= IntegerCache.low && i <= IntegerCache.high)\n>             return IntegerCache.cache[i + (-IntegerCache.low)];\n>         return new Integer(i);\n>     }\n> ```\n>\n> 代码显示，如果i在IntegerCache的范围（-127～128）内，就直接返回IntegerCache这个缓存中的对象。如果超过就new一个新的\n>\n> 所以下面的结果就有了理由\n>\n> ```java\n> Integer i1 = 100;\n> Integer i2 = 100;\n> Integer i3 = 200;\n> Integer i4 = 200;\n> System.out.println(i1 == i2);//true\n> System.out.println(i3 == i4);//false\n> ```\n>\n> \n\n', '0', '1', '1', '1', '2022-07-18 17:23:05', '2022-07-18 17:23:05');
INSERT INTO `tb_card_answer` VALUES ('199', '203', 'OOP的全称Object Oriented Programming（面向对象的程序设计）\n\n对象(Object)：包含一定的数据结构和状态的实体。 \n\n操作(Operation)：作用于对象的行为，如访问和处理对象的状态。\n\n封装(Encapsulation)：合并对象和操作（属性和方法），只提供抽象的接口，并隐藏它们的实现规则', '0', '1', '1', '1', '2022-07-18 17:39:13', '2022-07-18 17:39:13');
INSERT INTO `tb_card_answer` VALUES ('200', '204', '不可以，String类被final修饰，不可被继承\n\n```java\npublic final class String\n    implements java.io.Serializable, Comparable<String>, CharSequence\n```\n\n', '0', '1', '1', '1', '2022-07-18 17:39:27', '2022-07-18 17:39:27');
INSERT INTO `tb_card_answer` VALUES ('201', '205', '\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/0s9ncl.jpg)\n\n|              | 原子性**A**tomicity                                          | 一致性**C**onsistency                                        | 隔离性**I**solation                       | 持久性**D**urability                                         |\n| ------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ----------------------------------------- | ------------------------------------------------------------ |\n| 解释         | 事务是最小的单位,不允许进行分割,<br>                         | 事务执行之前和执行完成之后这个<br>业务数据的状态是一致的（不会出现中间状态的数据） | 多个事务执行期间对数据的修改不会相互影响  | 事务执行完成之后,对数据的修改会保存在数据库中,不会再有回滚的操作出现 |\n| 详细解释     | 即**事务所执行的操作要么都完成要么都失败**                   | 这个一致性其实很多概念解释的都很模糊,比如<br/> 1. ~~事务开始前和结束后，数据库的完整性约束没有被破坏 。比如A向B转账，不可能A扣了钱，B却没收到。~~<br/> 2. ~~一致性是指事务必须使数据库从一个一致性状态变换到另一个一致性状态，也就是说一个事务执行之前和执行之后都必须处于一致性状态。~~<br/>其实这些说法也对,但是没有说到点子上去<br/>就拿上面转账来说,事务的一致性**其实就是多个事务看这个总钱数,无论是这个事务之前前还是执行后,都是一样的.也就是别的事务不会看到这个事务执行期间的中间状态(中间状态从A扣钱和给B加钱肯定是有个顺序的,这个时候钱的总数肯定的少了或者多了的)**<br/>那么就有的人会问了,那么这个概念不是和原子性一致了嘛<br/>原子性关注于状态,要么都成功要么都失败<br/>而一致性关注于数据,保证事务执行期间的这个数据不会超脱于业务之上 | 多个事务执行期间,对同一条数据不会产生影响 |                                                              |\n| 实现方式     | 使用undo log实现                                             | 一般由代码层面来保证                                         | 通过加锁和MVCC去实现的                    | 使用的redo log实现的                                         |\n| 实现方式详解 | 1. 在操作任何数据之前,都先将数据备份到另一个地方(这个地方称之为undo log)<br/>2. 然后就行数据修改<br/>3. 如果出现异常或者执行了rollback操作,系统就使用undo log中的数据将数据恢复到事物执行之前的状态 |                                                              |                                           | 1. 操作任何数据的时候,都将操作之后的数据进行备份到一个地方(这个地方就叫做redo log)<br/>2. 事务提交之前将redo log持久化<br/>3. 如果 系统出现崩溃则可以直接使用redo log恢复数据 |\n\n', '0', '1', '1', '1', '2022-07-20 16:22:43', '2022-07-29 14:30:47');
INSERT INTO `tb_card_answer` VALUES ('202', '206', '\n+ **脏读（Dirty read）:** (读取了后来回滚的操作)事务A读取了事务B未提交的数据修改,事务B又回滚了(读了不该读的数据)\n+ **幻读（Phantom read）:** (我以为我读取了全部)事务A读取了全部学生进行操作,结果事务B又加了学生(幻想自己读了所有)\n+ **不可重复读（Unrepeatableread）:**(我读取的数据被修改了)事务A读取的数据被事务B修改并提交了(同一个事务读的两次结果不一样了)与幻读的区别在与幻读针对新增和删除.不可重复度在于修改\n\n理解起来很好理解,就是容易记混,哈哈哈\n\n', '0', '1', '1', '1', '2022-07-20 16:22:53', '2022-07-20 16:22:53');
INSERT INTO `tb_card_answer` VALUES ('203', '207', '\n|                                                    | 读未提交                                 | 读已提交                                           | 可重复读                                                     | 串行化               |\n| -------------------------------------------------- | ---------------------------------------- | -------------------------------------------------- | ------------------------------------------------------------ | -------------------- |\n| 英文及简写                                         | Read UnCommited                          | Read Commited（RC）                                | Repeatable    Read（RR）                                     | Serializable         |\n| 概念                                               | 别的事务可以读到这个事物未提交的数据变更 | 该事务的数据变更只有在提交之后才能被别的事务读取到 | 在一个事务的过程中每次获取的数据都是一样的（即使有别的事务修改了数据并提交了） | 所有事务都是依次执行 |\n| 有的问题（重复读、脏读、幻读）                     | 重复读、脏读、幻读                       | 重复读、幻读                                       | 幻读                                                         | 所有                 |\n| 如何解决                                           |                                          | 读取的数据必须是别的事物已提交的                   |                                                              |                      |\n| 数据库默认                                         |                                          | oracle默认                                         | mysql默认                                                    |                      |\n| 备注                                               |                                          | InnoDB这里使用了MVCC解决**可重复读**问题           | MVCC解决可重复读问题。<br>使用间隙锁解决幻读的问题           |                      |\n| 生成readView的时机（MVCC作用在RR和RC上不同的原因） |                                          | 事务中每次select都会生成一个readView               | 每个事务创建一个readView                                     |                      |\n\n在启动参数中设置`transaction_isolation`即可配置事务隔离级别,查看当前隔离级别` show variables like \'transaction_isolation\'`默认隔离级别是“可重复读”\n\n\n', '0', '1', '1', '1', '2022-07-20 16:23:07', '2022-07-29 14:31:08');
INSERT INTO `tb_card_answer` VALUES ('204', '208', '\n> 大体总结一句话描述什么是MVCC：\n>\n> 为了解决事务的问题“不可重复读”，MVCC相当于有一个版本号的概念，在事务开启的时候有一个快照，后续每次进行查找的时候，都会基于“版本号”进行回退查找历史更改记录。直到获取到<=这个版本号的数据。这样在该事务中获取的数据都会是一样的，不会因为别的线程修改而导致前后两次获取/修改的数据不一致\n\n### 为什么要使用MVCC？（Why）\n\nMulti-Version Concurrency Control，多版本并发控制。\n\n由上面MDL锁可知\n\n| 未使用MVCC | 读操作 | 写操作 |\n| ---------- | ------ | ------ |\n| 读操作     | 不阻塞 | 阻塞   |\n| 写操作     | 阻塞   | 阻塞   |\n\n只要涉及写操作的都会出现阻塞的情况。MVCC的机制就可以将上述MDL锁变成如下\n\n| 使用MVCC | 读操作 | 写操作 |\n| -------- | ------ | ------ |\n| 读操作   | 不阻塞 | 不阻塞 |\n| 写操作   | 不阻塞 | 阻塞   |\n\n也就是只有多个线程进行写操作的时候才会出现阻塞的情况。由此大大提升了数据的操作性能\n\n### 什么是MVCC？（What）\n\n> 首先理解几个概念\n>\n> + **当前读**：悲观锁状态下，有些业务要求的就是最新的数据。例如像select lock in share mode(`共享锁`), select for update ; update, insert ,delete(`排他锁`)这些操作都是一种当前读。他们操作的都得是最新的数据。\n>\n> + **快照读**：在非串行化的隔离级别下`不加锁`的select操作就是快照读。（串行化时快照读退化成当前读，毕竟执行严格按照顺序来了，也就没有之前数据一说了）这也就是为什么能够解决`可重复读`的问题的根由。\n\n综上所述：为了解决提升数据库操作性能->解决有写锁在的情况下的读操作阻塞问题->快照读解决`可重复读`的问题->所以就衍生出了MVCC这种机制\n\n> 这里有几个考察点\n>\n> 1、快照读只有在隔离级别是RR和RC的时候才是快照读，在串行化的情况下会变成当前读。在读未提交的级别下没有锁的概念，无所谓什么快照读了\n>\n> 2、当前读是指增删改和加锁的读。都是针对悲观锁的行锁。快照读一般针对我们业务用的最频繁的不加锁的select操作\n\n### MVCC的实现原理\n\n> 再有几个概念理解下\n>\n> + 三个隐式字段\n>   + **`DB_TRX_ID`**\n>     6byte，最近修改(`修改/插入`)事务ID：记录创建这条记录/最后一次修改该记录的事务ID\n>   + **`DB_ROLL_PTR`**\n>     7byte，回滚指针，指向这条记录的上一个版本（存储于rollback segment里）\n>   + `DB_ROW_ID`\n>     6byte，隐含的自增ID（隐藏主键），如果数据表没有主键，InnoDB会自动以`DB_ROW_ID`产生一个聚簇索引\n>\n> + undolog（区别于redolog）\n>\n>   会在每条DML语句都会生成一条相反的DML语句（比如delete就会生成一条insert语句）这个相反的语句会用在进行数据回滚等操作。undolog中记录的就是这种语句以及其一些基本信息（事务id、版本号等）\n>\n>   + Insert undo log ：涉及insert操作，回滚使用\n>   + update undo log：涉及update、delete操作，回滚和快照读使用\n>\n> + Read View（读视图）：事务在执行快照读的那一刻生成的数据库系统的一个快照\n>\n>   作用：是为了能确定在版本链（undolog组成的链表）要选择的是哪个记录\n>\n>   其中记录的数据：\n>\n>   | 参数           | 描述                                           | 举例 |\n>   | -------------- | ---------------------------------------------- | ---- |\n>   | m_ids          | 生成该视图时所有活跃的<br>（未commit的）事务ld | 1、3 |\n>   | min_trx_id     | m_ids中最小的事务id                            | 1    |\n>   | max_trx_id     | 生成该视图时，<br>事务id分配器下个生成的id     | 4    |\n>   | creator_trx_id | 生成该视图的事务id                             | 2    |\n\n**哪些版本可以被访问到（commit的事务可以访问）**\n\n   1. 如果版本链中trx_id有=creator_trx_id，可以。就使用这条undolog（我本身进行的操作）\n   2. trx_id<min_trx_id，可以。说明trx_id肯定是提交了的id了\n   3. trx_id>max_trx_id，不可以，相当于该trx_id是创建视图之后的id，不能读取\n   4. min_trx_id<=trx_id<=max_trx_id且m_ids.isNotContains(trx_id)，可以，因为在m_ids中的事务是活跃的也就是没有commit的事务。\n\n**MVCC实现步骤**\n\n第一步：根据进行的DML操作生成undolog，使用其中的`DB_ROLL_PTR`来组成版本链\n\n第二步：当启动一个事务之后，进行了快照读，则根据上述`哪些版本可以被访问到`的条件进行生成对应的`readView`\n\n第三步：在进行CRUD的时候，根据readView可以判断出版本链中的哪条数据可以被当前事务读取到从而确定被CRUD的数据最终的状态是什么样的\n\n   ![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/u1zLsy.png)\n\n\n', '0', '1', '1', '1', '2022-07-20 16:23:28', '2022-07-29 14:31:41');
INSERT INTO `tb_card_answer` VALUES ('205', '209', '\n事务是我们经常使用的,事务的由来就是遵循**四大基本特性**.但是面对高并发的时候的并发事务往往无法满足ACID,所以导致了一系列**并发问题**,为了解决这些并发问题,所以mysql提出了四种**隔离级别**供使用者进行自己的取舍.但是往往有人既想要熊掌又想要鱼,所以提出了**MVCC**的概念\n\n线路:\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/PVpGn2.png)\n\n\n\n\n', '0', '1', '1', '1', '2022-07-29 14:27:49', '2022-07-29 14:27:49');
INSERT INTO `tb_card_answer` VALUES ('206', '210', '\n**生成ReadView的时机不同**\n\nRR是在一个事务中每次进行select操作的时候就生成一个readView。（如果两个select操作之间有提交的事务，那么第二次select的版本链就不一样了）\n\nRC是在事务创建的时候针对这个事务生成一个readView（所以每次进行select的时候都是同一个）\n\n', '0', '1', '1', '1', '2022-07-29 14:31:54', '2022-07-29 14:31:54');
INSERT INTO `tb_card_answer` VALUES ('207', '211', '\n```\n查看隔离级别\n(5.0以上版本)：select @@tx_isolation;\nselect @@global.tx_isolation;\n(8.0以上版本)：select @@transaction_isolation;\nselect @@global.transaction_isolation;\n```\n\nMysql 默认采用的 REPEATABLE_READ（读已提交）隔离级别\n\nOracle 默认采用的 READ_COMMITTED（可重复读）隔离级别\n\n', '0', '1', '1', '1', '2022-07-29 14:32:04', '2022-07-29 14:32:04');
INSERT INTO `tb_card_answer` VALUES ('208', '212', '\n```sql\nSET [SESSION | GLOBAL] TRANSACTION ISOLATION LEVEL {READ UNCOMMITTED | READ COMMITTED | REPEATABLE READ | SERIALIZABLE}\n\n例子：set global transaction isolation level READ UNCOMMITTED\n```\n\n', '0', '1', '1', '1', '2022-07-29 14:32:12', '2022-07-29 14:32:12');
INSERT INTO `tb_card_answer` VALUES ('209', '213', '\n1、通过`undo log`保证事务的**原子性**\n\n2、通过`redo log`保证事务的**持久性**\n\n3、通过锁机制、MVCC（快照读）保证事务的**隔离性**\n\n4、两阶段提交保证binlog和redolog的**一致性**，从而保证主从的一致性\n\n', '0', '1', '1', '1', '2022-07-29 14:32:20', '2022-07-29 14:32:20');
INSERT INTO `tb_card_answer` VALUES ('210', '214', '\n1、Sql标准化默认的**RR（可重复读）**使用了大量的间隙锁来完成，会大大增加死锁的概率（而Mysql不像oracle对死锁有完善的自动处理机制）\n\n2、RR级别下条件没命中索引会锁表，RC级别下只会锁行\n\n', '0', '1', '1', '1', '2022-07-29 14:32:30', '2022-07-29 14:32:30');
INSERT INTO `tb_card_answer` VALUES ('211', '215', '\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/事务隔离级别.drawio.png)\n\n\n', '0', '1', '1', '1', '2022-07-29 14:32:39', '2022-07-29 14:32:39');
INSERT INTO `tb_card_answer` VALUES ('212', '216', '\n1、事务：InnoDB支持事务；MyISAM不支持事务。\n\n2、外键：InnoDB支持外键；MyISAM不支持外键。\n\n3、索引机制：InnoDB的主键索引时聚集索引，所以使用主键查找的时候不需要回表，相应的导致主键索引内存占用较大；MyISAM主键索引是非聚集索引，索引和数据是相互分离开的，主键索引比较小，但是相对于InnoDB在进行索引查找的时候多一步回表操作。\n\n4、是否保存表行数：InnoDB不保存，因为MVCC机制导致同一时刻的多次针对表级别的查询可能结果不一样，在执行count的时候还是将所有数据取出来进行计数，但是还是做了一些优化（比如count(*)的时候无论遍历哪个索引结果都是一致的，所以可能就会优先遍历索引树小的那一列索引结构）；MyISAM单独有一个字段保存整个表的行数。\n\n5、redolog：InnoDB有redolog；MyISAM没有。\n\n6、锁：InnoDB支持表级锁、行级锁；MyISAM只支持表级锁。锁一般就是用在事务处理上\n\n7、默认索引：InnoDB默认有一个主键索引（row_id）；MyISAM没有默认索引\n\n8、全文索引：MyISAM支持全文索引；InnoDB不支持全文索引\n\n\n\n总结：InnoDB因为支持事务，所以在事务的基础上支持了`行级锁`；`MVCC`机制导致在事务中每次获取的表数量不一样，所以没有一个字段表示整个表的行数；同时主键索引是**聚集索引**，所以必然有一个主键索引，没有的话会默认生成`row_id`字段。MyISAM不支持事务所以在一些实现上就简单了，就可以提出一个字段专门表示行数，然后可以做到全文索引。\n\n\n', '0', '1', '1', '1', '2022-07-29 14:34:23', '2022-07-29 14:34:23');
INSERT INTO `tb_card_answer` VALUES ('213', '217', '\n> 学习自「极客时间—Mysql实战45讲」\n\n基于InnoDB引擎开发的一套支持**crash-safe**操作的日志系统，由四个文件组成（ib_logfile_0~3）。也就是讲DB操作和数据写入两个步骤分离开来。\n\n**实现方式**：四个文件组成下图模式，也就是读完`ib_logfile_3`之后能接着读`ib_logfile_0`。有两个指针\n\n+ `write pos`表示当前写入位置，也就是update执行的时候写入日志的位置。\n+ `check point`表示当前要擦除的位置。擦除的时候需要讲数据同步到磁盘中去。\n\n`write pos`~`check point`中间的空间是当前的`redolog`剩余的空间。当`write pos`追上`check point`的时候就需要暂停下来不继续执行sql了等待`check point`对数据进行擦除之后再继续\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/redolog.png)\n\n**存在目的**：\n\n第一、**提高效率**，将sql的操作逻辑分离开，可以提高各个模块的执行效率。如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程IO成本、查找成本都很高。\n\n第二、**保持高可用性，数据一定不会丢失**，`crash-safe`功能可以在出现系统故障或无故宕机等情况时，保存当前的sql执行情况。在恢复的时候可以继续完成sql的写入防止数据丢失。\n\n\n', '0', '1', '1', '1', '2022-07-29 14:34:33', '2022-07-29 14:34:33');
INSERT INTO `tb_card_answer` VALUES ('214', '218', '\n### 什么时候将redo log中的数据保存到磁盘对应数据上\n\n1、redo log空间不足，write pos追上check point\n\n2、事务提交的时候\n\n3、将某个脏页（用户修改了数据，但是此时还没持久化的页数据）刷到磁盘中时\n\n4、后台有个线程，大约每一秒将redo log buffer中的redo日志刷入磁盘\n\n5、正常check point到的时候\n\n### 事务提交时redo log的刷盘策略\n\n`innodb_flush_log_at_trx_commit`参数用来标示在事务提交的时候，如何处理当前事务对应的redo log日志\n\n值为0：提交时不进行写入磁盘 ，等待其他情况触发写入（上述1345的时候）\n\n值为1：提交时就进行数据写入磁盘\n\n值为2：提交时将数据写入`page cache`，具体什么时候写入磁盘由OS控制（所以这个时候如果Mysql挂了没关系，但是操作系统挂了就丢失这部分数据）\n\n', '0', '1', '1', '1', '2022-07-29 14:34:42', '2022-07-29 14:34:42');
INSERT INTO `tb_card_answer` VALUES ('215', '219', '\n针对**事务**未提交的时候出现异常情况，可以通过`undo log`撤销对数据的修改\n\n**产生**：事务开启的时候开始生成，每一条数据变更语句都会生成对应的一条反方向的数据变更语句（比如一条insert语句会生成一条delete语句）\n\n**销毁**：并不会在事务提交之后立刻销毁。而是放入**销毁队列**中，后续由另一个线程`purge thread`进行循环销毁。\n\n**存在目的**：1. 支持MVCC的实现 2. 保证WAL机制的实现。\n\n', '0', '1', '1', '1', '2022-07-29 14:34:51', '2022-07-29 14:34:51');
INSERT INTO `tb_card_answer` VALUES ('216', '220', '\n全称：`Write-Ahead Logging`，核心概念就是先写日志再写磁盘。基于`redo log`和`undo log`实现。\n\n**存在目的**：因为磁盘IO操作是非常消耗资源的，所以为了降低client的访问压力，将访问操作和实际对磁盘的操作异步开。由另一个线程对`redo log`进行读取来写入磁盘。同时依赖于`undo log `保证事务的原子性和一致性\n\n先写入 log 中，磁盘写入从「随机写变为顺序写」，降低了 client 端的延迟。并且，由于顺序写入大概率是在一个磁盘块内，这样产生的 io 次数也大大降低\n\n写入日志当数据库崩溃的时候「可以使用日志来恢复磁盘数据」\n\n', '0', '1', '1', '1', '2022-07-29 14:34:58', '2022-07-29 14:34:58');
INSERT INTO `tb_card_answer` VALUES ('217', '221', '\n基础Server层，也就是所有引擎共用的。记录了所有的DDL（alter create等）和除select之外的DML（增删改查）语句。\n\n**作用**：\n\n1、主从复制，完成数据的备份操作，以及一些基于主从复制原理对从服务器进行的一些业务性操作（cannl）\n\n2、数据恢复，完整的数据保存机制，不像redolog存在擦除的情况。\n\n\n', '0', '1', '1', '1', '2022-07-29 14:35:05', '2022-07-29 14:35:05');
INSERT INTO `tb_card_answer` VALUES ('218', '222', '\n1、redo log是基于InnoDB引擎实现的；binlog是基于Mysql的Server实现的\n\n2、redo log是覆盖写，binlog是追加写。所以binlog数据是全的\n\n3、redo log记录的是物理日志：某行的某字段=xxx；binlog记录的是逻辑日志，某行的某字段自增1\n\n', '0', '1', '1', '1', '2022-07-29 14:35:14', '2022-07-29 14:35:14');
INSERT INTO `tb_card_answer` VALUES ('219', '223', '\n1、分属类别不一样，binlog属于mysql的server层写；redo log属于InnoDB引擎写\n\n2、功能不一样，binlog主要用作数据恢复（磁盘数据丢失了，rm -rf了）主从复制（完整的逻辑日志）；redo log主要用作于意外宕机情况下内存中未写入磁盘的数据恢复（基于WAL机制导致的）\n\n', '0', '1', '1', '1', '2022-07-29 14:35:21', '2022-07-29 14:35:21');
INSERT INTO `tb_card_answer` VALUES ('220', '224', '\nInnoDB引擎在写入redo log的时候有一个prepare和commit的状态。也就是**两阶段提交**，只有在得到Mysql的Server层写入binlog成功的通知才将prepare改成commit。\n\n也就是在宕机重启之后，检查该条语句的redo log。如果是prepare且binlog中没有这条日志，就实现事务的回滚；如果是commit状态就说明binlog肯定已经写入成功了，就实现事务的提交\n\n**两阶段提交**：\n\n第一阶段：InnoDB的Prepare阶段，此时生成事务ID，写入redo log但是没有提交，处于prepare阶段\n\n第二阶段：\n\n​	1、Server层写入binlog并持久化到磁盘中\n\n​	2、InnoDB将redo log处于commit阶段\n\n', '0', '1', '1', '1', '2022-07-29 14:35:29', '2022-07-29 14:35:29');
INSERT INTO `tb_card_answer` VALUES ('221', '225', '\n当前读（加锁读）：只要加锁了就不会出现多次读取不一致的情况\n\n1、update、delete、insert操作的时候\n\n2、select ... for update、select ... lock in share mode\n\n\n\n快照读（不加锁读）：那么如何实现多次读取数据一致呢，也就是每次读取都是读取的是某一次的快照版本数据。基于MVCC实现\n\n- 读已提交级别下，每次select都会生成一个快照。\n- 可重复读级别下，开启事务之后第一个select才会生成快照，而不是事务一开始就生成快照。\n\n', '0', '1', '1', '1', '2022-07-29 14:36:42', '2022-07-29 14:36:42');
INSERT INTO `tb_card_answer` VALUES ('222', '226', '\n锁对象是:整个数据库实例\n\nFlush tables with read lock (FTWRL)-会让整个库处于只读状态\n\n使用场景: 做全库逻辑备份\n\n> **为什么要进行全局锁才能进行数据备份呢?**\n>\n> 就比如售卖,我一张表记录发货,一张表记录扣款.结果我在备份发货记录表.这个时候有人买东西了,只扣款了但是没有发货记录.这个显然是不行的\n>\n> 官方自带的逻辑备份工具是`mysqldump`。当`mysqldump`使用参数`–single-transaction`的时候，导 数据之前就会启动一个事务，来确保拿到一致性视图。而由于`MVCC`的支持，这个过程中数据是 可以正常更新的。但是这个是基于**事务**的基础上的,针对`myisam`数据引擎就不可用,那么就有可能出现有的表不是基于innoDB的数据引擎\n>\n> 当然,如果全部都是innodb的数据引擎表,那么,还是使用默认的mysqldump增加参数`–single-transaction`来进行全局逻辑备份的好\n\n', '0', '1', '1', '1', '2022-07-29 14:36:49', '2022-07-29 14:36:49');
INSERT INTO `tb_card_answer` VALUES ('223', '227', '\n1. readonly会在别的逻辑中参与使用(不同系统不一样)\n2. ftwrl可以在客户端链接断开时,自动释放锁.防止造成死锁问题\n\n', '0', '1', '1', '1', '2022-07-29 14:36:58', '2022-07-29 14:36:58');
INSERT INTO `tb_card_answer` VALUES ('224', '228', '\n\n> 表锁\n\n命令:`lock table {tableName} read/write`(write比read权限大,能write当然能read),`unlock table`解锁\n\n锁住的资源只允许当前的线程可以执行对应的操作.且当前线程只能对锁住的表进行对应的操作\n\n例如:`lock table t1 read`,则当前线程只能读不能写,其他线程不能读不能写\n\n> MDL锁\n\nMDL锁也是一个在表上操作的锁\n\n在进行表字段的增删改查的时候，上读锁，在事务结束的时候释放\n\n在进行表结构变更/索引变更的时候，上写锁，在事务结束的时候释放\n\n*只要有写锁的存在，其他的线程的操作都是会阻塞的*。也就是说在修改表结构，创建表索引的时候，会影响其他线程的一切操作。\n\n', '0', '1', '1', '1', '2022-07-29 14:37:05', '2022-07-29 14:37:05');
INSERT INTO `tb_card_answer` VALUES ('225', '229', '\n行锁是由各自的引擎实现的，例如InnoDB有行锁，MyIsam没有行锁。\n\n在进行数据变更的时候上锁，在事务结束的时候自动释放锁\n\n多个线程对同一行进行修改就会导致需要等待一个线程的锁释放(事务结束)才能进行修改\n\n> 所以,对于我们来说需要注意的点就是:在进行事务操作时,如果update没有顺序操作,那么就尽量将访问最多的那条语句最后执行(**因为上锁是顺序上的,但是释放锁是一起释放的**)\n\n| 特点     | 表锁                               | 行锁                             |\n| -------- | ---------------------------------- | -------------------------------- |\n| 加锁层面 | mysql的server层                    | 数据引擎层                       |\n| 引擎     | MyISAM、innoDB                     | InnoDB                           |\n| 特点     | 不会死锁、开销小、加锁快、锁粒度大 | 易死锁、开销大、加锁慢、锁粒度小 |\n\n### **死锁**\n\n行锁很容易造成死锁\n\n例如\n\n```\n线程A和线程B都针对id=1和id=2进行修改并开启事务\n\n线程A先修改了id=1导致id=1被线程A上锁\n\n线程B修改了id=2导致id=2被县城B上锁\n\n此时线程A要等待id=2释放锁后执行对id=2的操作\n而线程B要等待id=1释放锁后怼id=1的操作\n\n从而达到了一个循环死锁的情况\n```\n\n解决方案：\n\n1. 等待其中一个线程的链接**请求超时**时间过了，就会自动断开链接从而自动释放锁\n\n2. 发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数innodb_deadlock_detect设置为on，表示开启这个逻辑（默认开启）\n\n   问题：就是每当一条数据被锁住的时候，就要检测下别的依赖这条数据的线程是否存在被锁住的情况。对性能有很高的损耗\n\n   如果对业务清晰不会出现类似上述的死锁情况，可以将参数改为off从而提升性能\n\n\n', '0', '1', '1', '1', '2022-07-29 14:37:18', '2022-07-29 14:37:18');
INSERT INTO `tb_card_answer` VALUES ('226', '230', '\n属于行锁的一种情况\n\n针对的是事务在加锁后锁住的某一条记录信息\n\n触发情况:查询条件精准命中且命中的条件字段是唯一的 例如:`update t1 set name=\"张三\" where id=12138`\n\n作用:记录在被当前事务管理时,加上锁之后不会被其他事务获取产生“重复读”和“数据脏读”的问题\n\n', '0', '1', '1', '1', '2022-07-29 14:37:27', '2022-07-29 14:37:27');
INSERT INTO `tb_card_answer` VALUES ('227', '231', '\n**解决范围查找的时候出现范围之内数据的操作**\n\n一个很特殊的存在，是为了解决幻读问题（即，我以为我修改了全部的十条数据，其实在我修改期间又新增了第十一条数据）\n\n例如：update t1 set record=\"蛋炒饭\" where num<10;\n\n虽然num<10的只有三条数据（num=2,num=5,num=7），但是在这个期间如果新增了数据就会造成幻读的情况。所以这个时候上锁的其实是\n\n+ num=2的记录行锁\n+ num=5的记录行锁\n+ num=7的记录行锁\n+ (-无穷大,2)(2,5)(5,7)(7,10)这四个范围的间隙锁', '0', '1', '1', '1', '2022-07-29 14:37:35', '2022-07-29 14:37:35');
INSERT INTO `tb_card_answer` VALUES ('228', '232', '\n**Next-key Locks**\n\n记录锁+当前记录的前一个间隙锁锁定的区间\n\n', '0', '1', '1', '1', '2022-07-29 14:37:42', '2022-07-29 14:37:42');
INSERT INTO `tb_card_answer` VALUES ('229', '233', '\n|          | 乐观锁                                                       | 悲观锁                                                       |\n| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |\n| 原理     | 认定不会出现数据冲突，<br>所以只是维护一个版本号，<br>在业务处理结束的时候验证下版本号是否正确（即该业务处理期间有没有数据变更） | 认定业务处理期间一定会发生数数据变更冲突<br/>在业务处理之前先获取到锁<br/>要求别的线程必须等待锁的释放才能继续该逻辑 |\n| 实现方式 | 业务实现<br>1. 获取该条数据的版本号<br>2. 业务操作<br>3. 业务处理完之后判断该条数据的版本号是否变更，如果变更就进行回滚等操作 | Mysql实现，在进行select操作的时候加上`for update`关键字，在当前事务结束之后自动释放锁。<br>别的线程在事务结束之前进行该条记录的变更都会进入阻塞状态，直到锁的释放 |\n\n\n', '0', '1', '1', '1', '2022-07-29 14:37:49', '2022-07-29 14:37:49');
INSERT INTO `tb_card_answer` VALUES ('230', '234', '\n**平衡二叉树**\n\n平衡二叉树与普通的二叉树的区别在于:二叉树中任意一个节点的左右子树的高度相差不能大于 1就是平衡二叉树\n\n![Mysql使用B+树的演变来由](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/UVqJiC.jpg)\n二叉树(树结构查询快)->平衡二叉树(解决二叉树出现极端情况的问题)->B树(多节点,高度远小于红黑树等)->B+树(外接链表,增加范围查找的功能.非叶子结点只保存索引不保存数据节省空间)\n\n', '0', '1', '1', '1', '2022-07-29 14:51:11', '2022-07-29 14:51:11');
INSERT INTO `tb_card_answer` VALUES ('231', '235', '\nB+树的数据结构有如下几个特点便于mysql的搜索\n\n+ 每个节点可以有多个值(联合索引)\n+ 叶子结点包含全部的索引数据(结果查询)\n+ 叶子结点使用双向指针进行指向(便于范围查找)\n\n索引演化也是按照需求来的,具体可以看上面的索引演化过程\n\n', '0', '1', '1', '1', '2022-07-29 14:51:19', '2022-07-29 14:51:19');
INSERT INTO `tb_card_answer` VALUES ('232', '236', '\n操作系统从磁盘中取数据,是按照页取的,即一次取出一页=4Kb.mysql获取磁盘中数据也是按照页获取,只是这里的页默认是16kb\n\n页的构成:\n\n+ **用户数据区域**:按照顺序存储,形成一个长链表(长链表的查询会很慢,所以需要页目录配合使用)\n\n+ **页目录**:简化查询操作,其中存储的其实就是这个页中的索引信息(类比上面B+树图中上三层数据)\n\n+ **页头**:包含前后指针,指向其他页的内存地址,使用该指针,所有的页之间构成了一个<font color=\"red\">双向指针的长链表</font>\n\n  ![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/Mysql-页.jpg)\n\n', '0', '1', '1', '1', '2022-07-29 14:51:27', '2022-07-29 14:51:27');
INSERT INTO `tb_card_answer` VALUES ('233', '237', '\n为了更快定位到所查询数据的页是哪个,将这个双向指针的长链表使用B+树构成一个索引\n\n下面就相当于是一个<font color=\'red\'>主键索引(聚簇索引)</font>\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/5JsmaE.jpg)\n\n总结:\n\n<font color=\'red\'>B+树的非叶子结点就是所有页数据构成的一个树结构</font>\n\n<font color=\'red\'>B+树的叶子结点,存储的就是各个页的数据信息,页与页之间使用双向链表相互连接</font>\n\n所以这里的查询操作就变成了\n\n1. 首先去页构成的目录中使用二分查找到需要获取的页\n2. 从磁盘中取出页\n3. 在页目录中找到数据区域分配的组信息\n4. 在数据区域找到对应的数据\n\n', '0', '1', '1', '1', '2022-07-29 14:51:35', '2022-07-29 14:51:35');
INSERT INTO `tb_card_answer` VALUES ('234', '238', '\n规则:\n\n1. 联合索引最佳左前缀原则\n2. 针对索引的任何操作都会失效(函数、计算等)`select  * from t where left(name,4)=\'July\'\n3. 多次回表会使索引失效(覆盖索引:查询的字段是索引结果信息,不需要回表就可以获取)\n4. 索引上使用`!=`、`<>`、`is null`、`is not null`会失效\n5. 使用like且以通配符开头会失效 `select * from t where name like \'%鱼\'`会失效,但是`select * from t where name like \'香%\'`不一定会失效\n6. 索引字段是字符串,但是查询时候字符串未加‘’会失效\n7. 索引字段使用`or`会失效,建议使用`union`修改\n\n', '0', '1', '1', '1', '2022-07-29 14:51:45', '2022-07-29 14:51:45');
INSERT INTO `tb_card_answer` VALUES ('235', '239', '\n原理:构建的联合索引,虽然有多个字段,但是最先比较的都是最左边的字段,如果没有最左边的字段,那么就没办法在B+树上进行判断走向\n\n即:其实创建联合索引的时候,实际上是从左向后创建索引\n\n举例:index(a,b,c),其实会创建类似index(a),index(a,b),index(a,b,c)的索引信息.而针对只有b和c的数据查询是命中不了索引的\n\n', '0', '1', '1', '1', '2022-07-29 14:51:53', '2022-07-29 14:51:53');
INSERT INTO `tb_card_answer` VALUES ('236', '240', '\n1. 减少空间的使用,因为如果创建一个索引就备份所有页的数据是很消耗空间的\n2. 进行update操作就需要对所有索引的数据进行修改\n\n', '0', '1', '1', '1', '2022-07-29 14:51:59', '2022-07-29 14:51:59');
INSERT INTO `tb_card_answer` VALUES ('237', '241', '\n也就是使用hash算法,使用链表的方式解决hash冲突,来定位到需要查询的结果信息\n\n支持hash的引擎有MEMORY(这里需要谷歌)，其他的引擎都通过各自的方式去支持hash方法。如InnoDB有一套自适应hash算法，内部实现还是采用了BT的方式，可以理解为BT索引的索引\n\n设置hash索引是否生效:`set global innodb_adaptive_hash_index=off/on`\n\nhash索引虽然使用hash算法的查询销量较高,但是有很多弊端,所以一般不建议随意使用\n\n+ 不支持范围查找\n+ 不支持查询排序\n+ 不支持模糊查找\n\n', '0', '1', '1', '1', '2022-07-29 14:52:07', '2022-07-29 14:52:07');
INSERT INTO `tb_card_answer` VALUES ('238', '242', '\nmysql索引包括主键索引、唯一索引、普通索引、联合索引及MyISAM引擎自带的全文索引等\n\nInnoDB引擎默认索引的实现数据结构是B+树,为了更快命中所查询数据在磁盘中存储的是哪个页,从而减少查询时间及减少磁盘IO的次数\n\n创建索引使用`create [索引属性] index 索引名 on 表名(索引字段(索引条件等))`\n\n索引是一种以空间换时间的一种系统优化方式\n\n默认创建表后会生成一个主键索引,如果不指定主键索引会自动获取表中的一个唯一索引生成主键索引,如果没有会自动虚拟出一列`rowId`作为主键索引', '0', '1', '1', '1', '2022-07-29 14:52:15', '2022-07-29 14:52:15');
INSERT INTO `tb_card_answer` VALUES ('239', '243', '\n聚簇索引一般也称为主键索引,其叶子结点是整张表的数据\n\n非聚簇索引的叶子结点的值是聚簇索引的key信息.使用非聚簇查询之后还需要再进行“回表”操作\n\n\n\n', '0', '1', '1', '1', '2022-07-29 14:52:23', '2022-07-29 14:52:23');
INSERT INTO `tb_card_answer` VALUES ('240', '244', '\n+ 插入数据的时候主键会维护一个聚集索引,索引使用的是B+树实现,B+树在增加数据的时候,从中间插入的效率要远大于从末尾插入一个数据\n+ 在页中存储的数据,如果从中间插入数据,会导致相应后续的数据需要”换页“的问题\n\n', '0', '1', '1', '1', '2022-07-29 14:52:31', '2022-07-29 14:52:31');
INSERT INTO `tb_card_answer` VALUES ('241', '245', '\n+ 按照每行的数据计算所得,一行数据1kb,再加上指针目录等,基本上可以发现二层的B+树的结构就是2500万行数据差不多\n+ 如果超过2500万行数据,这个B+树的索引就需要增加至三层\n\n', '0', '1', '1', '1', '2022-07-29 14:52:40', '2022-07-29 14:52:40');
INSERT INTO `tb_card_answer` VALUES ('242', '246', '\n+ 定位到需要从磁盘中获取的页数据,全表扫描就需要多次从磁盘中获取数据\n+ 类似二分查找的方式快速定位', '0', '1', '1', '1', '2022-07-29 14:52:48', '2022-07-29 14:52:48');
INSERT INTO `tb_card_answer` VALUES ('243', '247', '\n+ 最左前缀原则\n\n+ mysql也有自己校验的优化器,即如果判定走索引的消耗比全表扫描的消耗还大,就不会进行索引数据\n\n  类似全表扫描只需要一次查询出来,但是如果使用非聚簇索引还需要进行非常多次的回表操作,这个时候就不会进行索引\n\n', '0', '1', '1', '1', '2022-07-29 14:52:56', '2022-07-29 14:52:56');
INSERT INTO `tb_card_answer` VALUES ('244', '248', '\n1. mysql会检查有没有唯一索引,如果有的话就默认定义为主键索引\n2. 如果没有唯一索引,就会创建一个隐藏的主键索引(rowId)\n\n', '0', '1', '1', '1', '2022-07-29 14:53:04', '2022-07-29 14:53:04');
INSERT INTO `tb_card_answer` VALUES ('245', '249', '\n表(a,b,c,d,e),index(b,c,d),primary(a)\n\n| 查询语句                        | 是否使用索引 | 原因                                                         |\n| ------------------------------- | ------------ | ------------------------------------------------------------ |\n| select * from t where b>1       | 否           | 因为需要进行多次回表操作                                     |\n| select a,b,c,d from t where b>1 | 是           | 查询条件在非聚簇索引上就可以获得,不需要回表                  |\n| select b from t                 | 是           | 使用索引,但是是索引扫描.<br>因为索引存储数据量要小,所以分配的页少,<br>进行数据库的IO操作次数更少 |\n| select * from t order by b,c,d  | 都可         | 不使用索引(数据量少):全表扫描,需要进行重新排序<br>数据量少时直接在内存中排序速度快,如果速度量过多内存不足<br>以构成排序操作就需要进行一些规则性的操作(比如一次比较一部分))<br>使用索引:不需要排序直接使用索引排序,需要大量的回表操作 |\n\n', '0', '1', '1', '1', '2022-07-29 14:53:12', '2022-07-29 14:53:12');
INSERT INTO `tb_card_answer` VALUES ('246', '250', '\n注意,并不是一种索引类型,而是一种索引操作\n\n即查询结果信息可以直接在索引树结束获得,不需要再进行回表来获得数据.这种查询操作就叫做覆盖索引\n\n', '0', '1', '1', '1', '2022-07-29 14:53:25', '2022-07-29 14:53:25');
INSERT INTO `tb_card_answer` VALUES ('247', '251', '\nmysql5.6新增针对查询优化的\n\n在正常进行索引查询的时候,如果还有其他查询字段,会先使用索引字段命中一部分数据,再使用其他字段进行比较.之后再进行回表操作获取整张表的数据返回\n\n举例子\n\n```\n创建了name和age的联合索引\nselect * from t1 where name=“李” and age =10\nmysql5.6之前:B+索引命中name->搜索->查找到多个结果->多个结果回表->回表结果判断age=10的返回\nmysql5.6之后:B+索引命中name->搜索->查找到多个结果->判断该次索引结果的age是否=10->符合条件的结果进行回表并返回\n```\n\n也就是说,mysql针对联合索引的查找字段,增加了在非聚簇索引获得值之后判断另一个参数是否满足条件这一步再进行回表操作\n\n\n', '0', '1', '1', '1', '2022-07-29 14:53:39', '2022-07-29 14:53:39');
INSERT INTO `tb_card_answer` VALUES ('248', '252', '\n这块有点大,后期补充,可以先了解这位作者的[杰克思勒](https://www.cnblogs.com/tufujie/p/9413852.html)讲的很详细\n\n', '0', '1', '1', '1', '2022-07-29 14:53:47', '2022-07-29 14:53:47');
INSERT INTO `tb_card_answer` VALUES ('249', '253', '\n字段过长会导致每页存放的索引字段过少而导致页数过多,会增加索引树的层级从而增加查询消耗', '0', '1', '1', '1', '2022-07-29 14:53:54', '2022-07-29 14:53:54');
INSERT INTO `tb_card_answer` VALUES ('250', '254', '\n区别: 唯一索引指定的字段保证唯一性\n\n性能分析:\n\n**查询效率**\n\n\n普通索引在索引命中第一条数据之后,还会在叶子节电继续往后面查询,直到查询到不是对应参数为止\n\n唯一索引,命中第一条之后直接返回,不会再继续查询数据\n\n但是在innoDB是按照页数据来查询,所以相邻的数据查询出来的消耗很小(不排除相邻两条数据刚好在不同页上的情况).所以上述区别微乎其微\n\n**插入和更新效率**\n\n唯一索引的特征:不允许索引字段重复\n\n当数据在内存页中时:\n\n+ 普通索引:找到位置,插入数据\n+ 唯一索引:找到位置,判断是否重复,插入数据\n\n当要插入的数据不在内存页中时:\n\n+ 普通索引:更新记录到change buffer(没设计IO操作)\n+ 唯一索引:从磁盘中获取到数据页,判断是否重复,插入这个值到磁盘中(涉及两次IO操作)\n\n<font color=\"red\">唯一索引不能使用change buffer</font>(因为需要校验是否会产生重复的数据,所以需要将磁盘中的数据查询到缓存中,这个操作就已经违背了change buffer的初衷(消耗更大),所以不会使用change buffer,而是查询出来直接更新)\n\n\n', '0', '1', '1', '1', '2022-07-29 14:54:05', '2022-07-29 14:54:05');
INSERT INTO `tb_card_answer` VALUES ('251', '255', '\n正常针对字符串创建索引,只是针对整个字符串创建索引`alter table User add index idx_index1(tel)`\n\n经常会使用手机号来查询用户信息\nselect * from User where tel =\'12345678912\';\n\n\n所以针对索引字段是字符串,我们可以类似这种创建索引的方式`alter table User add index idx_index1(tel(3))`也就是取tel的前三个字符生成一个非聚集索引\n\n但是使用前缀索引,会导致查询的时候比正常索引多执行一步操作\n`获取到索引值之后需要比对是否是整体结果信息`\n\n<font color=\"red\">使用前缀索引优点:可以减少索引在内存中占用的空间,以前是索引整个tel,现在只用索引前三个字符即可.缺点是:进行一些查询操作的时候,多了查询的操作行为,增加了查询的消耗</font>\n\n\n\n\n\n', '0', '1', '1', '1', '2022-07-29 14:54:13', '2022-07-29 14:54:13');
INSERT INTO `tb_card_answer` VALUES ('252', '256', '\nmysql进行数据更新时,如果更新的数据刚好在内存中,那么就直接更新,如果没有在内存中.就会先将更新的操作缓存在change buffer中.\n\n`change buffer`实际更新数据的情况有以下几个情况\n\n+ 下次访问该数据页的时候,会同时将`change buffer`中的数据进行执行从而使查找的数据获得更新\n+ 定时自动将数据更新到磁盘的数据页上:`merge`操作\n\n`change buffer`的职能本质就是减少磁盘的IO操作\n\n`change buffer`用的是`buffer pool`中的内存空间,可以使用设置数据库参数`innodb_change_buffer_max_size`来指定change buffer可以占用的buffer pool的百分比空间\n\n**使用场景**:写多读少的业务场景 .而对于如果业务场景中所有的更新操作后面都带着查询,那么建议关掉`change buffer`\n\n所以在生产环境中,mysql是有一个内存命中率的概念(命中率越高,说明使用的操作越高效)\n\n', '0', '1', '1', '1', '2022-07-29 14:54:21', '2022-07-29 14:54:21');
INSERT INTO `tb_card_answer` VALUES ('253', '257', '\n> 单表索引上限不超过5个\n\n+ 索引可以增加查询效率,但是会降低插入和更新的效率\n\n+ 进行查询时mysql优化器会去优化索引的查询以及选择索引等操作,过多的索引会影响Mysql优化器生成执行计划的时间,所以也会降低查询性能\n\n> innoDB表必须有主键且使用自增id\n\n主键会生成对应的聚簇索引\n\n自增id可以降低插入数据时维护索引及页数据的资源消耗\n\n> 哪些字段添加索引\n\n+ 出现在 SELECT、UPDATE、DELETE 语句的 WHERE 从句中的列\n+ 包含在 ORDER BY、GROUP BY、DISTINCT 中的字段\n+ 多个字段建议使用联合索引\n+ 多表 join 的关联列\n\n> 如何选择联合索引的顺序\n\n+ 数据区分度高的在左\n+ 字段长度小的在左\n+ 单独查询使用更频繁的放在左\n\n> 查询数据少且频繁可以选择使用覆盖索引\n\n这样减少回表的操作大大降低查询的时间\n\n> 在线上环境设置索引需要遵循以下几点\n\n1. 一般在初始化表时创建好索引信息\n2. 如果在业务运行期间必须创建索引,应该选择业务量少的时候操作.索引的创建会造成锁表的情况\n3. 绝对不能使用线下的客户端工具创建索引(例如navicat血淋淋的教训?),使用命令创建\n4. 高版本的mysql好像有异步设置索引的功能,具体未了解\n5. online关键字可以在创建索引的时候使用非独占的方式创建\n\n\n', '0', '1', '1', '1', '2022-07-29 14:54:34', '2022-07-29 14:54:34');
INSERT INTO `tb_card_answer` VALUES ('254', '258', '\n> 1、setnx保证key存在就获取不到锁，key不存在就获取得到锁\n>\n> 2、使用lua脚本保证多个rediskey操作的原子性。（上锁setnx返回1成功，0失败。不具备设置过期时间的参数需要再用pexpire设置过期时间，释放锁需要先判断是否能get到，然后再delete）\n>\n> 3、使用watchdog保证锁过期的时候监听锁是否需要**续约**（watchdog其实是一段程序，因为如果不设置过期时间（在redis服务端宕机的情况下，可能导致死锁）；如果设置过期时间（又会出现过期时间已经过了但是业务代码还没处理完成的情况）。所以需要watchdog来每隔十秒判断上锁（其实就是调用java的方法判断上锁的那个线程是否存活，如果存活就将锁的过期时间重置））\n>\n> lua脚本：\n>\n> > 上锁\n> >\n> > ```lua\n> > 	if redis.call(\'setnx\', KEYS[1], ARGV[1]) == 1 then redis.call(\'pexpire\', KEYS[1], ARGV[2]) return 1 else return 0 end\n> > ```\n> >\n> > 释放锁\n> >\n> > ```lua\n> > if redis.call(\'get\', KEYS[1]) ~= nil then return redis.call(\'del\', KEYS[1]) else return 0 end\n> > ```\n>\n> watchdog代码，使用redission工具。', '0', '1', '1', '1', '2022-12-19 13:39:38', '2022-12-19 13:39:38');
INSERT INTO `tb_card_answer` VALUES ('255', '259', '\n> 1、纯内存操作\n>\n> 2、没有线程切换的开销\n>\n> 3、IO多路复用机制提升IO效率\n>\n> 4、高效的数据结构，全局hash表（结构和hashMap基本一致，只是在链表过高的时候进行rehash）及各种高效数据结构，跳表、压缩列表、链表等', '0', '1', '1', '1', '2022-12-19 13:39:55', '2022-12-19 13:39:55');
INSERT INTO `tb_card_answer` VALUES ('256', '260', '\n主从模式下，只有一个master供请求，所以还是单机的单线程运行。cluster模式下，每个master上保存的数据都不一致，所以查找还是到具体的master上找，所以还是单机的单线程运行\n', '0', '1', '1', '1', '2022-12-19 13:40:18', '2022-12-19 13:40:18');
INSERT INTO `tb_card_answer` VALUES ('257', '261', '\n1、有过期时间最近最少使用\n\n2、全体数据最近最少使用\n\n3、有过期时间随机淘汰\n\n4、全体数据随机淘汰\n\n5、有过期时间，距离最短淘汰\n\n6、不淘汰\n\n7、有过期时间使用次数最少淘汰\n\n8、全体数据使用次数最少淘汰\n\n\n\n|            | 全体数据                                                     | 有设置过期时间的数据                                         |\n| ---------- | ------------------------------------------------------------ | ------------------------------------------------------------ |\n| LRU        | allkeys-lru：全体数据中找**最近**使用最少的数据进行淘汰（时间） | volatile-lru：有设置过期时间的数据中找使用最少的数据进行淘汰（最近的时间使用） |\n| random     | allkeys-random：全体数据中进行淘汰                           | volatile-random：设置了过期时间的数据中随机淘汰              |\n| TTL        | ——                                                           | volatile-ttl：设置了过期时间，且距离过期越近淘汰率越高       |\n| noeviction | 禁止所有数据淘汰（默认）                                     |                                                              |\n| LFU        | allkeys-lfu：全体数据使用最不频繁淘汰（次数）                | volatile-lfu：设置了使用时间的数据中最不频繁使用的淘汰（次数） |\n\n\n\n1. noeviction:**禁止驱逐数据**，当内存上限的时候，再添加数据会产生异常。从而保证数据不会丢失（默认）\n\n2. **allkeys-lru: 全体数据中找最近使用最少的数据进行淘汰**\n\n3. volatile-lru: 从**有设置过期时间的数据**中找最近**使用最少**的数据进行淘汰\n\n4. allkeys-random: **全体数据**，**随机淘汰**\n\n5. volatile-random: **设置过期时间的数据**，**随机淘汰**\n\n6. volatile-ttl: 从**设置过期时间**的数据中，**随机**找一些数据淘汰。**距离过期时间越短，淘汰优先级越高**\n\n4.0版本后增加以下两种：\n\n7. volatile-lfu：从已设置过期时间的数据集(server.db[i].expires)中挑选最不经常使用的数据淘汰\n\n8. allkeys-lfu：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的key\n\nRedis淘汰策略主要分为LRU淘汰、TTL淘汰、随机淘汰三种机制。\n\n**LRU淘汰**\n\nLRU(Least recently used，<font color=\"red\">最近最少使用</font>)算法根据数据的历史访问记录来进行淘汰数据，其核心思想是“如果数据最近被访问过，那么将来被访问的几率也更高”。\n\n在服务器配置中保存了 lru 计数器 server.lrulock，会定时(redis 定时程序 serverCorn())更新，server.lrulock 的值是根据 server.unixtime 计算出来进行排序的，然后选择最近使用时间最久的数据进行删除。另外，从 struct redisObject 中可以发现，每一个 redis 对象都会设置相应的 lru。每一次访问数据，会更新对应redisObject.lru。\n\n在Redis中，LRU算法是一个近似算法，默认情况下，Redis会随机挑选5个键，并从中选择一个最久未使用的key进行淘汰。在配置文件中，按maxmemory-samples选项进行配置，选项配置越大，消耗时间就越长，但结构也就越精准。\n\n> 手写LRU代码\n\n```\n//使用LinkedHashMap<K,V>\n//Math.cell((cacheSize/0.75)+1,0.75f,true),最后一个true表示进行顺序的排序,最近访问的放在头部,最老访问的放在最后\n//removeEldestEntry\n//return size()>CACHE_SIZE表示大于制定的缓存时,就调用删除最老的数据\npublic class LruCache<K,V> extends LinkedHashMap<K,V> {\n\n    private int size;\n\n    public LruCache(int size){\n        super(size,0.75f,false);\n        this.size = size;\n    }\n\n    @Override\n    protected boolean removeEldestEntry(Map.Entry<K, V> eldest) {\n        return super.size() > size;\n    }\n\n    public static void main(String[] args) {\n        LruCache<Object, Object> LruCache = new LruCache<>(3);\n        LruCache.put(1,1);\n        LruCache.put(2,2);\n        LruCache.put(3,3);\n        System.out.println(LruCache.keySet());\n\n        LruCache.put(4,4);\n        System.out.println(LruCache.keySet());\n        LruCache.put(3,3);\n        System.out.println(LruCache.keySet());\n        LruCache.put(3,3)\n        System.out.println(LruCache.keySet());\n        LruCache.put(5,5);\n        System.out.println(LruCache.keySet());\n    }\n}\n```\n\n**LRU和LFU的区别**：LRU侧重点在于这个Key距离当前时间多久没使用；LFU侧重点在于一段时间内使用了多少次这个Key\n\n[大佬：Redis优化--LRU和LFU区别](https://blog.csdn.net/eafun_888/article/details/104714530)\n\n**TTL淘汰**\n\n也就是按照过期时间进行淘汰。距离过期时间越短，淘汰的优先级越高。\n\n**随机淘汰**\n\n在随机淘汰的场景下获取待删除的键值对，随机找hash桶再次hash指定位置的dictEntry即可。\n\nRedis中的淘汰机制都是几近于算法实现的，主要从性能和可靠性上做平衡，所以并不是完全可靠，所以开发者们在充分了解Redis淘汰策略之后还应在平时多主动设置或更新key的expire时间，主动删除没有价值的数据，提升Redis整体性能和空间。\n\n总结六种:\n\n1. 不淘汰\n2. 随机淘汰\n3. 有过期时间的随机淘汰\n4. 使用最少\n5. 有过期时间的使用最少\n6. 过期时间越短淘汰率越高\n\nRedis实现LRU算法\n\n随机取若干个key，然后按照访问时间排序，淘汰掉最不经常使用的数据。\n\n为此，Redis给每个key额外增加了一个24bit长度的字段，用于保存最后一次被访问的时钟（Redis维护了一个全局LRU时钟lruclock:REDIS_LUR_BITS，时钟分辨率默认1秒）。\n', '0', '1', '1', '1', '2022-12-19 13:40:26', '2022-12-19 13:42:24');
INSERT INTO `tb_card_answer` VALUES ('258', '262', '\n> 1、定期删除\n>\n> 2、惰性删除\n>\n> 一般合起来使用\n', '0', '1', '1', '1', '2022-12-19 13:40:36', '2022-12-19 13:40:36');
INSERT INTO `tb_card_answer` VALUES ('259', '263', '\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/5NdFBp.png)\n\n相当于进行二分查找，数据使用双向链表链接，然后上层使用索引进行分配（空间换时间）\n', '0', '1', '1', '1', '2022-12-19 13:40:57', '2022-12-19 13:40:57');
INSERT INTO `tb_card_answer` VALUES ('260', '264', '\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/2nWrry.png)\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/MyKFQC.png)\n\n其实对应关系很简单呢，list、hash、zset在数据量小的时候都使用压缩列表。数据量大的时候才使用自己的结构（使用object encoding key查看key的具体底层实现类型）\n\n+ 简单动态字符串\n+ 双向链表，双向指针的链表结构\n+ 压缩列表：基于数组的基础上\n+ 哈希表：hash表加链表的结构\n+ 跳表：\n+ 整数数组\n\n## 压缩列表\n\n列表的基础上进行压缩。然后增加一些偏移量的字段。适合存储数据量小的数据（hash、list、zset在数据量小的时候都是用这个结构）\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/pyJupm.png)\n\nzltail：记录最后一个元素的偏移量。所以可以很快的找到第一个元素和最后一个元素。\n\n## 跳表\n\nzset结构使用的底层数据结构，双向链表的基础上加上了多层索引\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/5NdFBp.png)\n\n看起来原理和B+树类似', '0', '1', '1', '1', '2022-12-19 13:41:18', '2022-12-19 13:41:18');
INSERT INTO `tb_card_answer` VALUES ('261', '265', '\n三种模式\n\n##主从复制模式\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/UgQ6N8.jpg)\n\n主进行读写，复制给从服务器，从服务器只读。\n\n> 产生的原因\n\n```\n1. 容错性(只有一台的情况,一旦挂掉就会影像业务逻辑)\n2. 并发性(一台的并发能力必然很低,读的能力会很差)\n```\n\n> 使用主从的结果\n\n```\n1. 数据冗余\n2. 读写分离\n```\n\n> 原理\n\n```\n1. 主节点负责读/写,从节点只能进行读操作\n2. 可以一主多从\n3. 数据同步:一般初次会讲所有主节点数据同步到从节点,后续都是补发更新的数据,并且主从节点有长链接的心跳机制\n```\n\n## 哨兵模式\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/vaN493.jpg)\n\n\n\n增加哨兵保证系统的可用性，在master宕机的时候，哨兵自动选举来将一个slave提升到master的节点以供使用\n\n> 产生的原因\n\n```\n在搭建主从之后,主节点只有一个,一旦发生错误之后就没有主节点信息了\n```\n\n> 存在的作用\n\n1. 监控：检查主从服务器的正常运行，出现问题会通过API来向管理员发送监控结果\n2. 故障转移：出现问题时，哨兵机制会使用流言协议获取下线状态，并在剩下的从节点中通过<font color=\'red\'>选举算法</font>选出一个节点充当主节点\n3. IP统一：不用再直接访问master节点而是访问哨兵的IP地址\n\n> 哨兵原理\n\n1. 每个`sentinel`会以心跳机制请求master、slave进行PING命令,如果一个实例响应超过设置的时间.\n2. 当有足够数量的额sentinel确定master下线,就会认定下线,就会进行选举算法选举出新节点作为主节点\n\n当使用哨兵模式之后,就不要再直接连redis的ip和端口了,而是访问哨兵的信息,由哨兵进行<font color=\'red\'>转发</font>\n\n## **Cluster**集群模式\n\n为了防止主从复制模式数据的冗余问题。集群中一共有16384个hash槽，所有节点平分这些哈希槽。每个 key 通过 CRC16 校验后对 16384 取模来决定放置哪个槽。\n\n特点：\n\n1、互为主从，备份复制数据A作为D从，B作为A的从，C作为B的从等\n\n2、开启6379和16379两个端口，16379作为节点之间的信息通信\n\n3、无中心化结构。\n\n缺点：\n\n1、扩容需要手动导入槽\n\n2、只能使用0数据库\n\n\n\n+ 自动将数据进行分片,每个master上放一部分数据\n\n![](https://img-blog.csdnimg.cn/2018112814193762.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1MTUyMDM3,size_16,color_FFFFFF,t_70)\n\n创建每个redis的服务端进行cluster的时候,需要给每个服务端分配hash槽\n\n![](https://img-blog.csdnimg.cn/20181128141957764.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1MTUyMDM3,size_16,color_FFFFFF,t_70)\n\n每个redis的key经过一系列算法获取到对应需要访问的hash槽在哪个redis服务端上\n\n### 分布式寻址算法\n\n针对cluster集群模式..每个请求进来的时候都需要按照一定的算法来判断是去哪个节点获取数据\n\n这个算法有以下三种\n\n**hash算法**(按照key的hash值/节点数来判断去哪个取,但是如果一旦一个节点挂了,那么算法就废了)\n\n**一致性hash算法**\n\n![](https://gitee.com/shishan100/Java-Interview-Advanced/raw/master/images/consistent-hashing-algorithm.png)\n\n**hash槽算法**\n\ncluster默认拥有16384个hash槽,在注册每个节点的时候,指定这个节点管理的hash槽是哪个范围.即可后续寻址\n\n## redis sharding\n\n客户端分片，也就是在客户端访问服务端的时候（jedis）进行hash算法去判断访问哪个节点', '0', '1', '1', '1', '2022-12-19 13:41:40', '2022-12-19 13:41:40');
INSERT INTO `tb_card_answer` VALUES ('262', '266', '\n## redis的击穿(穿透)\n\n> 出现原因\n\n```\n出现大量redis中的key不存在的请求,导致创建了太多的jdbc链接从而跳过了redis的缓存机制,给数据库带来太大的压力\n```\n\n> 解决办法\n\n```\n1. 增加数据规则的验证,只有符合规则的key才进行查询,防止人为恶意的进行请求\n2. 数据库中查询为null的对应key值信息也进行缓存\n```\n\n## redis的缓存雪崩\n\n> 出现原因\n\n```\n同一时间点大量的缓存数据失效,导致透过redis直接请求数据库出现问题\n```\n\n> 解决办法\n\n```\n1. 均匀分配缓存的过期时间(业务逻辑角度)\n2. 创建多级缓存来辅助修改(springBoot+redis+Ecache)\n3. 使用分布式锁的逻辑,保证获取数据库资源有一个一定的上限,超过上限就进行等待知道锁释放\n4. redis的高可用性\n```', '0', '1', '1', '1', '2022-12-19 13:41:50', '2022-12-19 13:41:50');
INSERT INTO `tb_card_answer` VALUES ('263', '267', '[线程模型](https://www.iamshuaidi.com/2592.html)\n\n1、内部多个Socket发起链接，进行链接的时候Socket产生AE_READABLE（可读时产生）和AE_WAITABLE（可写时产生）\n\n2、发送到IO多路复用程序，IO多路复用程序管理Socket链接，将已经就绪的socket压入队列中排队等待处理\n\n3、当排队等到要处理的时候，文件事件分派器判断当前socket是什么类型，将其调用对应的处理器去处理\n\n+ 连接应答处理器：socket是要建立链接\n+ 命令请求处理：socket是要进行读操作\n+ 命令回复处理：socket是要进行写操作。\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/picgo/20230221164157.png)\n\n\n\n', '0', '1', '1', '1', '2022-12-19 13:42:05', '2023-02-27 15:29:31');
INSERT INTO `tb_card_answer` VALUES ('264', '268', '\n两者一起使用\n\n+ 定期删除(定时器定时监视所有key，如果过期就删除)\n+ 惰性删除(调用的时候检查到该key已过期,过期则删除（弥补上面定期删除可能会出现删除不及时的问题）)\n\n定期删除+惰性删除：\n\n**为什么数据过期之后,并不会直接将redis的内存删除掉(一个小时过期了百分之五十,但是内存还是那样)?**\n\n```\n两者一起使用的真实情况是：\n\nredis默认每隔一段时间就随机抽取一些设置了过期时间的key检查是否过期,如果过期了就会删除.\n注意这个地方是随机操作的\n\n并不是key到时间就被删除掉,而是查询这个key的时候,redis在懒惰的检查一下.所以查的时候并查不到这百分之五十的key值信息,但是内存还是占用着\n```\n', '0', '1', '1', '1', '2022-12-19 13:42:35', '2022-12-19 13:42:35');
INSERT INTO `tb_card_answer` VALUES ('265', '269', '\n## RDB\n\n在一段时间内有设置的数量的key更新就是横城一个快照\n\n> 原理\n\n快照的方式保存数据,每隔一段时间有固定多少key值发生变更,将数据进行快照备份一次\n\n由父进程fork开启一个子进程，使用子进程进行I/O操作将内存中的快照保存在硬盘上\n\n> 缺点\n\n耗时,耗性能\n\n> 实现\n\n在 *`redis.windows.conf`* 配置文件中默认有此下配置：\n\n```\nsave 900 1\nsave 300 10\nsave 60 10000\n```\n\nsave 开头的一行就是持久化配置，可以配置多个条件（每行配置一个条件），每个条件之间是『或』的关系，*`save 900 1`* 表示 900 秒钟（15 分钟）内至少 1 个键被更改则进行快照，*`save 300 10`* 表示 300 秒（5 分钟）内至少 10 个键被更改则进行快照。\n\nRedis 启动后会读取 RDB 快照文件，将数据从硬盘载入到内存。根据数据量大小与结构和服务器性能不同，这个时间也不同。通常将记录一千万个字符串类型键、大小为 1GB 的快照文件载入到内存中需要花费 20～30 秒钟。\n\n但是 RDB 方式实现持久化有个问题啊：一旦 Redis 异常（突然）退出，就会丢失最后一次快照以后更改的所有数据。因此在使用 RDB 方式时，需要根据实际情况，调整配置中的参数，以便将数据的遗失控制在可接受范围内。\n\n## AOF\n\n每次支持数据的修改的时候，都将修改日志保存下来\n\n> 原理\n\n将操作日志保存下来,做的是增量保存.在重启的时候执行所有操作一遍\n\n> 缺点\n\n文件体积大,恢复速度慢\n\n现在一般采用两者集合的方式来进行持久化。底层对这两种方案做了融合处理\n\n> 实现\n\n默认情况下 Redis 没有开启 AOF（append only file）方式的持久化，可以通过配置文件中的 *`appendonly`* 参数开启：\n\n```\nappendonly yes\n```\n\n开启 AOF 持久化后每执行一条会更改 Redis 中的数据的命令，Redis 就会将该命令写入硬盘中的 AOF 文件。AOF 文件的保存位置和 RDB 文件的位置相同，都是通过 *`dir`* 参数设置的，默认的文件名是 *`appendonly.aof`*，可以通过 *`appendfilename`* 参数修改：*`appendfilename appendonly.aof`*\n\n\n\n\n', '0', '1', '1', '1', '2022-12-19 13:42:48', '2022-12-19 13:42:48');
INSERT INTO `tb_card_answer` VALUES ('266', '270', '\n数据同步问题\n\n#### 全量复制\n\n1、主节点使用bgsave命令在子进程（fork）上生成RDB持久化的文件（dump.rdb）\n\n2、通过网络master将文件发送到slave上，期间网络会受到影响\n\n3、从节点删除所有数据，然后根据持久化文件重新生成从节点的数据。期间不可使用\n\n#### 部分复制\n\n1、主节点发起slaveof建立主从关系\n\n2、从节点想master节点发送paync+上一次复制主节点ID+offset\n\n​	上一次复制主节点ID保证增量的来源是一致的。offset保证增量是从哪增的\n\n3、master返回之后，就可以从master的复制缓冲区（队列）依次执行命令进行复制\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/9xA7fu.png)\n\n\n', '0', '1', '1', '1', '2022-12-19 13:42:57', '2022-12-19 13:42:57');
INSERT INTO `tb_card_answer` VALUES ('267', '271', '\n先操作缓存再操作数据库：\n\n方案一（保证数据完全一致）：**缓存修改成一个特定值禁止访问**\n\n先修改缓存（修改成一个设定值-999），然后修改数据库，然后再将缓存修改成正确的数据。\n\n客户端发现缓存的数据是-999的时候，就休眠一会再重新访问。\n\n方案二：**延时双删**。\n\n先删除缓存，写入数据库，再休眠一段时间，再删除缓存。\n\n\n\n先操作数据库再操作缓存：（缓存写失败的情况）\n\n方案一：给缓存设置过期时间\n\n方案二：引入MQ保证原子操作（mq**重试机制**）\n\n方案三：**版本号**。数据库和redis中都存一个版本号。后台有一个程序不断的扫描这些关键数据的key，判断版本号是否一致，不一致就替换成版本最高的那个\n', '0', '1', '1', '1', '2022-12-19 13:43:07', '2022-12-19 13:43:07');
INSERT INTO `tb_card_answer` VALUES ('268', '272', '\n#### 1.String\n\n> **常用命令:**  set,get,decr,incr,mget 等。\n\nString数据结构是简单的key-value类型，value其实不仅可以是String，也可以是数字。 \n常规key-value缓存应用； \n\n#### 2.Hash\n\n> **常用命令：** hget,hset,hgetall 等。\n\nhash 是一个 string 类型的 field 和 value 的映射表，hash 特别适合用于存储对象，后续操作的时候，你可以直接仅仅修改这个对象中的某个字段的值。 比如我们可以 hash 数据结构来存储用户信息，商品信息等等。比如下面我就用 hash 类型：\n\n```\nkey=JavaUser293847\nvalue={\n  “id”: 1,\n  “name”: “SnailClimb”,\n  “age”: 22,\n  “location”: “Wuhan, Hubei”\n}\n\n```\n\n\n#### 3.List\n\n> **常用命令:** lpush,rpush,lpop,rpop,lrange等\n\nlist 就是链表，Redis list 的应用场景非常多，也是Redis最重要的数据结构之一，比如微博的关注列表，粉丝列表，消息列表等功能都可以用Redis的 list 结构来实现。\n\nRedis list 的实现为一个双向链表，即可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销。\n\n另外可以通过 lrange 命令，就是从某个元素开始读取多少个元素，可以基于 list 实现分页查询，这个很棒的一个功能，基于 redis 实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西（一页一页的往下走），性能高。\n\n#### 4.Set\n\n> **常用命令：**\n> sadd,spop,smembers,sunion 等\n\nset 对外提供的功能与list类似是一个列表的功能，特殊之处在于 set 是可以自动排重的（**不能重复**）。\n\n当你需要存储一个列表数据，又不希望出现重复数据时，set是一个很好的选择，并且set提供了判断某个成员是否在一个set集合内的重要接口，这个也是list所不能提供的。可以基于 set 轻易实现交集、并集、差集的操作。\n\n比如：在微博应用中，可以将一个用户所有的关注人存在一个集合中，将其所有粉丝存在一个集合。Redis可以非常方便的实现如共同关注、共同粉丝、共同喜好等功能。这个过程也就是求交集的过程，具体命令如下：\n\n```\nsinterstore key1 key2 key3     将交集存在key1内\n```\n\n#### 5.Sorted Set\n\n> **常用命令：** zadd,zrange,zrem,zcard等\n\n\n和set相比，sorted set增加了一个权重参数score，使得集合中的元素能够按score进行有序排列。\n\n**举例：** 在直播系统中，实时排行信息包含直播间在线用户列表，各种礼物排行榜，弹幕消息（可以理解为按消息维度的消息排行榜）等信息，适合使用 Redis 中的 Sorted Set 结构进行存储。\n\n队列模式:\n\nlist作为队列,rpush生产消息,lpop消费消息\n\n#### 6. Geospatial,地理位置类型\n\n#### 7. bitmap,位图类型(key:value(1,2))\n\n#### 8. Hyperloglog,数学上的集合类型\n\n# redis的事务\n\n通过`MULTI`、`EXEC`、`WATCH`等命令实现事务。redis提供一种将请求打包执行，期间不会切换到别的client去执行命令。也就相当于事务开启期间就不会出现其他的读写操作。（mysql的串行化事务隔离级别）\n\nredis支持事务，但是整体redis集群不支持事务\n\n在 Redis 中，事务总是具有原子性（Atomicity）、一致性（Consistency）和隔离性（Isolation），并且当 Redis 运行在某种特定的持久化模式下时，事务也具有持久性（Durability）。\n\n## 1. 事务的一般执行流程\n\n```\n1. 开启事务`MULTI`\n2. 执行操作，也就是执行你需要进行的操作set等\n3. 提交事务`EXEC`，会执行一并所有的操作一起提交\n```\n\n##  2. 使用SpringBoot+redis执行事务\n\n```java\n//1. 创建对应执行的RedisTemplate对象\n@Autowired\nStringRedisTemplate stringRedisTemplate\n//2. 开启事务权限\nstringRedisTemplate.setEnableTransationSupport(true);\n//3. 开启事务\nstringRedisTemplate.multi();\n//4. 回滚\nstringRedisTemplate.discard();\n//5. 提交\nstringRedisTemplate.exec();\n```\n\n如果开启事务，所有的命令只有在执行了exec。才会往redis中插入\n', '0', '1', '1', '1', '2022-12-19 13:43:25', '2022-12-19 13:43:25');
INSERT INTO `tb_card_answer` VALUES ('269', '273', '使用的淘汰策略可以是LRU策略，可以实现淘汰最近最少使用的数据淘汰掉', '0', '1', '1', '1', '2022-12-19 13:44:01', '2022-12-19 13:44:01');
INSERT INTO `tb_card_answer` VALUES ('270', '274', '不会，每条消息都会持久化到CommitLog中，每个Consumer连接到Broker后会维持消费进度信息，当有消息消费后只是当前Consumer的消费进度（CommitLog的offset）更新了。\n\n追问：那么消息会堆积吗？什么时候清理过期消息？\n默认72小时后会删除不再使用的CommitLog文件\n\n检查这个文件最后访问时间\n判断是否大于过期时间\n指定时间删除，默认凌晨4点', '0', '1', '1', '1', '2022-12-19 17:02:39', '2022-12-19 17:02:39');
INSERT INTO `tb_card_answer` VALUES ('271', '275', '三种模式，两个保障：单机模式、master集群模式、master-slave集群模式；同步刷盘，同步复制\n\n针对broker的开源版本\n\n多master-slave集群：多master是为了分摊每个topic的Queue，从而做到负载均衡。slave用作备份master的数据，保障消息不丢失，但是不能防止单点故障（master挂掉之后，该master-slave只支持从slave中取数据，消息发送不到该组合中。slave不会晋升master去处理消息）。\n\n**在5.0的版本之后，新增了主从切换的机制。基于Dleger Controller监听心跳机制来进行主从的选举。**', '0', '1', '1', '1', '2022-12-19 18:01:17', '2023-02-27 15:28:32');
INSERT INTO `tb_card_answer` VALUES ('272', '276', '\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/7H24ZO.png)\n\n生产者消息不丢失：发送**事务消息**（消息发送之前，生产者会先发送half进行broker的可用性确认），失败重试机制\n\n写入磁盘：异步写入改成同步写入，生产者发送消息之后只有得到broker的ack，且broker刷盘机制改成同步刷盘，消息复制改成同步复制。保证只有写入磁盘才返回消息发送成功\n\n磁盘消息：使用磁盘RAID阵列保证磁盘信息的多级备份，保证不丢失\n\n消费者消费消息：拉取消息，只有消息处理结束之后才返回成功。\n\n> Producer发送消息阶段\n>\n> 1通过采用同步发送消息到broker，等待broker接收到消息过后返回的一个确认消息，虽然效率低，但是时丢失几率最小的方式，异步1和单向消息发送丢失的几率比同步消息丢失的几率大。\n>\n> 2发送消息失败或超时则进行重试。\n>\n> 3broker提供多master模式【即使某台broker宕机了，换一台broker进行投递，保持高可用】\n>\n> ===》采用同步消息和失败重试和多master模式\n>\n> Broker处理消息阶段\n>\n> 手段四：提供同步刷盘的策略【等待刷盘成功才会返回producer成功】\n>\n> 当数据写入到内存中之后立刻刷盘(同步的将内存中的数据持久化到磁盘上)，\n>\n> 手段五：提供主从模式，同时主从支持同步双写\n>\n> 主从broker都同步刷盘成功，才返回producer一个确认消息。\n>\n> ===》采用同步刷盘+broker主从模式，支持同步双写\n>\n> Consumer消费消息阶段\n>\n> consumer默认提供的是At least Once（**Consumer先pull【主动拉取Broker中的信息】 消息到本地，消费完成后，才向服务器返回ack（消费成功的消息--acknowledge）**）机制\n>\n> 手段6 broker队列中的消息消费成功，才返回一个确认消息给broker。\n>\n> 手段7 当消息消费失败了，进行消费消息重试机制（保证幂等就行了。）\n>\n> ===》采用先消费，在返回一个确认消息+消息重试。\n\n事务消息：\n\n1、生产者发送half消息，当broker返回half消息的响应成功之后，生产者开始执行本地事务的代码\n\n2、当生产者本地代码执行完成之后，发送给broker/broker回查当前事务是否commit。如果broker发现commit了，就将消息释放出去供消费者消费\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/uigeYB.jpg)\n\n', '0', '1', '1', '1', '2022-12-19 18:01:26', '2022-12-19 18:01:26');
INSERT INTO `tb_card_answer` VALUES ('273', '277', '\n保证发送的消息都进入同一个MessageQueue：可以在发送者发送消息时指定一个MessageSelector对象，让这个对象来决定消息发入哪一个MessageQueue。\n\n实现方式\n\n1、接口上增加注解，选定顺序消费\n\n2、实现MessageQueueSelector接口，重写里面的选择算法。保证顺序消费\n', '0', '1', '1', '1', '2022-12-19 18:01:34', '2022-12-19 18:01:34');
INSERT INTO `tb_card_answer` VALUES ('274', '278', '\n如果Topic下的MessageQueue配置得是足够多的，那每个Consumer实际上会分配多个MessageQueue来进行消费。这个时候，就可以简单的通过增加Consumer的服务节点数量来加快消息的消费，等积压消息消费完了，再恢复成正常情况。\n\n如果messageQueue数量与consumer一致还是积压，可以\n\n', '0', '1', '1', '1', '2022-12-19 18:01:41', '2022-12-19 18:01:41');
INSERT INTO `tb_card_answer` VALUES ('275', '279', '\n**集群消费**\n一条消息只会被同Group中的一个Consumer消费\n多个Group同时消费一个Topic时，每个Group都会有一个Consumer消费到数据\n\n![输入图片说明](https://bright-boy.gitee.io/technical-notes/rocketmq/images/QQ%E6%88%AA%E5%9B%BE20220208141053.png)\n\n**广播消费**\n\n一条消息会被group下所有消费者消费一遍\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/mv3P6V.jpg)\n', '0', '1', '1', '1', '2022-12-19 18:01:55', '2022-12-19 18:01:55');
INSERT INTO `tb_card_answer` VALUES ('276', '280', '\npull就是客户端去broker获取消息。不断的请求，请求不到就结束过一段时间再请求。\n\n**push**就是主动推送给消费者消息，本质是对pull的包装，建立长链接（长轮询），服务端一旦有数据就会将数据发送给客户端。\n\n长轮询的方式：客户端请求broker获取消息，如果broker没有消息就挂起这个链接并不返回，直到客户端超时或者有消息才返回。\n\n优缺点：\n\n> push\n\n最常用的模式\n\n优点在于，数据的同步及时。\n\n缺点在于服务端不知道客户端的承受能力是多少容易出现数据的堆积在客户端\n\n> pull\n\n优点在于对客户端的压力不大，客户端能承受多少就拉取多少\n\n缺点在于无法评估拉取的时间间隔。\n\n', '0', '1', '1', '1', '2022-12-19 18:02:03', '2022-12-19 18:02:03');
INSERT INTO `tb_card_answer` VALUES ('277', '281', '\nRocketMq采用文件系统进行消息的存储，相对于ActiveMq采用关系型数据库进行存储的方式就更直接，性能更高了\n\nRocketMq与Kafka在写消息与发送消息上，继续沿用了Kafka的这两个方面：顺序写和零拷贝\n\n1）顺序写\n我们知道，操作系统每次从磁盘读写数据的时候，都需要找到数据在磁盘上的地址，再进行读写。而如果是机械硬盘，寻址需要的时间往往会比较长而一般来说，如果把数据存储在内存上面，少了寻址的过程，性能会好很多；\n但Kafka 的数据存储在磁盘上面，依然性能很好，这是为什么呢？\n这是因为，Kafka采用的是顺序写，直接追加数据到末尾。实际上，磁盘顺序写的性能极高，在磁盘个数一定，转数一定的情况下，基本和内存速度一致\n因此，磁盘的顺序写这一机制，极大地保证了Kafka本身的性能\n2）零拷贝\n比如：读取文件，再用socket发送出去这一过程\n\nbuffer = File.read\nSocket.send(buffer)\n\n传统方式实现：\n先读取、再发送，实际会经过以下四次复制\n1、将磁盘文件，读取到操作系统内核缓冲区Read Buffer\n2、将内核缓冲区的数据，复制到应用程序缓冲区Application Buffer\n3、将应用程序缓冲区Application Buffer中的数据，复制到socket网络发送缓冲区\n4、将Socket buffer的数据，复制到网卡，由网卡进行网络传输\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/W0SNOq.jpg)\n\n传统方式，读取磁盘文件并进行网络发送，经过的四次数据copy是非常繁琐的\n重新思考传统IO方式，会注意到在读取磁盘文件后，不需要做其他处理，直接用网络发送出去的这种场景下，第二次和第三次数据的复制过程，不仅没有任何帮助，反而带来了巨大的开销。那么这里使用了零拷贝，也就是说，**直接由内核缓冲区Read Buffer将数据复制到网卡**，**省去第二步和第三步的复制**。\n\n那么采用零拷贝的方式发送消息，必定会大大减少读取的开销，使得RocketMq读取消息的性能有一个质的提升\n\n此外，还需要再提一点，零拷贝技术采用了MappedByteBuffer内存映射技术，采用这种技术有一些限制，其中有一条就是传输的文件不能超过2G，这也就是为什么RocketMq的存储消息的文件CommitLog的大小规定为1G的原因\n\n小结：RocketMq采用文件系统存储消息，并采用顺序写写入消息，使用零拷贝发送消息，极大得保证了RocketMq的性能', '0', '1', '1', '1', '2022-12-19 18:02:12', '2022-12-19 18:02:12');
INSERT INTO `tb_card_answer` VALUES ('278', '282', '\n如图所示，消息生产者发送消息到broker，都是会按照顺序存储在CommitLog文件中，每个commitLog文件的大小为1G\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/B3iJVW.jpg)\n\nCommitLog-存储所有的消息元数据，包括Topic、QueueId以及message\n\nCosumerQueue-消费逻辑队列：存储消息在CommitLog的offset\n\nIndexFile-索引文件：存储消息的key和时间戳等信息，使得RocketMq可以采用key和时间区间来查询消息\n\n也就是说，rocketMq将消息均存储在CommitLog中，并分别提供了CosumerQueue和IndexFile两个索引，来快速检索消息\n', '0', '1', '1', '1', '2022-12-19 18:02:21', '2022-12-19 18:02:21');
INSERT INTO `tb_card_answer` VALUES ('279', '283', '\nRocketMq采用文件系统存储消息，采用顺序写的方式写入消息，使用零拷贝发送消息，这三者的结合极大地保证了RocketMq的性能\n', '0', '1', '1', '1', '2022-12-19 18:02:38', '2022-12-19 18:02:38');
INSERT INTO `tb_card_answer` VALUES ('280', '284', '\n> 原因\n\n+ 消息重发\n+ 分布式消息重复股消费\n\n```sequence\ntitle: kafka消息重复消费\nparticipant 生产者 as producer\nparticipant kafka\nparticipant zookeeper as zk\nparticipant 消费者 as consumer\n\n\nproducer -> kafka: 1. 发送每台消息都会带着一个offset(坐标,顺序)\n\nkafka-> consumer: 2. 消费者消费消息是按照顺序消费\nconsumer-> zk: 3. 消费者消费了消息之后会返回提交offset\nzk-> kafka: 4. 同步\n\n```\n\n消费者并不是消费一条数据就提交offset,而是定时定期去提交\n\n如果在已消费、未提交前出现了问题,就会出现kafka认为这条数据并没有消费的情况,下一次消费的时候kafka会将这个offset对应的消息再发给消费者\n\n\n\n> 解决方案\n\n幂等:\n\n业务逻辑进行处理\n\nredis锁进行处理\n\n关键业务数据的mysql写入唯一性约束\n\n', '0', '1', '1', '1', '2022-12-19 18:02:51', '2022-12-19 18:02:51');
INSERT INTO `tb_card_answer` VALUES ('281', '285', '\n> 原因\n\nrabbitMQ,一个队列,多个消费者,消费消息可能会因为性能不一致等原因导致顺序与生产顺序不一致\n\nkafka,能内部保障写入一个partition的数据是顺序的(在写入的时候指定一个key,这样可以保障所有同样key的数据被同一个partition消费)。kafka不顺序消费的情况是消费者内部的多线程处理\n\nrocketmq，能保证同一个Queue是顺序消费的。所以实现顺序消费的基础就是将消息都发送到该topic的一个Queue中。\n\n> 解决方案\n\n使用针对订单的订单号hash的方式进行运算,保证同一条订单的信息走到同一个MessageQueue中\n\nkafka\n\n+ 使用相同的key,保证进入同一个partition中\n+ 出队之后放入内存队列中,保证写入内存队列顺序写入,这样就会进入同一个线程处理\n\n针对重要的数据,也可以增加redis锁机制来保证一定的消费顺序消费的情况\n\n\n\n如果这种顺序消息消费失败了,不能使用`CONSUMER_LATER`来将消费发送会broker进行重试消费,而是将整个queue中的信息都回馈回去进行重试.即**不能针对消息重试,而需要针对queue进行重试**\n\n**终极：针对所有mq都适用的解决方案:针对不同的业务信息,创建多个队列.顺序的队列进行使用消息,也就是一个消费者是另一个数据的生产者**\n\n', '0', '1', '1', '1', '2022-12-19 18:02:58', '2022-12-19 18:02:58');
INSERT INTO `tb_card_answer` VALUES ('282', '286', '\n1. 生产者弄丢数据<br>\n   ribbitMQ使用transaction和confirm模式来保证生产者不会丢消息<br>\n\n   tacnsaction机制：发送消息前\"channel.txSelect()\"开启事务。消息发送没出现异常\"channel.txCommit()\"提交事务。出现任何异常\"channel.txRollback()\"回滚事务<br>\n   缺点：吞吐量下降\n\n   confirm机制：所有被生产者生产的消息都会被**加上唯一ID**，如果消息被正确消费了ribbitMQ就发送一个ACK给生产者。如果消息没有正确消费ribbitMQ就返还一个NACK给生产者\n\n2. 消息队列丢失数据\n   使用消息持久化磁盘的方法<br>\n\n   1. 开启持久化磁盘的方法\n      1. durable设置成true\n      2. 发送消息的时候将deliveryMode=2\n   2. 设置之后，和confirm一起使用，会在本地持久化存储生产者生产的消息。并在意外岱机之后重启恢复数据\n\n3. 消费者丢数据\n   一般是采用了自动确认消息模式。这种模式下，消费者会自动确认收到的消息。然后ribbitMQ会删除这个消息。如果这个时候消费者出现异常没有完整处理业务逻辑，就会出现数据丢失<br>\n   解决方法：手动确认消息即可\n   <br>\n   关闭rabbitMQ提供的自动ACK消息确认机制，改为消费者处理完消息之后,\n    手动ACK(基于tcp的ack事务包)\n\n> ###### rabbitmq消息丢失\n>\n> 1. 创建queue指定durable,也就是持久化的\n> 2. 生产消息的时候也指定持久化\n>\n> 在还没有将消息送入mq的时候,如果宕机会丢失\n', '0', '1', '1', '1', '2022-12-19 18:03:06', '2022-12-19 18:03:06');
INSERT INTO `tb_card_answer` VALUES ('283', '287', '实现方式：\n\n1、代码层面实现：当判断是个延时消息的时候，发送到的MQ是对应的代理MQ。代理MQ消费端消费消息之后，将其放入定时任务中，由定时任务触发执行\n\n2、时间轮和deley-file：将消息写入delayfile中或者直接写入时间轮（按照到期时间区分）。最终都是在时间轮中通过每秒进行判断消息是否到期从而写到commitlog中。只要写入到commitlog就会被消费\n\n![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/picgo/20230221094046.png)\n\n3、延时队列：将消息发送到对应时间阶段的延时队列中。这个时候有一个**Timer定时器**回去使用对应频次轮训延时队列，到期了就将消息发送到指定的队列中（写入commitlog），即可完成消费', '0', '1', '1', '1', '2022-12-19 18:03:15', '2023-02-27 15:28:12');
INSERT INTO `tb_card_answer` VALUES ('284', '288', 'commitlog默认过期时间为三天，按照文件来清理', '0', '1', '1', '1', '2022-12-19 18:03:27', '2022-12-19 18:03:27');
INSERT INTO `tb_card_answer` VALUES ('285', '289', '\n两种情况：\n\n如果queue本身便比consumer多。那么多上线几个consumer可以缓解消息堆积的问题\n\n如果queue本身不多于consumer，那么上线多个consumer是没有用的。此时应该上线代码将该topic中的数据转移到另一个topic中，然后开多个queue与consumer进行消费处理\n\n', '0', '1', '1', '1', '2022-12-19 18:03:33', '2022-12-19 18:03:33');
INSERT INTO `tb_card_answer` VALUES ('286', '290', '\nRocketmq实现分布式事务。\n\n通过向broker发送half消息。只有在TM获取到所有都准备好的指令之后，才会向broker发送commit/rollback消息，这个时候这个消息才能被消费者看到，才来让其他的所有RM都执行对应的逻辑进行提交', '0', '1', '1', '1', '2022-12-19 18:03:40', '2022-12-19 18:03:40');
INSERT INTO `tb_card_answer` VALUES ('287', '291', '\n批量发送的消息不能是延时消息或者事务消息。默认消息体最大上线为4M，可配置（需配置生产者和消费者两端）\n', '0', '1', '1', '1', '2022-12-19 18:03:46', '2022-12-19 18:03:46');
INSERT INTO `tb_card_answer` VALUES ('288', '292', '\n+ 平均分配\n\n+ 环型平均分配，这样就可以将queue依次分配，不用计算每个consumer分配几个queue的问题\n\n+ 一致性hash算法：最常见的形式了，将queue进行取模运算。适用于频繁变化consumer数量的情况\n\n+ 同机房策略\n\n  ![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/tXm2ul.jpg)\n\n', '0', '1', '1', '1', '2022-12-19 18:03:56', '2022-12-19 18:03:56');
INSERT INTO `tb_card_answer` VALUES ('289', '293', '1、快速排序：找到一个中间值，然后将大于放在右边，小于放在左边。然后再递归对两边分别进行快排\n\n2、选择排序：从前往后，取一个数字比较，如果后面的数字比当前小就替换。最后比较完了之后将该数字放在最前面（每次确定最前面的一个数字是当前最小的，下一次就可以从前面少比较一个数字）\n\n3、冒泡排序：从前往后依次比较相邻的两个数的大小，如果不符合顺序就替换位置。一直比较（每轮比较都能得到一个最大值，下一次就可以少比较一个数）\n\n4、插入排序：依次从数据中取出来一个数字，与下面设定的有序表的从前往后遍历比较，当大于当前位置且小于下一位置的时候，就放在这个地方\n\n5、归并排序：分治思想。先分，取mid将数据分成两边，然后两边继续分，直到都是单独的一个数字；再治，依次比较每组数据（采用两个指针的方式比较数字，当一组数字比较完另外一组直接放在当前tmp数组后面）\n\n6、基数排序：桶排序的变形，设置0-9十个桶，按照每个数字的从小往大的位数放置在每个桶中，每轮确定一个位数。', '0', '1', '1', '1', '2022-12-20 13:58:51', '2022-12-20 13:58:51');
INSERT INTO `tb_card_answer` VALUES ('290', '294', 'Synchronized关键字加载方法头上，会对整个方法上锁，也就是并发访问该方法只能有一个线程可以访问到。方法访问结束即释放锁。不需要开发者主动参与\n\nLock关键字，需要手动上锁和解锁，可能会出现死锁的情况。但是使用起来锁的粒度较小较灵活', '0', '1', '1', '1', '2023-02-27 15:23:16', '2023-02-27 15:23:16');
INSERT INTO `tb_card_answer` VALUES ('291', '295', '因为多个线程可以同时操作这一块数组空间，所以就会出现一个线程在访问数据的同时，另外一个线程在对数据进行修改。', '0', '1', '1', '1', '2023-02-27 15:23:25', '2023-02-27 15:23:25');
INSERT INTO `tb_card_answer` VALUES ('292', '296', '存在的目的就是为了在多线程的情况下，一个变量的变更能被别的正在访问该变量的线程察觉到。\n\n工作原理：加上之后，任何一个线程对该变量的修改，都会通知到主线程，主线程会通知子线程作废该变量的数据。\n\n其实不适用volatile，也可以对变量增加锁，来保证对变量的访问/修改只有一个线程可以进行', '0', '1', '1', '1', '2023-02-27 15:23:34', '2023-02-27 15:23:34');
INSERT INTO `tb_card_answer` VALUES ('293', '297', '1、synchronized关键字修饰方法或代码块，整个方法就会自动上锁解锁，异常自动解锁；lock需要手动调用lock()上锁和unlock()解锁。\n\n2、synchronized是从字节码层面上加上了`monitorenter`和`monitorexit`，其使用的锁是对象的元数据上的`monitor`；lock使用比较灵活，使用的锁是传入lock的对象。\n\n3、synchronized无法线程中断去执行别的线程（不灵活）', '0', '1', '1', '1', '2023-02-27 15:24:15', '2023-02-27 15:24:15');
INSERT INTO `tb_card_answer` VALUES ('294', '298', '1、从字节码的层面将`monitorenter`和`monitorexit`加入进去包裹方法块。\n\n2、基于对象的monitor锁，进行判断其值，每次进入锁+1，释放锁-1。直到其他线程观察这个锁为0才可以再进去。', '0', '1', '1', '1', '2023-02-27 15:24:27', '2023-02-27 15:24:27');
INSERT INTO `tb_card_answer` VALUES ('295', '299', '功能：多线程模式下去操作同一个变量，为了保证变量数据的变更能够在所有线程中实时共享。\n\n工作原理：被volatile修饰的变量，在任何一个线程中进行了修改，都会通知主线程进行修改。其他线程（处理器）通过嗅探发现数据被修改，就会将自己本地的数据作废进行重新获取。\n\n缺点：\n\n1、不能保证原子性操作：只能保证共享变量在所有线程的可见性，但是不能保证顺序执行，也就是通知别的线程进行变更的底层操作不是原子性的。（通过加锁解决）\n\n2、禁止了指令重排序（处理器对代码指令优化的一个功能）', '0', '1', '1', '1', '2023-02-27 15:24:35', '2023-02-27 15:24:35');
INSERT INTO `tb_card_answer` VALUES ('296', '300', '一共是七个（包括unit）\n\n**`corePoolSize`**：空闲时间也会存在的最小线程数量，不会被回收的线程数量\n\n**`maximumPoolSize`**：线程池允许的最大线程数量。当任务数量超过`corePoolSize`，就会将多余的任务加到队列中。如果队列也满了就会创建新的线程去处理业务。但是最大的线程数量就是`maximumPoolSize`。\n\n**`keepAliveTime`**：取出`corePoolSize`之外的线程，在空闲这个时间之后就会销毁。（还有一个unit参数是给这个时间的单位）\n\n**`workQueue`**：工作队列。当任务数量超过`corePoolSize`之后，多余的任务会放到工作队列中。\n\n+ 有界阻塞队列：`Array`实现，当任务超过`corePoolSize`数量，放到该队列中的任务，如果任务数量超过了该队列的大小，就会创建新的线程去处理多余的任务。\n+ 无界阻塞队列：`Linked`实现，该队列没有大小设置，只要多于`corePoolSize`处理的任务都会放在这个队列中等待。不会创建新的线程去处理\n+ 不缓存阻塞队列：不会缓存任务，消费一个任务才能允许放入下一个任务（不会缓存任务等待线程）。超过`corePoolSize`会直接创建新线程去处理任务\n+ 自定义优先级无界阻塞队列：实现`Comparator`接口，正常队列都是FIFO，但是这个队列可以修改任务的优先级。而且是无界的。\n\n**`ThreadFactory`**：线程工厂，用来创建线程，同时指定线程名称、是否是Daemon线程（会随着主线程结束而强制结束）等属性。\n\n**`handler`**：拒绝策略，工作队列满了且maximumPoolSize新线程的创建也到了上限。这个时候就根据这个策略配置来决定后面的任务如何处理\n\n+ `AbortPolicy`丢弃任务并抛出异常。\n+ `DiscardPolicy`丢弃任务不抛出异常。\n+ `DiscardOldestPolicy`丢弃队列中最前面的任务，喜新厌旧。\n+ `CallerRunsPolicy`由主线程去处理这些多余的任务。', '0', '1', '1', '1', '2023-02-27 15:24:44', '2023-02-27 15:24:44');
INSERT INTO `tb_card_answer` VALUES ('297', '301', '`execute`开启线程，没有返回结果（`runnable`类型任务）\n\n`submit`会获取执行结果。所以可以用来执行`callable`对象。返回结果是一个Future对象（可以调用方法强制等待callable线程执行结束获取执行结果）', '0', '1', '1', '1', '2023-02-27 15:24:53', '2023-02-27 15:24:53');
INSERT INTO `tb_card_answer` VALUES ('298', '302', 'Compare and Swap，比较和交换\n\n是什么：一种无锁方式实现线程之间变量同步的乐观锁实现。\n\n存在的目的：为了缓解加锁导致的内核态和用户态频繁切换带来的效率损耗，同时实现乐观锁的业务需求。\n\n实现原理：三个操作数，进行读写的值V、进行比较的值A、再次写入的值B。也就相当于CAS进行了一个循环等待\n\n当B过来写入的时候，就会比较自己的持有A是否和现在存在的A是否相同。不相同就循环等待下一次写入。\n\n```java\n//含义就是下面的代码（啥也不是的代码）这个代码是原子的\npublic JNI Integer cas(int A,int B){\n  if(A=v){\n    v1=v;\n    v=B;\n    return v1;\n  }else{\n    A=V;\n    return false;\n  }\n}\n```\n\n`AtomicInteger`就是基于`CAS`实现的线程安全的`Interger`。', '0', '1', '1', '1', '2023-02-27 15:25:02', '2023-02-27 15:25:02');
INSERT INTO `tb_card_answer` VALUES ('299', '303', '相当于对CAS的一种业务层面的封装\n\n存在原因：\n\n1、CAS只能关注一个int类型数据作为锁\n\n2、CAS底层调用方法太复杂。不切合业务。\n\n', '0', '1', '1', '1', '2023-02-27 15:25:10', '2023-02-27 15:25:10');
INSERT INTO `tb_card_answer` VALUES ('300', '304', '**乐观锁和悲观锁**\n\n> **悲观锁**\n>\n> 每个线程对同一个资源进行操作的时候，都需要进行加锁，使用完资源之后释放锁。\n>\n> 优点：解决所有并发问题\n>\n> 缺点：不支持并发执行，效率很低\n>\n> **乐观锁**\n>\n> 对同一个数据操作的时候，记录一个版本号。每次进行修改的时候更新这个版本号。然后所有线程进行更新操作的时候都需要判断该版本号和第一次获取的时候的版本号是否一致\n\n**自旋锁和自适应自旋锁**\n\n> 自旋锁：不需要线程切换去等待别的线程释放锁，自己一直持有资源去循环判断锁是否释放\n>\n> 自适应自旋锁：自旋锁的优化，会判断自旋的次数来优化资源分配。\n\n**无锁、偏向锁、轻量级锁、重量级锁**\n\n> 四种锁在jdk1.6之后默认开启，锁的膨胀有对应的条件\n>\n> 无锁（直接放行）：没有对资源进行锁定，所有线程访问同一个资源。但是同时只有一个线程进行修改。循环修改的一种实现 CAS就是无锁\n>\n> **偏向锁（有吊牌）：当无锁竞争的情况下，一个线程获取了一次锁。下一次就不需要去尝试获取锁而是直接执行代码就好了。**（会修改对象头中的ThreadID为自己的ID）\n>\n> 轻量级锁（需要登记）：有一个线程访问偏向锁，偏向锁发现这个线程不是我等的那个线程，所以就将该锁进化成轻量级锁。其他线程需要进行自旋等待来尝试获取锁（多个线程的多次CAS）（门卫本来以为只有老王会来，结果来了老杨，就让后面来的都进行登记并且玩会手机等着老杨出来才能进入）\n>\n> 重量级锁（厕所关门）：就是遇到没有钥匙就得阻塞该线程，CPU切换到别的线程执行（门卫跟老杨说，今天只能老王进来，你明天再来吧）\n>\n> **四锁的关系**\n>\n> 这个过程可以称为锁的升级，也可以称为锁的膨胀\n>\n> ![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/四级别锁.drawio.png)\n>\n> 只能正向升级，不能降级。\n>\n> `偏向锁`相对于`无锁`增加了**Mark Word**来标示锁\n>\n> `轻量级锁`相对于`偏向锁`增加了**自旋锁（适应性自旋锁）**操作来竞争锁\n>\n> `重量级锁`相对于`轻量级锁`增加了阻塞等待或者说悲观锁来实现\n\n**公平锁和非公平锁**\n\n> 公平锁，每个线程获取锁的结果是一样的，平均分配。\n>\n> 非公平锁，每个线程根据自己的执行效率和执行情况，每次获取锁的可能性不一样，随机分配。\n\n', '0', '1', '1', '1', '2023-02-27 15:25:22', '2023-02-27 15:25:22');
INSERT INTO `tb_card_answer` VALUES ('301', '305', 'sleep会切换上下文，但是不会释放锁。\n\nwait会释放锁让其他线程执行。', '0', '1', '1', '1', '2023-02-27 15:25:29', '2023-02-27 15:25:29');
INSERT INTO `tb_card_answer` VALUES ('302', '306', 'run方法是主线程去执行对应方法\n\nstart是新建线程去执行对应的方法', '0', '1', '1', '1', '2023-02-27 15:25:36', '2023-02-27 15:25:36');
INSERT INTO `tb_card_answer` VALUES ('303', '307', '1、Thread.stop，不安全不建议使用\n\n2、this.Interrupt()，只是告诉线程执行到这就不执行了。\n\n3、在run方法中标志位进行退出', '0', '1', '1', '1', '2023-02-27 15:25:43', '2023-02-27 15:25:43');
INSERT INTO `tb_card_answer` VALUES ('304', '308', '1、volatile，关键字的线程共享来实现线程的通信。\n\n2、join，一个线程调用了另外一个现成的join方法，就需要等待到对应线程执行结束才继续执行。可以通过这个来让线程顺序执行。\n\n3、ThreadLocal，线程局部变量。也就是整个线程都可以获取整个ThreadLocal中的数据。不需要方法调用的时候携带。线程私有。', '0', '1', '1', '1', '2023-02-27 15:25:52', '2023-02-27 15:25:52');
INSERT INTO `tb_card_answer` VALUES ('305', '309', 'jdk1.6之后默认开启偏向锁。对象实例化之后，处于无锁状态，第一个线程调用了就会将对象头的ThreadID改成这个线程的id。然后变成了偏向锁，偏向这个对象。\n\n第二个线程来访问，先去判断原本的线程是否还存在，如果不存在就变成无锁，然后再偏向新的线程。如果还存在就判断这个线程的操作数栈是否还需要使用到这个对象，还需要使用就升级成轻量级锁。开始竞争。并使用自旋等待的方式获取锁。\n\n当有第三个线程来访问这个对象的时候，将轻量级锁进化成重量级锁（悲观锁）防止自旋浪费CPU资源', '0', '1', '1', '1', '2023-02-27 15:26:00', '2023-02-27 15:26:00');
INSERT INTO `tb_card_answer` VALUES ('306', '310', '+ 加载：将.class从硬盘上加载到内存中的过程\n+ 连接\n  + 验证：验证字节码文件是否合法且不会破坏系统\n  + 准备：对静态变量赋予默认值\n  + 解析：常量池中的符号引用转换成直接引用\n+ 初始化：对静态变量赋予初始值', '0', '1', '1', '1', '2023-02-27 15:26:25', '2023-02-27 15:26:25');
INSERT INTO `tb_card_answer` VALUES ('307', '311', '+ 方法栈：栈型数据结构，存储的是方法中的局部变量表、临时变量、方法返回出口等。线程私有的\n+ 本地方法栈：针对native方法的方法栈存储。\n+ 程序计数器：记录程序运行的字节码文件的行号等\n+ 堆：存储的是实例化的对象，数组等\n+ 方法区：存储的是类的元数据，静态变量，JIT后的即时代码等', '0', '1', '1', '1', '2023-02-27 15:26:33', '2023-02-27 15:26:33');
INSERT INTO `tb_card_answer` VALUES ('308', '312', '垃圾收集算法：\n\n引用计数法和可达性分析法\n\n> 引用计数法：对象的引用在内存中开辟一块区域记录下来。被引用就+1，引用释放就-1。通过这个值的数量来判断当前对象是否还有用。问题在于会出现循环引用的情况，导致内存泄漏\n>\n> 可达性分析法：对一系列被称为GCRoots的根对象开始向下检索，一旦检索到就标注还在使用，最后将没有被检索到的对象释放掉。\n> GCRoots的确立：\n>\n> + 虚拟机栈、本地方法栈中引用的对象（正在使用的对象）\n> + 方法区/堆空间中静态属性引用的对象（说明使用频率会很高）\n> + ...\n\n强软弱虚引用类型，判断哪些引用是可回收的\n\n强引用：即使当前没有引用链指向该对象，也不能回收\n\n软引用：内存溢出之前的FullGC会将其回收\n\n弱引用：下一轮垃圾回收的时候会被回收\n\n虚引用：特殊存在，目的是在被回收的时候能够通知虚拟机一个状态。（发送系统通知）\n\n垃圾回收算法：\n\n> 标记-清除算法：一块内存空间的数据进行垃圾标记，标记结束之后，将属于垃圾的进行清楚（缺点是容易产生内存碎片）\n>\n> 复制算法：将一块内存空间的所有未被标记的数据复制到另外一个快内存空间。然后原本的内存空间全部回收（缺点是浪费空间）\n>\n> 标记-整理：先进行垃圾标记，清楚之后再对内存空间进行统一的整理，解决内存碎片化的问题（缺点是效率低下）\n>\n> 分代回收算法：\n>\n> 新生代使用**复制算法**\n>\n> 老年代使用**标记清楚**算法，一段时间之后进行一次**标记整理**\n>\n> ![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/新生代垃圾回收.drawio.png)', '0', '1', '1', '1', '2023-02-27 15:26:47', '2023-02-27 15:26:47');
INSERT INTO `tb_card_answer` VALUES ('309', '313', '回收年轻代的：SerialGC、ParallelGC、ParNewGC\n\n回收老年代的：Serial Old GC、Parallel Old GC、CMS\n\n都可以回收：G1\n\nCMS：\n\n> 并发标记清除。\n>\n> 先进性并发标记（和其他线程一起运行）\n>\n> 再重新标记（标记在上一轮运行的时候产生的垃圾，此时STW时间缩短）\n>\n> 再进行并发清除即可\n>\n> ![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/hNpvy4.jpg)\n\nG1：\n\n> ![](https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/G6Za7g.jpg)\n>\n> 将内存分配成多个小块空间。然后垃圾回收的时候可以指定每次回收的区域。从而降低垃圾回收造成的STW。同时可以实现多核CPU的性能问题\n\n\n\n', '0', '1', '1', '1', '2023-02-27 15:26:55', '2023-02-27 15:26:55');
INSERT INTO `tb_card_answer` VALUES ('310', '314', '1、将空间分为**新生代**和**老年代**。新生代分为一个Eden和两个Survivor区。\n\n2、每次垃圾回收，将Eden和From中剩余的对象全部复制到Survivor的To中\n\n3、对对象设置老年代计时器，超过计时器就复制到老年代中。\n\n新生代使用复制算法\n\n老年代使用标记清楚算法，时间长了之后进行依次标记整理解决碎片化问题', '0', '1', '1', '1', '2023-02-27 15:27:02', '2023-02-27 15:27:02');
INSERT INTO `tb_card_answer` VALUES ('311', '315', 'MinorGC（新生代）：正常GC，针对年轻代进行回收。Eden满了触发，将Eden和From复制到To中，STW\n\nMajorGC（老年代）：老年代满了，进行老年代回收（一般在MinorGC之后），STW\n\nFullGC（整堆及方法区）：进行MajorGC不能得到效果，进行整堆收集，包括方法区。', '0', '1', '1', '1', '2023-02-27 15:27:10', '2023-02-27 15:27:10');
INSERT INTO `tb_card_answer` VALUES ('312', '316', 'G1在CMS的并发收集基础之上（也有并发标记和最终标记两部分）。将整个内存空间划分成同样大小的region（大对象使用多个连续的region存储）。每次清理只清理局部区域的内存空间。所以STW时间要较于CMS小', '0', '1', '1', '1', '2023-02-27 15:27:18', '2023-02-27 15:27:18');
INSERT INTO `tb_card_answer` VALUES ('313', '317', '将有价值的字节码编译成机器语言\n\n**热点探测功能：**\n\n使用计时器对**方法的使用频率和循环体的使用频率**进行统计。达到一定频率就开启JIT优化代码\n\n**热点衰退：**\n\n在对应优化的代码使用频率衰退到一定程度的时候，就关闭即时编译。\n\n**编译器**\n\n+ C1编译器：用在client模式上的java代码。耗时短（即时编译的代码少）对应代码运行速度差点。\n+ C2编译器：用在server模式上的。耗时长（即时编译的代码多）对应代码运行速度可以。', '0', '1', '1', '1', '2023-02-27 15:27:26', '2023-02-27 15:27:26');
INSERT INTO `tb_card_answer` VALUES ('314', '318', '**版本问题：**\n\njdk1.6在永久代中\n\njdk1.7之后字符串常量池和静态变量的引用都被调整到了堆中\n\n**什么是字符串常量池**\n\n八种基本类型和String这种区分开\n\n1、使用双引号创建的字符串，自动存放在字符串常量池中。使用对象new出来的放在堆中。可以使用.intern()方法\n\n2、在1.7之前，使用双引号或者.intern()方法创建的字符串是放到了方法区中。但是之后全部都是在堆中，所以需要调整堆得大小。', '0', '1', '1', '1', '2023-02-27 15:27:42', '2023-02-27 15:27:42');
INSERT INTO `tb_card_answer` VALUES ('315', '319', '**<font color=\"red\">第一次</font>**：**没有双亲委派机制之前**。JDK1.2之前有了ClassLoader的概念，但是没有双亲委派机制。这个时候的开发者如果已经有了一些自定义类加载器的代码就没法去强迫用户修改了。所以就只能妥协承认已出现的代码的破坏行为。\n\n<font color=\"red\">第二次</font>：**SPI机制**。基础接口的实现类，需要用户自己实现。比如Driver的实现类。所以这个时候本身Driver是BootStrap加载，但是需要用户自己的实现类。所以Bootstrap委托**上线文加载器**去通知应用类加载器，加载用户自己实现的实现类。\n\n<font color=\"red\">第三次</font>：**热替换，热部署**。每一个代码模块（Bundle）都有自己的类加载器。需要替换这个Bundle，就将其和其类加载器一起替换掉。重新加载的时候就不是从上至下的委托加载而是平行结构的直接加载。', '0', '1', '1', '1', '2023-02-27 15:27:51', '2023-02-27 15:27:51');
INSERT INTO `tb_card_answer` VALUES ('316', '320', '[推荐看该文：存储结构](https://mp.weixin.qq.com/s?__biz=MzU0OTE4MzYzMw==&mid=2247508558&idx=5&sn=f798822d3b03d74f670e505e9b699df2&chksm=fbb12bb0ccc6a2a6a613f0f0169f3bb9b8e884758ddbc4d0fad2a15731c97d4bbca58ece5f01&scene=27)\n\n文件存储，主要包括三方面\n\n1、commitLog：存储消息主题和消息的元数据（topic等）。在commitlog文件夹中，使用20位来表示文件，每个文件1G，第一个文件是`00000000000000000000`每条消息的偏移量是对应消息的大小。\n\n2、`consumerQueue`：每个`topic`对应的`Queue`，存储的是`commitlog`中的`offset`。在`consumerQueue`的文件夹中，有对应所有的Topic名称的文件夹，每个文件夹下是对应Queue（默认四个）的文件夹。`consumerQueue`相当于`commitLog`的一个索引文件\n\n3、Index文件：除了使用consumerQueue快速查询文件（基于offset），还可以基于Message Key、Unique Key、Message Id。所以对应的查询条件都有对应的index索引文件来帮助快速查询到消息。\n\n', '0', '1', '1', '1', '2023-02-27 15:28:23', '2023-02-27 15:28:23');
INSERT INTO `tb_card_answer` VALUES ('317', '321', '发送端：实现SelectorQueue接口，返回一个QueueMq。发送的时候带上即可指定发送到一个\n\n消费端：分布式锁保证该消费是一次一次消费。', '0', '1', '1', '1', '2023-02-27 15:28:41', '2023-02-27 15:28:41');
INSERT INTO `tb_card_answer` VALUES ('318', '322', '1、发送端：使用half消息，只有确保broker有效才发送。当一个broker失败了，下一次发送到另一个broker中\n\n2、同步刷盘同步复制\n\n3、消费端，代码处理重试以及只有处理完成才主动ACK\n\n', '0', '1', '1', '1', '2023-02-27 15:28:47', '2023-02-27 15:28:47');
INSERT INTO `tb_card_answer` VALUES ('319', '323', '## \n\n| 类型   | 底层数据结构       | 简介                                                         | 特点                                                         |\n| ------ | ------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |\n| String | 简单动态字符串     |                                                              | k-v都是字符串（v是数字的时候支持incr和decr）                 |\n| List   | 双向链表、压缩列表 | 压缩列表，数组实现，将头结点和尾节点的偏移量放在了数组头部<br> | 有序列表，一个key对应多个val                                 |\n| Hash   | 哈希表、压缩列表   |                                                              | hash结构，一个key对应的是一整个hash数据，有key、field1、val1... |\n| Set    | 整数数组、压缩列表 |                                                              | 无序可重复集合                                               |\n| ZSet   | 压缩列表和跳表     | 一种基于二分查找思想实现的树形结构。                         | 有序可重复集合，增加score作为顺序                            |\n', '0', '1', '1', '1', '2023-02-27 15:29:06', '2023-02-27 15:29:06');
INSERT INTO `tb_card_answer` VALUES ('320', '324', '**解决雪崩**\n\n由于在特定时间有大量的key过期导致大量请求打到数据库\n\n1、有效时间增加随机值\n\n2、动态分配key的有效时间\n\n**解决击穿**\n\n大量恶意请求，获取不到mysql数据，任然请求\n\n1、布隆过滤器，数据是否存在在一个列表中能够记录下来（不存在则直接返回）\n\n2、本地缓存，对于null也存储', '0', '1', '1', '1', '2023-02-27 15:29:14', '2023-02-27 15:29:14');
INSERT INTO `tb_card_answer` VALUES ('321', '325', '**主从复制**\n\n目的就是从服务器备份主服务器的数据，防止数据丢失。\n\n**哨兵模式**\n\n哨兵可以进行主从的切换。防止单点故障。\n\n**cluster模式**\n\n1、将key分配到16832个槽里面，可以降低单个节点的压力\n\n2、主从结构去中心化，出现故障，自动进行切换\n\n3、数据复制，防止数据丢失', '0', '1', '1', '1', '2023-02-27 15:29:21', '2023-02-27 15:29:21');
INSERT INTO `tb_card_answer` VALUES ('322', '326', '**原理**：基于AOP机制\n\n1、对于被`@Transaction`修饰的Bean，会创建其代理对象\n\n2、当调用代理对象的对应方法时，会先创建一个关闭了自动提交的数据库链接\n\n3、执行该方法之前会开启事务，没有异常或异常是非捕捉回滚异常会自动提交事务。\n\n**事务传播机制**\n\nSpring事务自己实现的。对于配置的是新开一个事务而非进入原本的事务，会新建一个链接来开启新的事务。\n\n① PROPAGATION_REQUIRED：（**默认传播行为**）如果当前没有事务，就创建一个新事务；如果当前存在事务，就加入该事务。\n② PROPAGATION_REQUIRES_NEW：无论当前存不存在事务，都创建新事务进行执行。\n③ PROPAGATION_SUPPORTS：如果当前存在事务，就加入该事务；如果当前不存在事务，就以非事务执行。\n④ PROPAGATION_NOT_SUPPORTED：以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。\n⑤ PROPAGATION_NESTED：如果当前存在事务，则在嵌套事务内执行；如果当前没有事务，则按REQUIRED属性执行。\n⑥ PROPAGATION_MANDATORY：如果当前存在事务，就加入该事务；如果当前不存在事务，就抛出异常。\n⑦ PROPAGATION_NEVER：以非事务方式执行，如果当前存在事务，则抛出异常。\n\n**事务失效的原因**\n\n+ 该方法的调用的对象，不是注入到IOC中的对象。Spring未管理\n+ 异常抛出的时候没有被代理对象捕捉（自己内部捕捉处理或者配置的捕捉异常不匹配）\n+ 没有开启配置事务管理器\n+ Mysql本身不支持该事务\n\n', '0', '1', '1', '1', '2023-02-27 15:29:48', '2023-02-27 15:29:48');
INSERT INTO `tb_card_answer` VALUES ('323', '327', '1、代理模式：AOP机制、事务管理机制\n\n2、工厂模式：BeanFactory\n\n3、观察者模式：各种EventListener的实现类\n\n4、单例模式：IOC容器中配置的单例属性\n\n5、适配器模式：各种后处理器Aware方法等\n\n', '0', '1', '1', '1', '2023-02-27 15:29:55', '2023-02-27 15:29:55');
INSERT INTO `tb_card_answer` VALUES ('324', '328', '使用多级缓存的方式来解决\n\n一级缓存：放的是实例化结束后的Bean\n\n二级缓存：放的是开始实例化的，但是未完成属性配置的Bean\n\n三级缓存：用来生产二级缓存中对象的。存放创建的Bean实例的引用。\n\n原理：A依赖B，B也依赖A\n\n1、当要加载A的时候，实例化但是要注入B的属性值。这个时候可以将未完成依赖的A放入二级缓存中。开始初始化B\n\n2、初始化B，当需要注入A的时候，去二级缓存中找到了A。然后注入成功，将B的实例化对象放到一级缓存中\n\n3、给A注入B的属性，这个时候在一级缓存中找到了B。最终达到A中有B，B中有A', '0', '1', '1', '1', '2023-02-27 15:30:02', '2023-02-27 15:30:02');
INSERT INTO `tb_card_answer` VALUES ('325', '329', '**设计模式中的代理模式**\n\n存在目的：\n\n1、为了防止直接使用对象带来不可预知的问题\n\n2、增强对象\n\n简单的代码实现逻辑\n\n1、对象A有对应方法a\n\n2、代理对象AProxy，有对应方法aProxy，其中调用a方法\n\n3、调用a方法不再创建A对象。而是创建AProxy，来调用aProxy方法\n\n\n\n**静态代理和动态代理**\n\n本质区别：\n\n1、静态代理是代理模式的一种代码实现。动态代理只是用了代理模式的思想\n\n2、动态代理不需要去对每一个代理对象实现具体的代理类。而是统一交给动态代理方法去管理\n\n**jdk动态代理和CGLib动态代理**\n\n**底层实现原理区别：**\n\n+ JDK动态代理是基于java内部的反射机制来生成对应的代理类\n+ CGLib是基于asm包在字节码层面生成代理类来实现方法的增强\n\n**使用上的区别**\n\n1、JDK动态代理要求，代理类和代理对象实现同一个接口；CGLib不需要实现同一个接口。\n\n2、JDK动态代理依赖InvocationHandler来创建代理类；CGLib依赖MethodIntercepter对象来创建代理类。\n\n**SpringAOP在使用动态代理的时候**\n\n能用JDK动态代理（代理对象有接口（能让代理类实现对应的接口））就用，否则就用CGLib。\n\n**AOP除了代理方式**\n\nAspectJ插件，帮助在编译阶段将通知的业务代码切入到切点中去。这样就可以不用生成代理类来帮助实现。', '0', '1', '1', '1', '2023-02-27 15:30:10', '2023-02-27 15:30:20');
INSERT INTO `tb_card_answer` VALUES ('326', '330', '实例化、属性注入、初始化、销毁\n\n1、实例化：通过反射机制创建对应的对象\n\n2、属性注入：对实例化的对象中需要的属性进行注入，如果依赖未创建的Bean就先去创建对应的Bean\n\n3、初始化：执行一些Bean的后处理器。\n\n4、销毁：不受依赖的时候进行销毁。销毁前也会执行一些后处理器\n\n', '0', '1', '1', '1', '2023-02-27 15:30:33', '2023-02-27 15:30:33');
INSERT INTO `tb_card_answer` VALUES ('327', '331', '观察者：对象中的一对多关系，当一个对象发生变化，其他依赖于它的对象能得到通知去做一些操作。就是在被依赖对象做一些操作之后，去调用依赖对象的方法（被依赖对象需要一个属性保存其依赖对象）。\n\n工厂：一种将创建对象抽象成一个工厂中取出来。将代码层面的创建对象变成传入参数来决定创建的对象\n\n单例：保证对象的生成只能有一个对象。\n\n代理：使用代理类来生成对象，再生成的时候可以进行一些增强操作\n\n桥接：将类的属性相互解耦合，保证后期增加属性的便利性。属性的对象类型，是通过创建对象的时候传入的。\n\n建造者：对于构造函数的参数超过四个的，使用建造者模式来创建对象。类似lombok中的@Builder', '0', '1', '1', '1', '2023-02-27 15:31:40', '2023-02-27 15:31:40');
INSERT INTO `tb_card_answer` VALUES ('328', '332', '1、快速排序：找到一个中间值，然后将大于放在右边，小于放在左边。然后再递归对两边分别进行快排\n\n2、选择排序：从前往后，取一个数字比较，如果后面的数字比当前小就替换。最后比较完了之后将该数字放在最前面（每次确定最前面的一个数字是当前最小的，下一次就可以从前面少比较一个数字）\n\n3、冒泡排序：从前往后依次比较相邻的两个数的大小，如果不符合顺序就替换位置。一直比较（每轮比较都能得到一个最大值，下一次就可以少比较一个数）\n\n4、插入排序：依次从数据中取出来一个数字，与下面设定的有序表的从前往后遍历比较，当大于当前位置且小于下一位置的时候，就放在这个地方\n\n5、归并排序：分治思想。先分，取mid将数据分成两边，然后两边继续分，直到都是单独的一个数字；再治，依次比较每组数据（采用两个指针的方式比较数字，当一组数字比较完另外一组直接放在当前tmp数组后面）\n\n6、基数排序：桶排序的变形，设置0-9十个桶，按照每个数字的从小往大的位数放置在每个桶中，每轮确定一个位数。\n\n7、希尔排序：插入排序的优化，增加分组的概念，先进行分组，组内排序完成之后，缩小组的数量增大每个组的元素数量，然后再进行排序。\n\n先学习：动态规划算法、KMP算法、BM算法（后面两个是解决str的通用算法（最优））\n\n**时间复杂度：冒泡、插入、选择都是O(n^2)，快速、希尔、归并、堆都是O(nlogn)，桶是O(n+k)基数是O(n*k)**\n\n![](https://img-blog.csdnimg.cn/20210316213527859.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzIwNzAyNQ==,size_16,color_FFFFFF,t_70#pic_center)\n', '0', '1', '1', '1', '2023-02-27 15:32:11', '2023-02-27 15:32:11');
INSERT INTO `tb_card_answer` VALUES ('329', '333', '1. **哈希映射**：如果数据太大，不能全部放入内存中，就可以利用映射函数将每条数据映射到一个小文件中，例如 `%1000` 可以将大文件映射成 1000 个小文件。**相同的数据会出现在同一个文件中。**\n2. **HashMap 统计**：将大文件转换为小文件后，就可以利用 HashMap 来统计每个 key 出现的次数。\n3. **堆排序/快速排序**：根据 HashMap 中的数据，利用堆排序/快速排序，就可以得到频率最高的 key。', '0', '1', '1', '1', '2023-02-27 16:09:06', '2023-02-27 16:09:06');
INSERT INTO `tb_card_answer` VALUES ('330', '334', '将大文件映射为小文件，比如使用 `IP%1000` 将所有 IP 映射到 1000 个小文件中，相同的 IP 会被映射到同一个文件中。然后找出每个小文件中出现频率最高的 IP，那么这 1000 个 IP 中频率最高的那个就是所有 IP 中频率最高的那个。\n\n具体来说，对于一个小文件，使用 HashMap 统计每个 IP 的次数，统计过程中找出频次最高的 IP。', '0', '1', '1', '1', '2023-02-27 16:09:16', '2023-02-27 16:09:16');
INSERT INTO `tb_card_answer` VALUES ('331', '335', '假设每个字符串占据 255 字节，那么 300 万个字符串一共占据 300∗10000∗255/1024/1024/1024=0.75GB300∗10000∗255/1024/1024/1024=0.75GB，可以全部放到内存中来处理。所以不再需要将大文件转化为小文件，可以直接使用 `HashMap` 进行统计，然后使用快排/堆排序找出结果。\n\n1. HashMap 统计：使用 HashMap 保存每个字符串的频次，可以在 O(n)O(n) 时间完成统计。\n2. 堆排序：维护一个大小为 10 的小根堆，遍历每个字符串，将它的频次和堆顶元素比较，如果大于堆顶元素的频次，就将堆顶元素删除，将当前字符串加入堆。这样最后堆中元素就是频次最大的 10 个字符串。', '0', '1', '1', '1', '2023-02-27 16:09:28', '2023-02-27 16:09:28');
INSERT INTO `tb_card_answer` VALUES ('332', '336', '1. hash 映射：依次读取每个文件，按照 `hash(str)%10` 的结果将每个字符串写入一个文件，形成另外 10 个文件，和原来的 10 个文件的不同在于，现在 **相同的字符串会出现在同一个文件中**。如果 hash 函数结果是随机的，那么每个文件的大小也会是 1G。\n2. HashMap 统计每个字符串出现的次数。\n3. 利用堆排序按照出现次数对字符串排序，将排好序的字符串和对应的次数输出到文件中，形成 10 个排序文件（因为全部排序的话内存装不下）。然后利用外部排序（归并排序）对这 10 个文件进行整体排序。', '0', '1', '1', '1', '2023-02-27 16:09:38', '2023-02-27 16:09:38');
INSERT INTO `tb_card_answer` VALUES ('333', '337', '每个文件大小约为 320G，需要分治。首先读取文件 a，对每个 url 求 `hash(url)%1000`，将每个 url 映射到一个小文件中，且相同的 url 会被放到同一个文件。这样每个小文件大小约为 300M。对文件 b 执行同样的操作。然后求出这 2000 个小文件中的共同 url 即可：\n\n1. 使用 HashSet 对每个小文件去重。\n\n2. 求出 1000 对小文件中的共同 url：\n\n   ```rust\n   for fa in all_file_a:\n   	for fb in all_file_b:\n   		求出 fa 和 fb 中的共同 url\n   ```\n\n------\n\n', '0', '1', '1', '1', '2023-02-27 16:09:47', '2023-02-27 16:09:47');
INSERT INTO `tb_card_answer` VALUES ('334', '338', '采用 **2-bitmap** 方法：00 表示不存在，01表示出现一次，10表示出现多次。即用两位就可以表示一个数的状态。`int` 型整数占用 4B，一共有 232232 个不同的数，所以需要使用 232∗2b=1GB232∗2b=1GB 内存来表示所有 `int` 整数的状态。\n\n遍历这 2.5 亿个数，查看位图中对应的位，如果是 00，则变为 01，如果是 01，则变为 10，如果是 10，则保持不变。遍历结束后，将 01 对应的所有整数输出即可。', '0', '1', '1', '1', '2023-02-27 16:09:55', '2023-02-27 16:09:55');
INSERT INTO `tb_card_answer` VALUES ('335', '339', '如果数据可以全部放入内存中，那么可以直接排序，时间复杂度为 O(nlogn)O(nlogn)，更好的办法是使用两个堆，一个大根堆一个小根堆，**大根堆中最大的数小于等于小根堆中最小的数**，且保证两个堆中的元素个数相差不超过 1。如果数据总数为偶数，那么中位数就是这两个堆顶元素的平均值；如果为奇数，中位数就是数据较多的那个堆的堆顶元素。\n\n```java\nclass MedianFinder {\n  private PriorityQueue<Integer> maxHeap;\n  private PriorityQueue<Integer> minHeap;\n  \n  public MedianFinder() {\n    maxHeap = new PriorityQueue<>(Comparator.reverseOrder());\n    minHeap = new PriorityQueue<>(Integer::compareTo);\n  }\n  \n  public void addNum(int num) {\n    // 大根堆中的元素都小于小根堆\n    if (maxHeap.isEmpty() || maxHeap.peek() > num) {\n      maxHeap.offer(num);\n    } else {\n      minHeap.offer(num);\n    }\n    // 保证两堆数据个数相差最多一个\n    int size1 = maxHeap.size();\n    int size2 = minHeap.size();\n    if (size1 - size2 > 1) {\n      minHeap.offer(maxHeap.poll());\n    } else if (size2 - size1 > 1) {\n      maxHeap.offer(minHeap.poll());\n    }\n  }\n  \n  public double findMedian() {\n    int size1 = maxHeap.size();\n    int size2 = minHeap.size();\n    return size1 == size2\n      	? (maxHeap.peek() + minHeap.peek()) * 1.0 / 2\n      	: (size1 > size2 ? maxHeap.peek() : minHeap.peek());\n  }\n}\n```\n\n5 亿个数，每个数字占 4B，那么一共需要 2G 内存，一般来说是可以全部放入内存的。但如果数据量大于可用内存，就需要使用分治法了。\n\n顺序读取这 5 亿个数字，对于读取到的数字 num，如果它对应的二进制中最高位为 1（说明是负数），则把这个数字写到 f1 中，否则写入 f0 中。通过这一步，可以把这 5 亿个数划分为两部分，而且 f0 中的数都大于 f1 中的数。\n\n如果划分后两个文件中的数据有相同个数，那么中位数就是数据较小的文件中的最大值与数据较大的文件中的最小值的平均值。\n\n如果划分后个数不同，则中位数在那个数据较多的文件中。假设 f1 中有 1 亿个数，那么中位数就是 f0 中从第 1.5 亿个数开始的两个数求得的平均值。对于 f0 可以用次高位的二进制继续将文件一分为二，如此划分下去，直到划分后的文件可以被加载到内存中，把数据加载到内存中以后直接排序，找出中位数。', '0', '1', '1', '1', '2023-02-27 16:10:48', '2023-02-27 16:10:48');
INSERT INTO `tb_card_answer` VALUES ('336', '340', '1、去DNS服务器解析域名获取ip\n\n2、使用ip建立TCP链接\n\n3、向IP地址发送HTTP请求\n\n4、服务器处理请求\n\n5、服务器响应\n\n6、关闭TCP链接\n\n7、解析HTML\n\n8、渲染页面布局', '0', '1', '1', '1', '2023-02-27 16:12:53', '2023-02-27 16:12:53');
INSERT INTO `tb_card_answer` VALUES ('337', '341', '[相关问题](https://www.cnblogs.com/Sandy-1128/p/http.html)\n\n对于HTTP1.0，默认是不支持多个请求的，一个请求结束之后就会断开链接\n\n对于HTTP1.1，如果connection设置的是keep-alive，则可以发送多个请求。', '0', '1', '1', '1', '2023-02-27 16:13:05', '2023-02-27 16:13:05');
INSERT INTO `tb_card_answer` VALUES ('338', '342', 'HTTP1.1中，同一时间只能处理一个请求，虽然1.1中规定了Pipelining（同时接收请求，按顺序返回响应）来解决这个问题，但浏览器默认该功能关闭，浏览器无法判断响应是哪一个请求的，问题比较多，若第1个响应延迟或不能正确处理，将会导致其他响应阻塞等等。\n\nHTTP2提供了Multiplexing多路传输特性，可以在一个TCP中同时完成多个HTTP请求，并行完成。', '0', '1', '1', '1', '2023-02-27 16:13:11', '2023-02-27 16:13:11');
INSERT INTO `tb_card_answer` VALUES ('339', '343', '有，Chrome最多允许对同一个Host建立6个TCP连接，不同浏览器有差别。优先使用HTTP2，如果不支持，就使用多连结来并发请求，如连接都有请求在处理，那只能继续等待空闲了。', '0', '1', '1', '1', '2023-02-27 16:13:20', '2023-02-27 16:13:20');
INSERT INTO `tb_card_answer` VALUES ('340', '344', '长时间不通信，服务端会给客户端发送一个TCP Keep-Alive来查看客户端是否还存活,如果客户端没有应答，服务端超时没有收到回复就会再次重新发送；连续发送三次后，服务端都没有收到应答，服务端就会主动断开连接。\n\n ', '0', '1', '1', '1', '2023-02-27 16:13:26', '2023-02-27 16:13:26');
INSERT INTO `tb_card_answer` VALUES ('341', '345', '**301重定向，也叫“永久性转移”，301会把原网页权重转移到重定向目标的网站上面。302跳转也称为，“临时跳属转”。**\n\n301 Moved Permanently\n被请求的资源已永久移动到新位置，并且将来任何对此资源的引用都应该使用本响应返回的若干个URI之一。如果可能，拥有链接编辑功能的客户端应当自动把请求的地址修改为从服务器反馈回来的地址。除非额外指定，否则这个响应也是可缓存的。\n302 Found\n请求的资源现在临时从不同的URI响应请求。由于这样的重定向是临时的，客户端应当继续向原有地址发送以后的请求。只有在Cache-Control或Expires中进行了指定的情况下，这个响应才是可缓存的。', '0', '1', '1', '1', '2023-02-27 16:13:36', '2023-02-27 16:13:36');
INSERT INTO `tb_card_answer` VALUES ('342', '346', 'cpu异常，在Java中一般是以下几种情况导致的\n\n+ 死循环 jstack\n+ 频繁GC jstat\n+ 上下文切换过多 vmstat\n\n解决方案\n\n第一步、使用top命令看到是哪个进程ID占用cpu资源过多\n\n第二步、使用`top -H -p pid`，获取线程占用情况的tid\n\n第三步、将占用最高的线程tid转换成16进制`printf \'%x\\n\' nid`\n\n第四步、使用jstack将对应线程的堆栈信息输出出来`jstack pid |grep \'nid\' -C5 –color`（16进制是四位，不够前面补充0x）', '0', '1', '1', '1', '2023-02-27 17:46:08', '2023-02-27 17:46:08');
INSERT INTO `tb_card_answer` VALUES ('343', '347', '+ OM。每次请求都 new 对象，导致大量重复创建对象；进行文件流操作但未正确关闭；手动不当触发 gc；ByteBuffer 缓存分配不合理等都会造成代码 OOM。\n+ GC 问题\n+ 堆外内存\n\n`Exception in thread \"main\" java.lang.OutOfMemoryError: unable to create new native thread`\n\n没有足够的内存用于栈的分配。一般是代码未进行shutdown等。使用jstack、jmap定位到代码进行查看修改\n\n`Exception in thread \"main\" java.lang.OutOfMemoryError: Java heap space`\n\n堆内存已经达到最大，可能有内存泄漏。从代码层面查找问题jstack、jmap。\n\n**Caused by: java.lang.OutOfMemoryError: Meta space**\n\n元空间不足，可能的原因是资源未关闭，数组引用使用异常等（类加载的太多了）\n\n**Exception in thread \"main\" java.lang.StackOverflowError**\n\n栈溢出，方法内的常量，局部变量等有使用问题。死循环等。jmap -dump:format=b,file=filename pid进行查看\n\n\n\n在启动参数中指定-XX:+\nHeapDumpOnOutOfMemoryError来保存 OOM 时的 dump 文件。但是主要要定时删除，防止磁盘被压满', '0', '1', '1', '1', '2023-02-27 17:46:23', '2023-02-27 17:46:23');
INSERT INTO `tb_card_answer` VALUES ('344', '348', '第一步：合理调整年轻代和老年代的分配比例\n\n对于【IO密集型】可以将【年轻代】空间加大些，因为大多数对象都是在年轻代灭亡。\n\n【CPU密集型】可以将【老年代】空间加大，对象的存活时间会更长些。\n\n> CPU密集，表示一个逻辑需要进行大量的计算和上下文切换等，这个时候对象存活时间长。\n>\n> IO密集，表示接口请求量很大，但是不关注业务处理时间。这个时候对象的存活时间短，但是对象量大\n\n第二步：合理使用各种垃圾回收期。\n\n主要还是在G1上，如果说机器是多核CPU，使用G1垃圾回收器的效率更高，STW的时间也更低。\n\n', '0', '1', '1', '1', '2023-02-27 17:46:42', '2023-02-27 17:46:42');
INSERT INTO `tb_card_answer` VALUES ('345', '349', '方法区的内存就是使用的主机内存，所以查看主机内存发现使用率特别高的时候，就说明Jvm的方法区占用了太多。\n\n一般是因为内存泄漏（用了内存没有释放），导致的频繁full GC（会产生STW），继而导致系统响应慢。最后主机内存使用完毕，系统崩溃。\n\n排查方法（找到Full GC的dump文件）：\n\n（1）通过`jps`查找java进程id。\n（2）通过`top -p [pid]`发现内存占用达到了最大值\n（3）`jstat -gccause pid 20000` 每隔20秒输出`Full GC`结果\n（4）发现`Full GC`次数太多，基本就是内存泄露了。生成`dump`文件，借助工具分析是哪个对象太多了。基本能定位到问题在哪。\n\n产生原因实例：\n\n1、使用流资源（socket流、文件流），未释放\n\n```java\ntry {\n    BufferedReader br = new BufferedReader(new FileReader(inputFile));\n    ...\n    ...\n} catch (Exception e) {\n    e.printStacktrace();\n}\n```\n\n## ', '0', '1', '1', '1', '2023-02-27 17:46:53', '2023-02-27 17:46:53');
INSERT INTO `tb_card_answer` VALUES ('346', '350', 'https://blog.csdn.net/JavaShark/article/details/125300646', '0', '1', '1', '1', '2023-02-27 17:47:26', '2023-02-27 17:47:26');

-- ----------------------------
-- Table structure for tb_card_tag
-- ----------------------------
DROP TABLE IF EXISTS `tb_card_tag`;
CREATE TABLE `tb_card_tag` (
  `id` int unsigned NOT NULL AUTO_INCREMENT,
  `tag_name` varchar(64) NOT NULL DEFAULT '' COMMENT '卡片标签名称',
  `classify` tinyint NOT NULL DEFAULT '0' COMMENT '分类 1-一级分类 2-二级分类',
  `superior_id` tinyint DEFAULT '0' COMMENT '上级tagId',
  `card_num` int NOT NULL DEFAULT '0' COMMENT '该类型卡片数量',
  `desc` varchar(1024) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL DEFAULT '' COMMENT 'tag 的基本描述',
  `status` tinyint NOT NULL DEFAULT '0' COMMENT '标签状态 0-无效 1-有效',
  `img_url` varchar(1024) NOT NULL DEFAULT '' COMMENT '图片后缀',
  `type` tinyint NOT NULL DEFAULT '0' COMMENT '类型：0-官方 1-个人 2-贡献',
  `ctime` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
  `mtime` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '修改时间',
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=33 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci COMMENT='卡片标签';

-- ----------------------------
-- Records of tb_card_tag
-- ----------------------------
INSERT INTO `tb_card_tag` VALUES ('1', 'Java', '1', '0', '209', '最广泛应用于web开发，一般面试的问题包括 “Java基础知识”，“Java各类集合框架”，“Jvm的底层结构和各项功能实现”，“HashMap的实现和相关扩展”，“Java多线程和线程池技术”，“Java中的锁机制”。实际工作中其实这些知识都需要掌握。\n', '1', 'https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/Java_yasuo.png', '0', '2022-06-28 11:53:22', '2023-02-27 17:47:26');
INSERT INTO `tb_card_tag` VALUES ('2', 'Java基础知识', '2', '1', '24', '', '1', '', '0', '2022-06-28 11:54:18', '2022-07-18 17:39:27');
INSERT INTO `tb_card_tag` VALUES ('3', 'JVM', '2', '1', '79', '', '1', '', '0', '2022-06-28 11:55:54', '2023-02-27 15:27:51');
INSERT INTO `tb_card_tag` VALUES ('4', '并发编程', '2', '1', '43', '', '1', '', '0', '2022-06-28 11:56:25', '2023-02-27 15:26:00');
INSERT INTO `tb_card_tag` VALUES ('5', 'Hashmap', '2', '1', '57', '', '1', '', '0', '2022-06-28 11:56:48', '2022-07-13 15:50:43');
INSERT INTO `tb_card_tag` VALUES ('6', 'Mysql', '1', '0', '53', '数据库管理工具，主要特点在于扩展化强，可以很轻松的进行集群化搭建来满足日渐增长的业务需要。主要面试点在于“Mysql的基本操作和概念”，“Mysql的事务机制”，“Mysql的索引和优化逻辑”，“Mysql中的锁机制”\n', '1', 'https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/MYSQL_yasuo.png', '0', '2022-06-28 11:57:16', '2022-07-30 16:03:51');
INSERT INTO `tb_card_tag` VALUES ('8', '索引', '2', '6', '24', '', '1', '', '0', '2022-06-28 14:28:55', '2022-07-29 14:54:34');
INSERT INTO `tb_card_tag` VALUES ('9', '锁', '2', '6', '9', '', '1', '', '0', '2022-06-28 14:29:17', '2022-07-29 14:37:49');
INSERT INTO `tb_card_tag` VALUES ('11', 'MQ', '1', '0', '26', '主流的队列技术有RocketMq、RabbitMq和Kafka。ActiveMq由于社区不再维护所有使用率越来越低。而RabbitMq由于本身不支持分布式的架构所以在大型互联网公司使用率也不高，但是其自带的管理界面还是很好用的。RocketMq目前社区活跃并且其自身具有各种业务逻辑的实现，使得使用者只需要关注本身业务的逻辑而不需要关注Mq如何实现这个逻辑，所以是目前市面上最火的MQ工具。Kafka相对于RockeMq由于还需要依赖Zookeeper作注册中心，所以在业务层面上使用的并不多，但是其在大型的数据处理方面应用的较多。', '1', 'https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/MQ_yasuo.png', '0', '2022-06-28 14:30:00', '2023-02-27 15:28:47');
INSERT INTO `tb_card_tag` VALUES ('12', 'RocketMq', '2', '11', '26', '', '1', '', '0', '2022-06-28 14:30:36', '2023-02-27 15:28:47');
INSERT INTO `tb_card_tag` VALUES ('13', 'RabbitMq', '2', '11', '0', '', '1', '', '0', '2022-06-28 14:30:52', '2022-06-28 15:12:26');
INSERT INTO `tb_card_tag` VALUES ('14', 'Kafka', '2', '11', '0', '', '1', '', '0', '2022-06-28 14:31:27', '2022-06-28 15:12:26');
INSERT INTO `tb_card_tag` VALUES ('15', 'Mq业务实现', '2', '11', '0', '', '1', '', '0', '2022-06-28 14:32:20', '2022-06-28 15:12:26');
INSERT INTO `tb_card_tag` VALUES ('17', 'Spring', '1', '0', '5', '这里主要对Spring的基本概念、IOC的实现原理、AOP的实现原理和Spring衍生出来的各类框架的规则和使用方式进行相关介绍。其中SpringBoot以及SpringCloud相关插件也是面试的重点。', '1', 'https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/Spring_yasuo.png', '0', '2022-06-30 17:42:58', '2023-02-27 15:30:33');
INSERT INTO `tb_card_tag` VALUES ('18', 'ES', '1', '0', '0', 'ES是一个基于RESTful web接口并且构建在Apache Lucene之上的开源分布式搜索引擎。', '1', 'https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/ElasticSearch_yasuo.png', '0', '2022-06-30 17:43:27', '2022-08-01 11:37:59');
INSERT INTO `tb_card_tag` VALUES ('19', 'Redis', '1', '0', '19', 'Redis是一种数据库,是能够存储数据、管理数据的软件。', '1', 'https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/Redis_yasuo.png', '0', '2022-06-30 17:43:50', '2023-02-27 15:29:21');
INSERT INTO `tb_card_tag` VALUES ('21', 'JavaIO', '2', '1', '0', '', '0', '', '0', '2022-07-15 15:01:32', '2022-07-18 16:18:09');
INSERT INTO `tb_card_tag` VALUES ('22', '事务', '2', '6', '11', '', '1', '', '0', '2022-07-18 18:17:13', '2022-07-29 14:32:39');
INSERT INTO `tb_card_tag` VALUES ('23', 'Spring', '2', '17', '5', '', '1', '', '0', '2022-07-18 18:18:25', '2023-02-27 15:30:33');
INSERT INTO `tb_card_tag` VALUES ('24', 'SpringBoot', '2', '17', '0', '', '1', '', '0', '2022-07-18 18:18:47', '2022-07-18 18:18:48');
INSERT INTO `tb_card_tag` VALUES ('25', 'Mysql基础', '2', '6', '9', '', '1', '', '0', '2022-07-18 18:26:50', '2022-07-29 14:35:29');
INSERT INTO `tb_card_tag` VALUES ('26', 'redis基础', '2', '19', '19', '', '1', '', '0', '2022-12-19 13:38:28', '2023-02-27 15:29:21');
INSERT INTO `tb_card_tag` VALUES ('27', '其他', '1', '0', '16', '涉及基础的数据结构及算法、设计模式等相关的信息', '1', 'https://coderymy-image.oss-cn-beijing.aliyuncs.com/uPic/Java_yasuo.png', '0', '2022-12-20 13:57:23', '2023-02-27 16:13:36');
INSERT INTO `tb_card_tag` VALUES ('28', '数据结构与算法', '2', '27', '2', '', '1', '', '0', '2022-12-20 13:57:54', '2023-02-27 15:32:11');
INSERT INTO `tb_card_tag` VALUES ('29', '设计模式', '2', '27', '1', '', '1', '', '0', '2022-12-20 13:58:17', '2023-02-27 15:31:40');
INSERT INTO `tb_card_tag` VALUES ('30', '数据治理', '2', '27', '7', '', '1', '', '0', '2023-02-27 16:08:34', '2023-02-27 16:10:48');
INSERT INTO `tb_card_tag` VALUES ('31', '计算机网络', '2', '27', '6', '', '1', '', '0', '2023-02-27 16:12:34', '2023-02-27 16:13:36');
INSERT INTO `tb_card_tag` VALUES ('32', '线上问题解决', '2', '1', '5', '', '1', '', '0', '2023-02-27 17:45:35', '2023-02-27 17:47:26');

-- ----------------------------
-- Table structure for tb_user
-- ----------------------------
DROP TABLE IF EXISTS `tb_user`;
CREATE TABLE `tb_user` (
  `id` int NOT NULL AUTO_INCREMENT,
  `open_id` varchar(32) NOT NULL DEFAULT '0' COMMENT '微信各个产品的openID',
  `tel` bigint NOT NULL DEFAULT '0' COMMENT '关联手机号',
  `real_name` varchar(16) DEFAULT '' COMMENT '真实姓名',
  `nick_name` varchar(50) DEFAULT NULL COMMENT '昵称',
  `head` varchar(1024) DEFAULT NULL COMMENT '头像地址',
  `birthday` bigint DEFAULT '0' COMMENT '生日(毫秒)',
  `gender` tinyint DEFAULT '0' COMMENT '性别 1男 2女',
  `status` int DEFAULT '0' COMMENT '用户状态（1表示正常）',
  `ctime` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
  `mtime` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '修改时间',
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=5 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci COMMENT='用户信息';

-- ----------------------------
-- Records of tb_user
-- ----------------------------
INSERT INTO `tb_user` VALUES ('1', 'oybrt4keer8knDXGANT_GAO_zvOk', '0', '学习小崽', '明宇', 'https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJ49mQdvtv7tNEJw0VL6qcGtL3tiaANqHbwDZEKrQAdy14qN8zerk0HBzVic3K0uv5KhMGvk5TrPnqw/132', '1656831703210', '0', '1', '2022-07-03 15:01:43', '2022-07-03 15:01:43');
INSERT INTO `tb_user` VALUES ('2', 'oybrt4v9FXjXkenbCKpY6JXPbGxw', '0', '学习小崽', '超_越梦想', 'https://thirdwx.qlogo.cn/mmopen/vi_32/7icobCA5aE7A7aa4pmEx96OYEheBGYkhtA8WxRPIyKNGibkAzPstDibib6zdgsiblqbFKU5gG7SUMxsnRDx4cAwcbgQ/132', '1657534067595', '0', '1', '2022-07-11 18:07:47', '2022-07-11 18:07:47');
INSERT INTO `tb_user` VALUES ('3', 'oybrt4t-gvnY7lXN2mhg3XyZqhjs', '0', '学习小崽', '魏剑帆', 'https://thirdwx.qlogo.cn/mmopen/vi_32/Qp6EnXhUrLJtymib6icE93nnmhS8OXUWibFxYRd2z8LCsJsrfTCGtdKrM2eicBIibnDsb7eBUiaKg1co7YWQvLPKW0HA/132', '1668397190806', '0', '1', '2022-11-14 11:39:50', '2022-11-14 11:39:50');
INSERT INTO `tb_user` VALUES ('4', 'oybrt4v5okNFahCr0ZyiujzJozuY', '0', '学习小崽', '微信用户', 'https://thirdwx.qlogo.cn/mmopen/vi_32/POgEwh4mIHO4nibH0KlMECNjjGxQUq24ZEaGT4poC6icRiccVGKSyXwibcPq4BWmiaIGuG1icwxaQX6grC9VemZoJ8rg/132', '1669011938583', '0', '1', '2022-11-21 14:25:38', '2022-11-21 14:25:38');

-- ----------------------------
-- Table structure for tb_user_card_relation
-- ----------------------------
DROP TABLE IF EXISTS `tb_user_card_relation`;
CREATE TABLE `tb_user_card_relation` (
  `id` int unsigned NOT NULL AUTO_INCREMENT,
  `question_id` int NOT NULL DEFAULT '0' COMMENT '问题id',
  `uid` int NOT NULL DEFAULT '0' COMMENT '用户ID',
  `study_status` tinyint NOT NULL DEFAULT '1' COMMENT '0-未学习、1-已学习未通过、2-已学习已通过',
  `first_class` int NOT NULL DEFAULT '0',
  `second_class` int NOT NULL DEFAULT '0',
  `try_time` tinyint NOT NULL DEFAULT '0' COMMENT '尝试次数',
  `is_collect` tinyint NOT NULL DEFAULT '0' COMMENT '是否收藏 0-未收藏 1-已收藏',
  `ctime` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
  `mtime` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '修改时间',
  `status` tinyint NOT NULL DEFAULT '0' COMMENT '0-无效 1-有效',
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=68 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci COMMENT='用户与卡片关系';

-- ----------------------------
-- Records of tb_user_card_relation
-- ----------------------------
INSERT INTO `tb_user_card_relation` VALUES ('1', '24', '1', '3', '1', '4', '1', '1', '2022-07-13 16:08:37', '2022-07-18 11:04:02', '1');
INSERT INTO `tb_user_card_relation` VALUES ('2', '25', '1', '2', '1', '4', '1', '1', '2022-07-13 16:15:28', '2022-07-18 11:04:02', '1');
INSERT INTO `tb_user_card_relation` VALUES ('3', '7', '1', '3', '1', '3', '1', '1', '2022-07-13 16:35:53', '2022-07-18 11:04:02', '1');
INSERT INTO `tb_user_card_relation` VALUES ('4', '184', '1', '2', '1', '2', '1', '0', '2022-07-14 17:39:16', '2022-07-18 11:03:38', '1');
INSERT INTO `tb_user_card_relation` VALUES ('5', '185', '1', '3', '1', '2', '1', '0', '2022-07-14 23:37:31', '2022-07-18 11:03:38', '1');
INSERT INTO `tb_user_card_relation` VALUES ('6', '180', '1', '2', '1', '2', '1', '1', '2022-07-16 16:59:52', '2022-07-18 11:03:38', '1');
INSERT INTO `tb_user_card_relation` VALUES ('7', '182', '1', '2', '1', '2', '1', '0', '2022-07-16 17:23:32', '2022-07-18 11:03:38', '1');
INSERT INTO `tb_user_card_relation` VALUES ('8', '183', '1', '2', '1', '2', '1', '0', '2022-07-16 17:23:42', '2022-07-18 11:03:38', '1');
INSERT INTO `tb_user_card_relation` VALUES ('9', '181', '1', '2', '1', '2', '1', '0', '2022-07-16 17:24:32', '2022-07-18 11:03:38', '1');
INSERT INTO `tb_user_card_relation` VALUES ('10', '51', '1', '3', '1', '3', '1', '0', '2022-07-16 17:44:48', '2022-07-18 11:04:02', '1');
INSERT INTO `tb_user_card_relation` VALUES ('11', '186', '1', '2', '1', '2', '1', '0', '2022-07-18 11:10:58', '2022-07-18 11:10:58', '1');
INSERT INTO `tb_user_card_relation` VALUES ('12', '8', '1', '3', '11', '12', '1', '0', '2022-07-18 11:11:08', '2022-07-18 11:11:08', '1');
INSERT INTO `tb_user_card_relation` VALUES ('13', '119', '1', '2', '1', '5', '1', '0', '2022-07-18 17:25:24', '2022-07-18 17:25:24', '1');
INSERT INTO `tb_user_card_relation` VALUES ('14', '187', '1', '2', '1', '2', '1', '0', '2022-07-23 15:00:06', '2022-07-23 15:00:06', '1');
INSERT INTO `tb_user_card_relation` VALUES ('15', '205', '1', '2', '6', '22', '1', '0', '2022-07-29 14:32:52', '2022-07-29 14:32:52', '1');
INSERT INTO `tb_user_card_relation` VALUES ('16', '206', '1', '2', '6', '22', '1', '0', '2022-07-29 14:33:04', '2022-07-29 14:33:04', '1');
INSERT INTO `tb_user_card_relation` VALUES ('17', '207', '1', '2', '6', '22', '1', '0', '2022-07-29 14:33:07', '2022-07-29 14:33:07', '1');
INSERT INTO `tb_user_card_relation` VALUES ('18', '208', '1', '2', '6', '22', '1', '0', '2022-07-29 14:33:11', '2022-07-29 14:33:11', '1');
INSERT INTO `tb_user_card_relation` VALUES ('19', '209', '1', '2', '6', '22', '1', '0', '2022-07-29 14:33:25', '2022-07-29 14:33:25', '1');
INSERT INTO `tb_user_card_relation` VALUES ('20', '233', '1', '2', '6', '9', '1', '0', '2022-07-29 14:37:58', '2022-07-29 14:37:58', '1');
INSERT INTO `tb_user_card_relation` VALUES ('21', '188', '1', '2', '1', '2', '1', '0', '2022-07-30 22:34:37', '2022-07-30 22:34:37', '1');
INSERT INTO `tb_user_card_relation` VALUES ('22', '52', '1', '2', '1', '3', '1', '0', '2022-07-31 08:57:03', '2022-07-31 08:57:03', '1');
INSERT INTO `tb_user_card_relation` VALUES ('23', '194', '1', '2', '1', '2', '1', '0', '2022-08-01 14:10:10', '2022-08-01 14:10:10', '1');
INSERT INTO `tb_user_card_relation` VALUES ('24', '181', '3', '2', '1', '2', '1', '0', '2022-11-14 11:40:01', '2022-11-14 11:40:01', '1');
INSERT INTO `tb_user_card_relation` VALUES ('25', '189', '1', '2', '1', '2', '1', '1', '2022-11-14 16:21:39', '2022-11-14 16:21:39', '1');
INSERT INTO `tb_user_card_relation` VALUES ('26', '128', '1', '2', '1', '5', '1', '0', '2022-11-14 17:46:12', '2022-11-14 17:46:12', '1');
INSERT INTO `tb_user_card_relation` VALUES ('27', '162', '1', '2', '1', '5', '1', '0', '2022-11-15 11:31:18', '2022-11-15 11:31:18', '1');
INSERT INTO `tb_user_card_relation` VALUES ('28', '138', '1', '2', '1', '5', '1', '0', '2022-11-15 11:32:28', '2022-11-15 11:32:28', '1');
INSERT INTO `tb_user_card_relation` VALUES ('29', '163', '1', '2', '1', '5', '1', '0', '2022-11-15 11:35:03', '2022-11-15 11:35:03', '1');
INSERT INTO `tb_user_card_relation` VALUES ('30', '8', '4', '2', '11', '12', '1', '0', '2022-11-21 14:25:50', '2022-11-21 14:25:50', '1');
INSERT INTO `tb_user_card_relation` VALUES ('31', '9', '4', '2', '11', '12', '1', '0', '2022-11-21 14:25:59', '2022-11-21 14:25:59', '1');
INSERT INTO `tb_user_card_relation` VALUES ('32', '10', '4', '2', '11', '12', '1', '0', '2022-11-21 14:26:07', '2022-11-21 14:26:07', '1');
INSERT INTO `tb_user_card_relation` VALUES ('33', '258', '1', '2', '19', '26', '1', '0', '2022-12-19 13:44:59', '2022-12-19 13:44:59', '1');
INSERT INTO `tb_user_card_relation` VALUES ('34', '9', '1', '2', '11', '12', '1', '0', '2022-12-19 19:01:30', '2022-12-19 19:01:30', '1');
INSERT INTO `tb_user_card_relation` VALUES ('35', '10', '1', '2', '11', '12', '1', '0', '2022-12-19 19:02:06', '2022-12-19 19:02:06', '1');
INSERT INTO `tb_user_card_relation` VALUES ('36', '11', '1', '2', '11', '12', '1', '0', '2022-12-19 19:03:08', '2022-12-19 19:03:08', '1');
INSERT INTO `tb_user_card_relation` VALUES ('37', '274', '1', '2', '11', '12', '1', '0', '2022-12-19 19:03:45', '2022-12-19 19:03:45', '1');
INSERT INTO `tb_user_card_relation` VALUES ('38', '275', '1', '2', '11', '12', '1', '0', '2022-12-19 19:04:04', '2022-12-19 19:04:04', '1');
INSERT INTO `tb_user_card_relation` VALUES ('39', '276', '1', '2', '11', '12', '1', '0', '2022-12-19 19:04:32', '2022-12-19 19:04:32', '1');
INSERT INTO `tb_user_card_relation` VALUES ('40', '277', '1', '2', '11', '12', '1', '0', '2022-12-19 19:05:02', '2022-12-19 19:05:02', '1');
INSERT INTO `tb_user_card_relation` VALUES ('41', '278', '1', '2', '11', '12', '1', '0', '2022-12-19 19:05:08', '2022-12-19 19:05:08', '1');
INSERT INTO `tb_user_card_relation` VALUES ('42', '279', '1', '2', '11', '12', '1', '0', '2022-12-19 19:05:20', '2022-12-19 19:05:20', '1');
INSERT INTO `tb_user_card_relation` VALUES ('43', '281', '1', '2', '11', '12', '1', '0', '2022-12-19 19:05:45', '2022-12-19 19:05:45', '1');
INSERT INTO `tb_user_card_relation` VALUES ('44', '283', '1', '2', '11', '12', '1', '0', '2022-12-19 19:07:00', '2022-12-19 19:07:00', '1');
INSERT INTO `tb_user_card_relation` VALUES ('45', '284', '1', '2', '11', '12', '1', '0', '2022-12-19 19:07:17', '2022-12-19 19:07:17', '1');
INSERT INTO `tb_user_card_relation` VALUES ('46', '285', '1', '2', '11', '12', '1', '0', '2022-12-19 19:07:54', '2022-12-19 19:07:54', '1');
INSERT INTO `tb_user_card_relation` VALUES ('47', '286', '1', '2', '11', '12', '1', '0', '2022-12-19 19:08:22', '2022-12-19 19:08:22', '1');
INSERT INTO `tb_user_card_relation` VALUES ('48', '287', '1', '2', '11', '12', '1', '0', '2022-12-19 19:08:31', '2022-12-19 19:08:31', '1');
INSERT INTO `tb_user_card_relation` VALUES ('49', '288', '1', '2', '11', '12', '1', '0', '2022-12-19 19:09:24', '2022-12-19 19:09:24', '1');
INSERT INTO `tb_user_card_relation` VALUES ('50', '289', '1', '2', '11', '12', '1', '0', '2022-12-19 19:09:31', '2022-12-19 19:09:31', '1');
INSERT INTO `tb_user_card_relation` VALUES ('51', '290', '1', '2', '11', '12', '1', '0', '2022-12-19 19:09:38', '2022-12-19 19:09:38', '1');
INSERT INTO `tb_user_card_relation` VALUES ('52', '291', '1', '2', '11', '12', '1', '0', '2022-12-19 19:09:56', '2022-12-19 19:09:56', '1');
INSERT INTO `tb_user_card_relation` VALUES ('53', '292', '1', '2', '11', '12', '1', '0', '2022-12-19 19:10:03', '2022-12-19 19:10:03', '1');
INSERT INTO `tb_user_card_relation` VALUES ('54', '260', '1', '2', '19', '26', '1', '0', '2022-12-19 19:16:52', '2022-12-19 19:16:52', '1');
INSERT INTO `tb_user_card_relation` VALUES ('55', '264', '1', '2', '19', '26', '1', '0', '2022-12-19 19:18:15', '2022-12-19 19:18:15', '1');
INSERT INTO `tb_user_card_relation` VALUES ('56', '265', '1', '2', '19', '26', '1', '0', '2022-12-19 19:19:23', '2022-12-19 19:19:23', '1');
INSERT INTO `tb_user_card_relation` VALUES ('57', '266', '1', '2', '19', '26', '1', '0', '2022-12-19 19:19:51', '2022-12-19 19:19:51', '1');
INSERT INTO `tb_user_card_relation` VALUES ('58', '267', '1', '2', '19', '26', '1', '0', '2022-12-19 19:20:31', '2022-12-19 19:20:31', '1');
INSERT INTO `tb_user_card_relation` VALUES ('59', '268', '1', '2', '19', '26', '1', '0', '2022-12-19 19:20:55', '2022-12-19 19:20:55', '1');
INSERT INTO `tb_user_card_relation` VALUES ('60', '269', '1', '2', '19', '26', '1', '0', '2022-12-19 19:23:01', '2022-12-19 19:23:01', '1');
INSERT INTO `tb_user_card_relation` VALUES ('61', '270', '1', '2', '19', '26', '1', '0', '2022-12-19 19:23:08', '2022-12-19 19:23:08', '1');
INSERT INTO `tb_user_card_relation` VALUES ('62', '190', '1', '2', '1', '2', '1', '0', '2022-12-21 15:47:15', '2022-12-21 15:47:15', '1');
INSERT INTO `tb_user_card_relation` VALUES ('63', '192', '1', '2', '1', '2', '1', '0', '2022-12-21 15:47:30', '2022-12-21 15:47:30', '1');
INSERT INTO `tb_user_card_relation` VALUES ('64', '323', '1', '2', '19', '26', '1', '0', '2023-02-27 15:31:01', '2023-02-27 15:31:01', '1');
INSERT INTO `tb_user_card_relation` VALUES ('65', '293', '1', '2', '27', '28', '1', '0', '2023-02-27 15:31:19', '2023-02-27 15:31:19', '1');
INSERT INTO `tb_user_card_relation` VALUES ('66', '332', '1', '2', '27', '28', '1', '0', '2023-02-27 15:32:25', '2023-02-27 15:32:25', '1');
INSERT INTO `tb_user_card_relation` VALUES ('67', '350', '1', '2', '1', '32', '1', '0', '2023-02-27 17:47:34', '2023-02-27 17:47:34', '1');
